<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Notes]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://jayitha.github.io/Notes/</link><image><url>https://jayitha.github.io/Notes/lib/media/favicon.png</url><title>Notes</title><link>https://jayitha.github.io/Notes/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 18 Mar 2024 20:35:41 GMT</lastBuildDate><atom:link href="https://jayitha.github.io/Notes/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 18 Mar 2024 20:35:38 GMT</pubDate><copyright><![CDATA[Jayitha Cherapanamjeri]]></copyright><ttl>60</ttl><dc:creator>Jayitha Cherapanamjeri</dc:creator><item><title><![CDATA[Weak Law of Large Numbers]]></title><description><![CDATA[ 
 <br><a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a><br>Aside
See <a data-href="Converges in Probability" href="https://jayitha.github.io/Notes/glossary/converges-in-probability.html" class="internal-link" target="_self" rel="noopener">Converges in Probability</a><br>
for definition of 
<br>Let  be <a data-tooltip-position="top" aria-label="Independent and Identically Distributed (IID)" data-href="Independent and Identically Distributed (IID)" href="https://jayitha.github.io/Notes/glossary/independent-and-identically-distributed-(iid).html" class="internal-link" target="_self" rel="noopener">IID</a> random variables and  is finite, then<br>
<br>Aside
Testing aside
<br>Slutsky's Theorem<br><br><br><a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a><br>
Let  be random vectors (of the same arity) and  be a continuous function. If  and  is finite then <br>Related Corollaries:<br>If  and  are sequences of random variables s.t.  and , then <br>
<br>An idea!<a href="https://jayitha.github.io/Notes/#fn-1-7a4cc735db5d8312" class="footnote-link" target="_self" rel="noopener">[1]</a>
<br>Info
<br>Ooo danger!
<br>
<br>
<br>
<a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a>
<a href="https://jayitha.github.io/Notes/#fnref-1-7a4cc735db5d8312" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>

]]></description><link>https://jayitha.github.io/Notes/glossary/weak-law-of-large-numbers.html</link><guid isPermaLink="false">Glossary/Weak Law of Large Numbers.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 20:35:11 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Chebyshev Metric</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: L-inf Norm, Maximum Metric, Infinity Norm<br>
Papers: [-]<br>
Tags: <a href="https://jayitha.github.io/Notes?query=tag:metric" class="tag" target="_blank" rel="noopener">#metric</a>]]></description><link>https://jayitha.github.io/Notes/glossary/chebyshev-metric.html</link><guid isPermaLink="false">Glossary/Chebyshev Metric.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 06 Nov 2023 09:46:02 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Concurrency</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="arpacidusseau2018operating" href="https://jayitha.github.io/Notes/literature-notes/arpacidusseau2018operating.html" class="internal-link" target="_self" rel="noopener">arpacidusseau2018operating</a>]<br>
Tags: ]]></description><link>https://jayitha.github.io/Notes/glossary/concurrency.html</link><guid isPermaLink="false">Glossary/Concurrency.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 17 Nov 2023 10:58:41 GMT</pubDate></item><item><title><![CDATA[Converges in Probability]]></title><description><![CDATA[ 
 <br><a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a><br>
A sequence of random vectors (where all vectors have the same arity)   converges in probability  to a constant vector  if for all  the probability of  being at most  away from  converges to  as .<br> Related Lemmas:<br>If  is a sequence of random variables with finite variance and  and , then ]]></description><link>https://jayitha.github.io/Notes/glossary/converges-in-probability.html</link><guid isPermaLink="false">Glossary/Converges in Probability.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 09:37:22 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Curse of Dimensionality</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [-]<br>
Tags: ]]></description><link>https://jayitha.github.io/Notes/glossary/curse-of-dimensionality.html</link><guid isPermaLink="false">Glossary/Curse of Dimensionality.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 21 Nov 2023 15:33:37 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Equi-Join</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: Theta Equi-Join<br>
Papers: [-]<br>
Tags: <a href="https://jayitha.github.io/Notes?query=tag:join-type" class="tag" target="_blank" rel="noopener">#join-type</a>]]></description><link>https://jayitha.github.io/Notes/glossary/equi-join.html</link><guid isPermaLink="false">Glossary/Equi-Join.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sat, 04 Nov 2023 09:37:55 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>iMinMax</span></span>(<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span>)]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="ooi2000indexing" href="https://jayitha.github.io/Notes/literature-notes/ooi2000indexing.html" class="internal-link" target="_self" rel="noopener">ooi2000indexing</a>]<br>
Tags: <a href="https://jayitha.github.io/Notes?query=tag:indexing" class="tag" target="_blank" rel="noopener">#indexing</a><br><a data-href="ooi2000indexing" href="https://jayitha.github.io/Notes/literature-notes/ooi2000indexing.html" class="internal-link" target="_self" rel="noopener">ooi2000indexing</a><br>
<br>Maps points in high dimensional spaces to single dimension values determined by their maximum or minimum values amongst all their dimensions
<br> is a tunable parameter that can be adapted for different data distributions
<br>iMinMax has three notable features<br>
<br>Adopts a simple transformation function from high dimensions to single dimension. Let  and  be the minimum and maximum value of a point  across all dimensions ( and  resp.). The mapping is given as follows<br>
This transformation partitions the data based on the dimension which has the largest or smallest value. 
<br>The single dimension values can be then indexed using a B+-Tree index and hence the iMinMax index can be used on top of existing DBMS
<br>The range query needs to be transformed. The transformation involves generating a range query on each dimension. The intersection of all range query answers is a superset of the required solution set. This is supposedly still efficient because

<br>The produced candidate set cannot be further pruned without losing out critical candidates
<br>The search space is reduced and 
<br>some range subqueries can be pruned without being evaluated


<br>By varying , you end up constructing different families of iMinMax index structures. At extremes, you map all data points to their maximum (minimum) value. At other values of , you partition data points based on the dimensions which has max/min values
<br>Unlike the <a data-href="Pyramid Technique" href="https://jayitha.github.io/Notes/glossary/pyramid-technique.html" class="internal-link" target="_self" rel="noopener">Pyramid Technique</a>, this index performs well on skewed distributions as well. <br>The value of  and  varies between 0-&gt;1. Therefore, the elements that get indexed using the first dimension usually range between , the elements that get ranged in the second dimension range between  and so on.<br>Lets say you have a range query  with th query subrange , the subquery  is given by<br><br>
<br>
]]></description><link>https://jayitha.github.io/Notes/glossary/iminmax.html</link><guid isPermaLink="false">Glossary/iMinMax.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 07 Nov 2023 03:59:34 GMT</pubDate></item><item><title><![CDATA[Independent and Identically Distributed (IID)]]></title><description><![CDATA[ 
 ]]></description><link>https://jayitha.github.io/Notes/glossary/independent-and-identically-distributed-(iid).html</link><guid isPermaLink="false">Glossary/Independent and Identically Distributed (IID).md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 08:52:00 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Locality Sensitive Hashing</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: LSH<br>
Papers: [<a data-href="slaney2008locality" href="https://jayitha.github.io/Notes/literature-notes/slaney2008locality.html" class="internal-link" target="_self" rel="noopener">slaney2008locality</a>]<br>
Tags: <a href="https://jayitha.github.io/Notes?query=tag:indexing" class="tag" target="_blank" rel="noopener">#indexing</a>]]></description><link>https://jayitha.github.io/Notes/glossary/locality-sensitive-hashing.html</link><guid isPermaLink="false">Glossary/Locality Sensitive Hashing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 21 Nov 2023 15:33:37 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Persistence</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="arpacidusseau2018operating" href="https://jayitha.github.io/Notes/literature-notes/arpacidusseau2018operating.html" class="internal-link" target="_self" rel="noopener">arpacidusseau2018operating</a>]<br>
Tags: ]]></description><link>https://jayitha.github.io/Notes/glossary/persistence.html</link><guid isPermaLink="false">Glossary/Persistence.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 17 Nov 2023 10:58:56 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Pyramid Technique</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="berchtold1998pyramid" href="https://jayitha.github.io/Notes/literature-notes/berchtold1998pyramid.html" class="internal-link" target="_self" rel="noopener">berchtold1998pyramid</a>]<br>
Tags: <br><a data-href="berchtold1998pyramid" href="https://jayitha.github.io/Notes/literature-notes/berchtold1998pyramid.html" class="internal-link" target="_self" rel="noopener">berchtold1998pyramid</a><br>
<br>Indexing technique for high-dimensional data spaces
<br>Adapted to range query processing using the <a data-tooltip-position="top" aria-label="Chebyshev Metric" data-href="Chebyshev Metric" href="https://jayitha.github.io/Notes/glossary/chebyshev-metric.html" class="internal-link" target="_self" rel="noopener">Maximum Metric</a>  
<br>
The basic idea is divide the data space such that the resulting partitions are shaped like peels of an onion
<br>Two major steps<br>
Step 1: Divide the -dimensional space into  pyramids having the center point of the space as their top.<br>
Step 2: Single pyramids are cut into slices parallel to the basis of the pyramid forming the data pages.<br>The paper <a data-href="berchtold1998pyramid" href="https://jayitha.github.io/Notes/literature-notes/berchtold1998pyramid.html" class="internal-link" target="_self" rel="noopener">berchtold1998pyramid</a> states that unlike other indexing structures, the performance of the pyramid technique is not impacted by the <a data-href="Curse of Dimensionality" href="https://jayitha.github.io/Notes/glossary/curse-of-dimensionality.html" class="internal-link" target="_self" rel="noopener">Curse of Dimensionality</a>, in fact, the performance improves as the dimensionality of the space increases. <br>
It's important to note that these observations are made for hypercube queries and uniform data distributions. Queries which touch the boundary of the data space or very skewed queries are handled less efficiently. 
<br>This technique maps the given -dimensional data space into a -dimensional data space so we can use B-Tree indexing.<br><br>
<br>
<br>
<br>
]]></description><link>https://jayitha.github.io/Notes/glossary/pyramid-technique.html</link><guid isPermaLink="false">Glossary/Pyramid Technique.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 06 Nov 2023 10:20:53 GMT</pubDate></item><item><title><![CDATA[Slutsky's Theorem]]></title><description><![CDATA[ 
 <br><a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a><br>
Let  be random vectors (of the same arity) and  be a continuous function. If  and  is finite then <br>Related Corollaries:<br>If  and  are sequences of random variables s.t.  and , then ]]></description><link>https://jayitha.github.io/Notes/glossary/slutsky's-theorem.html</link><guid isPermaLink="false">Glossary/Slutsky's Theorem.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 19:39:14 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>The Relational Model</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="codd1970relational" href="https://jayitha.github.io/Notes/literature-notes/codd1970relational.html" class="internal-link" target="_self" rel="noopener">codd1970relational</a>]<br>
Tags: <br><a data-href="moseley2006out" href="https://jayitha.github.io/Notes/literature-notes/moseley2006out.html" class="internal-link" target="_self" rel="noopener">moseley2006out</a><br>
<br>Origin <a data-href="codd1970relational" href="https://jayitha.github.io/Notes/literature-notes/codd1970relational.html" class="internal-link" target="_self" rel="noopener">codd1970relational</a>
<br>Nothing intrinsically to do with databases

Elegant approach to structuring data, a means for manipulating such data, and a mechanism for maintaining integrity and consistency of state and a fourth strength is its insistence on a clear separation between the logical and physical layers of the system


<br>The relational model has the following four aspects

<br>Structure (relations represent data)
<br>Manipulation (means to specify derived data)
<br>Integrity (a means to specify restrictions on data)
<br>Data Independence (separation b/w logical data and its physical representation)


<br><br><br>: <br>: ]]></description><link>https://jayitha.github.io/Notes/glossary/the-relational-model.html</link><guid isPermaLink="false">Glossary/The Relational Model.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 08 Jan 2024 12:14:12 GMT</pubDate></item><item><title><![CDATA[Unstable Nearest Neighbor Query]]></title><description><![CDATA[ 
 <br><a data-href="beyer1999nearest" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">beyer1999nearest</a><br>
A nearest neighbor query is unstable for a given  if the distance from the query point to most data points is less than  times the distance from the query point to its nearest neighbor<br>
<br>In many situations, for any fixed , as dimensionality increases, the probability that a query is unstable converges to 
]]></description><link>https://jayitha.github.io/Notes/glossary/unstable-nearest-neighbor-query.html</link><guid isPermaLink="false">Glossary/Unstable Nearest Neighbor Query.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 09:34:48 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>VA-File</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [-]<br>
Tags: <br><a data-href="ooi2000indexing" href="https://jayitha.github.io/Notes/literature-notes/ooi2000indexing.html" class="internal-link" target="_self" rel="noopener">ooi2000indexing</a><br>
The performance of the VA-File is sensitive to the data distribution]]></description><link>https://jayitha.github.io/Notes/glossary/va-file.html</link><guid isPermaLink="false">Glossary/VA-File.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 07 Nov 2023 02:32:38 GMT</pubDate></item><item><title><![CDATA[<span class="dataview dataview-inline-query"><span>Virtualization</span></span>]]></title><description><![CDATA[ 
 <br><br>Aliases: <br>
Papers: [<a data-href="arpacidusseau2018operating" href="https://jayitha.github.io/Notes/literature-notes/arpacidusseau2018operating.html" class="internal-link" target="_self" rel="noopener">arpacidusseau2018operating</a>]<br>
Tags: ]]></description><link>https://jayitha.github.io/Notes/glossary/virtualization.html</link><guid isPermaLink="false">Glossary/Virtualization.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 17 Nov 2023 10:58:16 GMT</pubDate></item><item><title><![CDATA[A new file system for flash storage]]></title><description><![CDATA[ 
 <br><br>Changman Lee, Dongho Sim, Jooyoung Hwang, Sangyeun Cho (2015)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Changman-Lee" class="tag" target="_blank" rel="noopener">#Changman-Lee</a> <a href="https://jayitha.github.io/Notes?query=tag:Dongho-Sim" class="tag" target="_blank" rel="noopener">#Dongho-Sim</a> <a href="https://jayitha.github.io/Notes?query=tag:Jooyoung-Hwang" class="tag" target="_blank" rel="noopener">#Jooyoung-Hwang</a> <a href="https://jayitha.github.io/Notes?query=tag:Sangyeun-Cho" class="tag" target="_blank" rel="noopener">#Sangyeun-Cho</a><br>Abstract
F2FS is a Linux file system designed to perform well on modern flash storage devices. The file system builds on append-only logging and its key design decisions were made with the characteristics of flash storage in mind. This paper describes the main design ideas, data structures, algorithms and the resulting performance of F2FS. Experimental results highlight the desirable performance of F2FS; on a state-of-the-art mobile system, it outperforms EXT4 under synthetic workloads by up to 3.1 (iozone) and 2 (SQLite). It reduces elapsed time of several realistic workloads by up to 40%. On a server system, F2FS is shown to perform better than EXT4 by up to 2.5 (SATA SSD) and 1.8 (PCIe SSD).
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lee2015f2fs.html</link><guid isPermaLink="false">Literature Notes/lee2015f2fs.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:28:58 GMT</pubDate></item><item><title><![CDATA[Integrating compression and execution in column-oriented database systems]]></title><description><![CDATA[ 
 <br><br>Daniel Abadi, Samuel Madden, Miguel Ferreira (2006)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel-Abadi" class="tag" target="_blank" rel="noopener">#Daniel-Abadi</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel-Madden" class="tag" target="_blank" rel="noopener">#Samuel-Madden</a> <a href="https://jayitha.github.io/Notes?query=tag:Miguel-Ferreira" class="tag" target="_blank" rel="noopener">#Miguel-Ferreira</a><br>Abstract
Column-oriented database system architectures invite a re-evaluation of how and when data in databases is compressed. Storing data in a column-oriented fashion greatly increases the similarity of adjacent records on disk and thus opportunities for compression. The ability to compress many adjacent tuples at once lowers the per-tuple cost of compression, both in terms of CPU and space overheads.In this paper, we discuss how we extended C-Store (a column-oriented DBMS) with a compression sub-system. We show how compression schemes not traditionally used in row-oriented DBMSs can be applied to column-oriented systems. We then evaluate a set of compression schemes and show that the best scheme depends not only on the properties of the data but also on the nature of the query workload.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abadi2006integrating.html</link><guid isPermaLink="false">Literature Notes/abadi2006integrating.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:23:46 GMT</pubDate></item><item><title><![CDATA[Column-stores vs. Row-stores: How different are they really?]]></title><description><![CDATA[ 
 <br><br>Daniel J Abadi, Samuel R Madden, Nabil Hachem (2008)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel" class="tag" target="_blank" rel="noopener">#Daniel</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Abadi" class="tag" target="_blank" rel="noopener">#J-Abadi</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel" class="tag" target="_blank" rel="noopener">#Samuel</a> <a href="https://jayitha.github.io/Notes?query=tag:R-Madden" class="tag" target="_blank" rel="noopener">#R-Madden</a> <a href="https://jayitha.github.io/Notes?query=tag:Nabil-Hachem" class="tag" target="_blank" rel="noopener">#Nabil-Hachem</a><br>Abstract
There has been a significant amount of excitement and recent work on column-oriented database systems ("column-stores"). These database systems have been shown to perform more than an order of magnitude better than traditional row-oriented database systems ("row-stores") on analytical workloads such as those found in data warehouses, decision support, and business intelligence applications. The elevator pitch behind this performance difference is straightforward: column-stores are more I/O efficient for read-only queries since they only have to read from disk (or from memory) those attributes accessed by a query. This simplistic view leads to the assumption that one can obtain the performance benefits of a column-store using a row-store: either by vertically partitioning the schema, or by indexing every column so that columns can be accessed independently. In this paper, we demonstrate that this assumption is false. We compare the performance of a commercial row-store under a variety of different configurations with a column-store and show that the row-store performance is significantly slower on a recently proposed data warehouse benchmark. We then analyze the performance difference and show that there are some important differences between the two systems at the query executor level (in addition to the obvious differences at the storage layer level). Using the column-store, we then tease apart these differences, demonstrating the impact on performance of a variety of column-oriented query execution techniques, including vectorized query processing, compression, and a new join algorithm we introduce in this paper. We conclude that while it is not impossible for a row-store to achieve some of the performance advantages of a column-store, changes must be made to both the storage layer and the query executor to fully obtain the benefits of a column-oriented approach.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abadi2008column.html</link><guid isPermaLink="false">Literature Notes/abadi2008column.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:23:52 GMT</pubDate></item><item><title><![CDATA[The design and implementation of modern column-oriented database systems]]></title><description><![CDATA[ 
 <br><br>Daniel Abadi, Peter Boncz, Stavros Harizopoulos, Stratos Idreos, Samuel Madden, others (2013)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel-Abadi" class="tag" target="_blank" rel="noopener">#Daniel-Abadi</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Boncz" class="tag" target="_blank" rel="noopener">#Peter-Boncz</a> <a href="https://jayitha.github.io/Notes?query=tag:Stavros-Harizopoulos" class="tag" target="_blank" rel="noopener">#Stavros-Harizopoulos</a> <a href="https://jayitha.github.io/Notes?query=tag:Stratos-Idreos" class="tag" target="_blank" rel="noopener">#Stratos-Idreos</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel-Madden" class="tag" target="_blank" rel="noopener">#Samuel-Madden</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract
In this article, we survey recent research on column-oriented database systems, or column-stores, where each attribute of a table is stored in a separate file or region on storage. Such databases have seen a resurgence in recent years with a rise in interest in analytic queries that perform scans and aggregates over large portions of a few columns of a table. The main advantage of a column-store is that it can access just the columns needed to answer such queries. We specifically focus on three influential research prototypes, MonetDB [46], MonetDB/X100 [18], and C-Store [86]. These systems have formed the basis for several well-known commercial column-store implementations. We describe their similarities and differences and discuss their specific architectural features for compression, late materialization, join processing, vectorization and adaptive indexing (database cracking).
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abadi2013design.html</link><guid isPermaLink="false">Literature Notes/abadi2013design.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:23:32 GMT</pubDate></item><item><title><![CDATA[Urgent virtual machine eviction with enlightened post-copy]]></title><description><![CDATA[ 
 <br><br>Yoshihisa Abe, Roxana Geambasu, Kaustubh Joshi, Mahadev Satyanarayanan (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Yoshihisa-Abe" class="tag" target="_blank" rel="noopener">#Yoshihisa-Abe</a> <a href="https://jayitha.github.io/Notes?query=tag:Roxana-Geambasu" class="tag" target="_blank" rel="noopener">#Roxana-Geambasu</a> <a href="https://jayitha.github.io/Notes?query=tag:Kaustubh-Joshi" class="tag" target="_blank" rel="noopener">#Kaustubh-Joshi</a> <a href="https://jayitha.github.io/Notes?query=tag:Mahadev-Satyanarayanan" class="tag" target="_blank" rel="noopener">#Mahadev-Satyanarayanan</a><br>Abstract
Virtual machine (VM) migration demands distinct properties under resource oversubscription and workload surges. We present enlightened post-copy, a new mechanism for VMs under contention that evicts the target VM with fast execution transfer and short total duration. This design contrasts with common live migration, which uses the down time of the migrated VM as its primary metric; it instead focuses on recovering the aggregate performance of the VMs being affected. In enlightened post-copy, the guest OS identifies memory state that is expected to encompass the VM's working set. The hypervisor accordingly transfers its state, mitigating the performance impact on the migrated VM resulting from post-copy transfer. We show that our implementation, with modest instrumentation in guest Linux, resolves VM contention up to several times faster than live migration.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abe2016urgent.html</link><guid isPermaLink="false">Literature Notes/abe2016urgent.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:23:59 GMT</pubDate></item><item><title><![CDATA[Integrating multimedia applications in hard real-time systems]]></title><description><![CDATA[ 
 <br><br>Luca Abeni, Giorgio Buttazzo (1998)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Luca-Abeni" class="tag" target="_blank" rel="noopener">#Luca-Abeni</a> <a href="https://jayitha.github.io/Notes?query=tag:Giorgio-Buttazzo" class="tag" target="_blank" rel="noopener">#Giorgio-Buttazzo</a><br>Abstract
This paper focuses on the problem of providing efficient run-time support to multimedia applications in a real-time system, where two types of tasks can coexist simultaneously: multimedia soft real-time tasks and hard real-time tasks. Hard tasks are guaranteed based on worst case execution times and minimum interarrival times, whereas multimedia and soft tasks are served based on mean parameters. The paper describes a server-based mechanism for scheduling soft and multimedia tasks without jeopardizing the a priori guarantee of hard real-time activities. The performance of the proposed method is compared with that of similar service mechanisms through extensive simulation experiments and several multimedia applications have been implemented on the HARTIK kerne
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abeni1998integrating.html</link><guid isPermaLink="false">Literature Notes/abeni1998integrating.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:24:02 GMT</pubDate></item><item><title><![CDATA[Foundations of databases]]></title><description><![CDATA[ 
 <br><br>Serge Abiteboul, Richard Hull, Victor Vianu (1995)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Serge-Abiteboul" class="tag" target="_blank" rel="noopener">#Serge-Abiteboul</a> <a href="https://jayitha.github.io/Notes?query=tag:Richard-Hull" class="tag" target="_blank" rel="noopener">#Richard-Hull</a> <a href="https://jayitha.github.io/Notes?query=tag:Victor-Vianu" class="tag" target="_blank" rel="noopener">#Victor-Vianu</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/abiteboul1995foundations.html</link><guid isPermaLink="false">Literature Notes/abiteboul1995foundations.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 14 Mar 2024 12:56:22 GMT</pubDate></item><item><title><![CDATA[HadoopDB: An architectural hybrid of MapReduce and DBMS technologies for analytical workloads]]></title><description><![CDATA[ 
 <br><br>Azza Abouzeid, Kamil Bajda-Pawlikowski, Daniel Abadi, Avi Silberschatz, Alexander Rasin (2009)<br>Tags: <br>Abstract
The production environment for analytical data management applications is rapidly changing. Many enterprises are shifting away from deploying their analytical databases on high-end proprietary machines, and moving towards cheaper, lower-end, commodity hardware, typically arranged in a shared-nothing MPP architecture, often in a virtualized environment inside public or private "clouds". At the same time, the amount of data that needs to be analyzed is exploding, requiring hundreds to thousands of machines to work in parallel to perform the analysis. There tend to be two schools of thought regarding what technology to use for data analysis in such an environment. Proponents of parallel databases argue that the strong emphasis on performance and efficiency of parallel databases makes them well-suited to perform such analysis. On the other hand, others argue that MapReduce-based systems are better suited due to their superior scalability, fault tolerance, and flexibility to handle unstructured data. In this paper, we explore the feasibility of building a hybrid system that takes the best features from both technologies; the prototype we built approaches parallel databases in performance and efficiency, yet still yields the scalability, fault tolerance, and flexibility of MapReduce-based systems.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/abouzeid2009hadoopdb.html</link><guid isPermaLink="false">Literature Notes/abouzeid2009hadoopdb.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:58 GMT</pubDate></item><item><title><![CDATA[Efficient optimistic concurrency control using loosely synchronized clocks]]></title><description><![CDATA[ 
 <br><br>Atul Adya, Robert Gruber, Barbara Liskov, Umesh Maheshwari (1995)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Atul-Adya" class="tag" target="_blank" rel="noopener">#Atul-Adya</a> <a href="https://jayitha.github.io/Notes?query=tag:Robert-Gruber" class="tag" target="_blank" rel="noopener">#Robert-Gruber</a> <a href="https://jayitha.github.io/Notes?query=tag:Barbara-Liskov" class="tag" target="_blank" rel="noopener">#Barbara-Liskov</a> <a href="https://jayitha.github.io/Notes?query=tag:Umesh-Maheshwari" class="tag" target="_blank" rel="noopener">#Umesh-Maheshwari</a><br>Abstract
This paper describes an efficient optimistic concurrency control scheme for use in distributed database systems in which objects are cached and manipulated at client machines while persistent storage and transactional support are provided by servers. The scheme provides both serializability and external consistency for committed transactions; it uses loosely synchronized clocks to achieve global serialization. It stores only a single version of each object, and avoids maintaining any concurrency control information on a per-object basis; instead, it tracks recent invalidations on a per-client basis, an approach that has low in-memory space overhead and no per-object disk overhead. In addition to its low space overheads, the scheme also performs well. The paper presents a simulation study that compares the scheme to adaptive callback locking, the best concurrency control scheme for client-server object-oriented database systems studied to date. The study shows that our scheme outperforms adaptive callback locking for low to moderate contention workloads, and scales better with the number of clients. For high contention workloads, optimism can result in a high abort rate; the scheme presented here is a first step toward a hybrid scheme that we expect to perform well across the full range of workloads.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/adya1995efficient.html</link><guid isPermaLink="false">Literature Notes/adya1995efficient.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:45:05 GMT</pubDate></item><item><title><![CDATA[Generalized isolation level definitions]]></title><description><![CDATA[ 
 <br><br>Atul Adya, Barbara Liskov, Patrick O'Neil (2000)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Atul-Adya" class="tag" target="_blank" rel="noopener">#Atul-Adya</a> <a href="https://jayitha.github.io/Notes?query=tag:Barbara-Liskov" class="tag" target="_blank" rel="noopener">#Barbara-Liskov</a> <a href="https://jayitha.github.io/Notes?query=tag:Patrick-O" class="tag" target="_blank" rel="noopener">#Patrick-O</a>'Neil<br>Abstract
Commercial databases support different isolation levels to allow programmers to trade off consistency for a potential gain in performance. The isolation levels are defined in the current ANSI standard, but the definitions are ambiguous and revised definitions proposed to correct the problem are too constrained since they allow only pessimistic (locking) implementations. This paper presents new specifications for the ANSI levels. Our specifications are portable: they apply not only to locking implementations, but also to optimistic and multi-version concurrency control schemes. Furthermore, unlike earlier definitions, our new specifications handle predicates in a correct and flexible manner at all levels.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/adya2000generalized.html</link><guid isPermaLink="false">Literature Notes/adya2000generalized.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:33:27 GMT</pubDate></item><item><title><![CDATA[Concurrency control performance modeling: Alternatives and implications]]></title><description><![CDATA[ 
 <br><br>Rakesh Agrawal, Michael J Carey, Miron Livny (1987)<br>Tags: <br>Abstract
A number of recent studies have examined the performance of concurrency control algorithms for database management systems. The results reported to date, rather than being definitive, have tended to be contradictory. In this paper, rather than presenting “yet another algorithm performance study,” we critically investigate the assumptions made in the models used in past studies and their implications. We employ a fairly complete model of a database environment for studying the relative performance of three different approaches to the concurrency control problem under a variety of modeling assumptions. The three approaches studied represent different extremes in how transaction conflicts are dealt with, and the assumptions addressed pertain to the nature of the database system's resources, how transaction restarts are modeled, and the amount of information available to the concurrency control algorithm about transactions' reference strings. We show that differences in the underlying assumptions explain the seemingly contradictory performance results. We also address the question of how realistic the various assumptions are for actual database systems.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/agrawal1987concurrency.html</link><guid isPermaLink="false">Literature Notes/agrawal1987concurrency.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:04:00 GMT</pubDate></item><item><title><![CDATA[Massively parallel sort-merge joins in main memory multi-core database systems]]></title><description><![CDATA[ 
 <br><br>Martina-Cezara Albutiu, Alfons Kemper, Thomas Neumann (2012)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Martina-Cezara-Albutiu" class="tag" target="_blank" rel="noopener">#Martina-Cezara-Albutiu</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a><br>Abstract
Two emerging hardware trends will dominate the database system technology in the near future: increasing main memory capacities of several TB per server and massively parallel multi-core processing. Many algorithmic and control techniques in current database technology were devised for disk-based systems where I/O dominated the performance. In this work we take a new look at the well-known sort-merge join which, so far, has not been in the focus of research in scalable massively parallel multi-core data processing as it was deemed inferior to hash joins. We devise a suite of new massively parallel sort-merge (MPSM) join algorithms that are based on partial partition-based sorting. Contrary to classical sort-merge joins, our MPSM algorithms do not rely on a hard to parallelize final merge step to create one complete sort order. Rather they work on the independently created runs in parallel. This way our MPSM algorithms are NUMA-affine as all the sorting is carried out on local memory partitions. An extensive experimental evaluation on a modern 32-core machine with one TB of main memory proves the competitive performance of MPSM on large main memory databases with billions of objects. It scales (almost) linearly in the number of employed cores and clearly outperforms competing hash join proposals - in particular it outperforms the "cutting-edge" Vectorwise parallel query engine by a factor of four.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/albutiu2012massively.html</link><guid isPermaLink="false">Literature Notes/albutiu2012massively.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:50:58 GMT</pubDate></item><item><title><![CDATA[Consistency analysis in bloom: A CALM and collected approach.]]></title><description><![CDATA[ 
 <br><br>Peter Alvaro, Neil Conway, Joseph M Hellerstein, William R Marczak (2011)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/alvaro2011consistency.html</link><guid isPermaLink="false">Literature Notes/alvaro2011consistency.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:36:41 GMT</pubDate></item><item><title><![CDATA[Operating systems: Three easy pieces]]></title><description><![CDATA[ 
 <br><br>Remzi H. Arpaci-Dusseau, Andrea C. Arpaci-Dusseau (2018)<br>
Tags: <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br>URL - <a rel="noopener" class="external-link" href="https://pages.cs.wisc.edu/~remzi/OSTEP/" target="_blank">https://pages.cs.wisc.edu/~remzi/OSTEP/</a><br><br>
<br>Read "Surely You're Joking, Mr. Feynman"
<br>The three pieces are virtualization, concurrency and persistence
<br>Other names for an OS<br>
<br>a virtual machine
<br>provides a standard library to applications
<br>resource manager
<br>Role of OS

<br>Takes physical resources, like CPU, memory, or disk and virtualizes them
<br>IT handles concurrency issues
<br>Stores files persistently

<br>Design Goals<br>
<br>Performance - minimize time and space for features like virtualization
<br>Protection - isolating one application from the others and the OS
<br>Reliability - OS cannot fail
<br>History<br>
<br>Early OS simply consisted of a set of libraries for commonly-used functions
<br>Next, system calls were invented - they realized you should treat code that runs on behalf of the OS differently (it should have superior access) from a user's
<br>Aside
User applications run in user mode  OS processes are run in kernel mode
<br>
The key difference between a system call and a procedure call is that a system call transfers control (i.e. jumps) into the OS while simultaneously raising the hardware privilege level
In user mode, the program cannot initialize I/O request to the disk or access physical memory or send a packet on the network. 
A system call is initiated through a trap, control is passed to a trap handler entering the kernel mode. When the request has been serviced, control is passed back to the user via a return-from-trap instruction
<br>
<br>Shift from mainframe to minicomputers
<br>Introduction of multiprogramming - instead of running one job at a time, run multiple jobs switching rapidly between them.

<br>Switching was important because I/O devices were slow


<br>Shortly after, the UNIX OS was developed by Bell Labs
<br>From minicomputers to PCs
<br><br><a data-href="Virtualization" href="https://jayitha.github.io/Notes/glossary/virtualization.html" class="internal-link" target="_self" rel="noopener">Virtualization</a><br>
<br>the OS takes a physical resource and transforms it into a more general, powerful and easy-to-use virtual form of itself
<br>Virtualizing the CPU enables you to, say, run multiple programs on a single processor as if they were running on multiple processors
<br>Each running program has its own private memory - virtualizing memory

<br>Each process accesses its own private virtual address space


<br><br>
<br>A program itself is just lifeless data. A process is a running program.
<br>Virtualizing the CPU by stopping one process to run another is called time sharing the CPU
<br>To implement time-sharing, you need both low-level machinery mechanisms like context switches and high-level intelligence policies like scheduling
<br>Note
Separating mechanisms (low-level) and policies (high-level) is a way of achieving modularity i.e. you can change low-level mechanisms without having to change (high-level) policies.
<br>
<br>To characterize a process we need to take stock of its machine state

<br>What it can read or update
<br>What parts of the machine is it using 
<br>memory (its address space)
<br>registers 

<br>special registers include - Program Counter (PC) (or Instruction Pointer (IP)), stack pointer and associated frame pointer


<br>I/O


<br>Process APIs should include<br>
<br>Create
<br>Destroy
<br>Wait
<br>Miscellaneous Control - e.g. suspend and resume 
<br>Status
<br>Process Creation<br>
<br>Load code and any static data into the address space of the process (usually onto the heap)

<br>Old OS' load eagerly whereas modern ones load lazily


<br>Allocate program's run-time stack ans heap

<br>the heap is initially small, but grows as the program requests for more space


<br>Initialize I/O file descriptors - e.g. stdin, stdout, stderr
<br>Start the process by jumping to the main()
<br>Process States<br>
<br>
Running - executing instructions on a processor

<br>
Ready

<br>
Blocked - e.g. initiated I/O request to disk, blocked. Some other process can use the processor

<br>
Does there need to be any processor involvement as I/O is taking place?

<br>Data Structures<br>
<br>The OS has data structures to track information such as - the process list
<br>The process list will for instance track the following information about each process (called a Process Control Block (PCB))<br><img alt="Pasted image 20240203110534.png" src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240203110534.png"><br><br><a data-href="Concurrency" href="https://jayitha.github.io/Notes/glossary/concurrency.html" class="internal-link" target="_self" rel="noopener">Concurrency</a><br>
<br>A thread is a function that is running within the same memory space as other functions with more than one active at a time
<br>A program that uses threads to increment a shared counter but doesn't force atomicity will see different outputs for the same number of specified increments
<br><br><a data-href="Persistence" href="https://jayitha.github.io/Notes/glossary/persistence.html" class="internal-link" target="_self" rel="noopener">Persistence</a><br>
<br>The software that manages the disk is called the file system
<br>Unlike CPU or memory, disks aren't typically virtualized
<br>For performance, file systems delay write for a while hoping to batch them using intricate write protocols like journaling or copy-on-write
<br><br><br><br><a data-tooltip-position="top" aria-label="Glossary/Virtualization.md" data-href="Glossary/Virtualization.md" href="https://jayitha.github.io/Notes/glossary/virtualization.html" class="internal-link" target="_self" rel="noopener">Virtualization</a>: -<br><a data-tooltip-position="top" aria-label="Glossary/Concurrency.md" data-href="Glossary/Concurrency.md" href="https://jayitha.github.io/Notes/glossary/concurrency.html" class="internal-link" target="_self" rel="noopener">Concurrency</a>: -<br><a data-tooltip-position="top" aria-label="Glossary/Persistence.md" data-href="Glossary/Persistence.md" href="https://jayitha.github.io/Notes/glossary/persistence.html" class="internal-link" target="_self" rel="noopener">Persistence</a>: -]]></description><link>https://jayitha.github.io/Notes/literature-notes/arpacidusseau2018operating.html</link><guid isPermaLink="false">Literature Notes/arpacidusseau2018operating.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sat, 03 Feb 2024 05:37:11 GMT</pubDate><enclosure url="https://jayitha.github.io/Notes/lib/media/pasted-image-20240203110534.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240203110534.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[System R: Relational approach to database management]]></title><description><![CDATA[ 
 <br><br>Morton M. Astrahan, Mike W. Blasgen, Donald D. Chamberlin, Kapali P. Eswaran, Jim N Gray, Patricia P. Griffiths, W Frank King, Raymond A. Lorie, Paul R. McJones, James W. Mehl, others (1976)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a><br>Abstract
System R is a database management system which provides a high level relational data interface. The systems provides a high level of data independence by isolating the end user as much as possible from underlying storage structures. The system permits definition of a variety of relational views on common underlying data. Data control features are provided, including authorization, integrity assertions, triggered transactions, a logging and recovery subsystem, and facilities for maintaining data consistency in a shared-update environment. This paper contains a description of the overall architecture and design of the system. At the present time the system is being implemented and the design evaluated. We emphasize that System R is a vehicle for research in database architecture, and is not planned as a product.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/astrahan1976system.html</link><guid isPermaLink="false">Literature Notes/astrahan1976system.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 10:58:14 GMT</pubDate></item><item><title><![CDATA[Eddies: Continuously adaptive query processing]]></title><description><![CDATA[ 
 <br><br>Ron Avnur, Joseph M Hellerstein (2000)<br>Tags: <br>Abstract
In large federated and shared-nothing databases, resources can exhibit widely fluctuating characteristics. Assumptions made at the time a query is submitted will rarely hold throughout the duration of query processing. As a result, traditional static query optimization and execution techniques are ineffective in these environments. In this paper we introduce a query processing mechanism called an eddy, which continuously reorders operators in a query plan as it runs. We characterize the moments of symmetry during which pipelined joins can be easily reordered, and the synchronization barriers that require inputs from different sources to be coordinated. By combining eddies with appropriate join algorithms, we merge the optimization and execution phases of query processing, allowing each tuple to have a flexible ordering of the query operators. This flexibility is controlled by a combination of fluid dynamics and a simple learning algorithm. Our initial implementation demonstrates promising results, with eddies performing nearly as well as a static optimizer/executor in static scenarios, and providing dramatic improvements in dynamic execution environments.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/avnur2000eddies.html</link><guid isPermaLink="false">Literature Notes/avnur2000eddies.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:53:28 GMT</pubDate></item><item><title><![CDATA[Highly available transactions: Virtues and limitations (extended version)]]></title><description><![CDATA[ 
 <br><br>Peter Bailis, Aaron Davidson, Alan Fekete, Ali Ghodsi, Joseph M Hellerstein, Ion Stoica (2013)<br>Tags: <br>Abstract
To minimize network latency and remain online during server failures and network partitions, many modern distributed data storage systems eschew transactional functionality, which provides strong semantic guarantees for groups of multiple operations over multiple data items. In this work, we consider the problem of providing Highly Available Transactions (HATs): transactional guarantees that do not suffer unavailability during system partitions or incur high network latency. We introduce a taxonomy of highly available systems and analyze existing ACID isolation and distributed data consistency guarantees to identify which can and cannot be achieved in HAT systems. This unifies the literature on weak transactional isolation, replica consistency, and highly available systems. We analytically and experimentally quantify the availability and performance benefits of HATs–often two to three orders of magnitude over wide-area networks–and discuss their necessary semantic compromises.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bailis2013highly.html</link><guid isPermaLink="false">Literature Notes/bailis2013highly.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:26:55 GMT</pubDate></item><item><title><![CDATA[Coordination avoidance in database systems (Extended version)]]></title><description><![CDATA[ 
 <br><br>Peter Bailis, Alan Fekete, Michael J Franklin, Ali Ghodsi, Joseph M Hellerstein, Ion Stoica (2014)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Bailis" class="tag" target="_blank" rel="noopener">#Peter-Bailis</a> <a href="https://jayitha.github.io/Notes?query=tag:Alan-Fekete" class="tag" target="_blank" rel="noopener">#Alan-Fekete</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael" class="tag" target="_blank" rel="noopener">#Michael</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Franklin" class="tag" target="_blank" rel="noopener">#J-Franklin</a> <a href="https://jayitha.github.io/Notes?query=tag:Ali-Ghodsi" class="tag" target="_blank" rel="noopener">#Ali-Ghodsi</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Ion-Stoica" class="tag" target="_blank" rel="noopener">#Ion-Stoica</a><br>Abstract
Minimizing coordination, or blocking communication between concurrently executing operations, is key to maximizing scalability, availability, and high performance in database systems. However, uninhibited coordination-free execution can compromise application correctness, or consistency. When is coordination necessary for correctness? The classic use of serializable transactions is sufficient to maintain correctness but is not necessary for all applications, sacrificing potential scalability. In this paper, we develop a formal framework, invariant confluence, that determines whether an application requires coordination for correct execution. By operating on application-level invariants over database states (e.g., integrity constraints), invariant confluence analysis provides a necessary and sufficient condition for safe, coordination-free execution. When programmers specify their application invariants, this analysis allows databases to coordinate only when anomalies that might violate invariants are possible. We analyze the invariant confluence of common invariants and operations from real-world database systems (i.e., integrity constraints) and applications and show that many are invariant confluent and therefore achievable without coordination. We apply these results to a proof-of-concept coordination-avoiding database prototype and demonstrate sizable performance gains compared to serializable execution, notably a 25-fold improvement over prior TPC-C New-Order performance on a 200 server cluster.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bailis2014coordination.html</link><guid isPermaLink="false">Literature Notes/bailis2014coordination.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:42:45 GMT</pubDate></item><item><title><![CDATA[Feral concurrency control: An empirical investigation of modern application integrity]]></title><description><![CDATA[ 
 <br><br>Peter Bailis, Alan Fekete, Michael J Franklin, Ali Ghodsi, Joseph M Hellerstein, Ion Stoica (2015)<br>Tags: <br>Abstract
The rise of data-intensive "Web 2.0" Internet services has led to a range of popular new programming frameworks that collectively embody the latest incarnation of the vision of Object-Relational Mapping (ORM) systems, albeit at unprecedented scale. In this work, we empirically investigate modern ORM-backed applications' use and disuse of database concurrency control mechanisms. Specifically, we focus our study on the common use of feral, or application-level, mechanisms for maintaining database integrity, which, across a range of ORM systems, often take the form of declarative correctness criteria, or invariants. We quantitatively analyze the use of these mechanisms in a range of open source applications written using the Ruby on Rails ORM and find that feral invariants are the most popular means of ensuring integrity (and, by usage, are over 37 times more popular than transactions). We evaluate which of these feral invariants actually ensure integrity (by usage, up to 86.9%) and which—due to concurrency errors and lack of database support—may lead to data corruption (the remainder), which we experimentally quantify. In light of these findings, we present recommendations for database system designers for better supporting these modern ORM programming patterns, thus eliminating their adverse effects on application integrity.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bailis2015feral.html</link><guid isPermaLink="false">Literature Notes/bailis2015feral.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:53 GMT</pubDate></item><item><title><![CDATA[Scalable atomic visibility with RAMP transactions]]></title><description><![CDATA[ 
 <br><br>Peter Bailis, Alan Fekete, Ali Ghodsi, Joseph M Hellerstein, Ion Stoica (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Bailis" class="tag" target="_blank" rel="noopener">#Peter-Bailis</a> <a href="https://jayitha.github.io/Notes?query=tag:Alan-Fekete" class="tag" target="_blank" rel="noopener">#Alan-Fekete</a> <a href="https://jayitha.github.io/Notes?query=tag:Ali-Ghodsi" class="tag" target="_blank" rel="noopener">#Ali-Ghodsi</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Ion-Stoica" class="tag" target="_blank" rel="noopener">#Ion-Stoica</a><br>Abstract
Databases can provide scalability by partitioning data across several servers. However, multipartition, multioperation transactional access is often expensive, employing coordination-intensive locking, validation, or scheduling mechanisms. Accordingly, many real-world systems avoid mechanisms that provide useful semantics for multipartition operations. This leads to incorrect behavior for a large class of applications including secondary indexing, foreign key enforcement, and materialized view maintenance. In this work, we identify a new isolation model—Read Atomic (RA) isolation—that matches the requirements of these use cases by ensuring atomic visibility: either all or none of each transaction's updates are observed by other transactions. We present algorithms for Read Atomic Multipartition (RAMP) transactions that enforce atomic visibility while offering excellent scalability, guaranteed commit despite partial failures (via coordination-free execution), and minimized communication between servers (via partition independence). These RAMP transactions correctly mediate atomic visibility of updates and provide readers with snapshot access to database state by using limited multiversioning and by allowing clients to independently resolve nonatomic reads. We demonstrate that, in contrast with existing algorithms, RAMP transactions incur limited overhead—even under high contention—and scale linearly to 100 servers.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bailis2016scalable.html</link><guid isPermaLink="false">Literature Notes/bailis2016scalable.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:43:55 GMT</pubDate></item><item><title><![CDATA[To partition, or not to partition, that is the join question in a real system]]></title><description><![CDATA[ 
 <br><br>Maximilian Bandle, Jana Giceva, Thomas Neumann (2021)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Maximilian-Bandle" class="tag" target="_blank" rel="noopener">#Maximilian-Bandle</a> <a href="https://jayitha.github.io/Notes?query=tag:Jana-Giceva" class="tag" target="_blank" rel="noopener">#Jana-Giceva</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a><br>Abstract
An efficient implementation of a hash join has been a highly researched problem for decades. Recently, the radix join has been shown to have superior performance over the alternatives (e.g., the non-partitioned hash join), albeit on synthetic microbenchmarks. Therefore, it is unclear whether one can simply replace the hash join in an RDBMS or use the radix join as a performance booster for selected queries. If the latter, it is still unknown when one should rely on the radix join to improve performance. In this paper, we address these questions, show how to integrate the radix join in Umbra, a code-generating DBMS, and make it competitive for selective queries by introducing a Bloom-filter based semi-join reducer. We have evaluated how well it runs when used in queries from more representative workloads like TPC-H. Surprisingly, the radix join brings a noticeable improvement in only one out of all 59 joins in TPC-H. Thus, with an extensive range of microbenchmarks, we have isolated the effects of the most important workload factors and synthesized the range of values where partitioning the data for the radix join pays off. Our analysis shows that the benefit of data partitioning quickly diminishes as soon as we deviate from the optimal parameters, and even late materialization rarely helps in real workloads. We thus, conclude that integrating the radix join within a code-generating database rarely justifies the increase in code and optimizer complexity and advise against it for processing real-world workloads.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bandle2021partition.html</link><guid isPermaLink="false">Literature Notes/bandle2021partition.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:07 GMT</pubDate></item><item><title><![CDATA[Xen and the art of virtualization]]></title><description><![CDATA[ 
 <br><br>Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, Andrew Warfield (2003)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Paul-Barham" class="tag" target="_blank" rel="noopener">#Paul-Barham</a> <a href="https://jayitha.github.io/Notes?query=tag:Boris-Dragovic" class="tag" target="_blank" rel="noopener">#Boris-Dragovic</a> <a href="https://jayitha.github.io/Notes?query=tag:Keir-Fraser" class="tag" target="_blank" rel="noopener">#Keir-Fraser</a> <a href="https://jayitha.github.io/Notes?query=tag:Steven-Hand" class="tag" target="_blank" rel="noopener">#Steven-Hand</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Harris" class="tag" target="_blank" rel="noopener">#Tim-Harris</a> <a href="https://jayitha.github.io/Notes?query=tag:Alex-Ho" class="tag" target="_blank" rel="noopener">#Alex-Ho</a> <a href="https://jayitha.github.io/Notes?query=tag:Rolf-Neugebauer" class="tag" target="_blank" rel="noopener">#Rolf-Neugebauer</a> <a href="https://jayitha.github.io/Notes?query=tag:Ian-Pratt" class="tag" target="_blank" rel="noopener">#Ian-Pratt</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Warfield" class="tag" target="_blank" rel="noopener">#Andrew-Warfield</a><br>Abstract
Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be ported with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead — at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/barham2003xen.html</link><guid isPermaLink="false">Literature Notes/barham2003xen.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:04 GMT</pubDate></item><item><title><![CDATA[Implementing constant-bandwidth servers upon multiprocessor platforms]]></title><description><![CDATA[ 
 <br><br>Sanjoy Baruah, Joël Goossens, Giuseppe Lipari (2002)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanjoy-Baruah" class="tag" target="_blank" rel="noopener">#Sanjoy-Baruah</a> <a href="https://jayitha.github.io/Notes?query=tag:Joël-Goossens" class="tag" target="_blank" rel="noopener">#Joël-Goossens</a> <a href="https://jayitha.github.io/Notes?query=tag:Giuseppe-Lipari" class="tag" target="_blank" rel="noopener">#Giuseppe-Lipari</a><br>Abstract
In constant-bandwidth server (CBS) systems, several different applications are executed upon a shared computing platform in such a manner that each application seems to be executing on a slower dedicated processor. CBS systems have thus far only been implemented upon uniprocessors; here, a multiprocessor extension, which can be implemented upon computing platforms comprised of several identical preemptable processors, is proposed and proven correct.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/baruah2002implementing.html</link><guid isPermaLink="false">Literature Notes/baruah2002implementing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:50:06 GMT</pubDate></item><item><title><![CDATA[Finding a needle in haystack: Facebook's photo storage]]></title><description><![CDATA[ 
 <br><br>Doug Beaver, Sanjeev Kumar, Harry C Li, Jason Sobel, Peter Vajgel (2010)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/beaver2010finding.html</link><guid isPermaLink="false">Literature Notes/beaver2010finding.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:17:33 GMT</pubDate></item><item><title><![CDATA[The pyramid-technique: Towards breaking the curse of dimensionality]]></title><description><![CDATA[ 
 <br><br>Stefan Berchtold, Christian Böhm, Hans-Peter Kriegal (1998)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a><br>Abstract
In this paper, we propose the Pyramid-Technique, a new indexing method for high-dimensional data spaces. The Pyramid-Technique is highly adapted to range query processing using the maximum metric Lmax. In contrast to all other index structures, the performance of the Pyramid-Technique does not deteriorate when processing range queries on data of higher dimensionality. The Pyramid-Technique is based on a special partitioning strategy which is optimized for high-dimensional data. The basic idea is to divide the data space first into 2d pyramids sharing the center point of the space as a top. In a second step, the single pyramids are cut into slices parallel to the basis of the pyramid. These slices from the data pages. Furthermore, we show that this partition provides a mapping from the given d-dimensional space to a 1-dimensional space. Therefore, we are able to use a B+-tree to manage the transformed data. As an analytical evaluation of our technique for hypercube range queries and uniform data distribution shows, the Pyramid-Technique clearly outperforms index structures using other partitioning strategies. To demonstrate the practical relevance of our technique, we experimentally compared the Pyramid-Technique with the X-tree, the Hilbert R-tree, and the Linear Scan. The results of our experiments using both, synthetic and real data, demonstrate that the Pyramid-Technique outperforms the X-tree and the Hilbert R-tree by a factor of up to 14 (number of page accesses) and up to 2500 (total elapsed time) for range queries.
<br>
<br>Proposes <a data-href="Pyramid Technique" href="https://jayitha.github.io/Notes/glossary/pyramid-technique.html" class="internal-link" target="_self" rel="noopener">Pyramid Technique</a>
<br>None of the existing indexing techniques that provide good performance for low-dimensional data perform well for high dimensional data because of the <a data-href="Curse of Dimensionality" href="https://jayitha.github.io/Notes/glossary/curse-of-dimensionality.html" class="internal-link" target="_self" rel="noopener">Curse of Dimensionality</a>
<br>Most existing high dimensional approaches (at that time) were extensions of multidimensional indices and therefore restricted to space partitioning
<br>An interesting observation this paper makes is that the 50%-quantile splitting strategy that most prior indexing strategies used to ensure storage utilization guarantees performs poorly in high-dimensions because the access probability of pages is close to 100%
]]></description><link>https://jayitha.github.io/Notes/literature-notes/berchtold1998pyramid.html</link><guid isPermaLink="false">Literature Notes/berchtold1998pyramid.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 06 Nov 2023 10:04:51 GMT</pubDate></item><item><title><![CDATA[A critique of ANSI SQL isolation levels]]></title><description><![CDATA[ 
 <br><br>Hal Berenson, Phil Bernstein, Jim Gray, Jim Melton, Elizabeth O'Neil, Patrick O'Neil (1995)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Hal-Berenson" class="tag" target="_blank" rel="noopener">#Hal-Berenson</a> <a href="https://jayitha.github.io/Notes?query=tag:Phil-Bernstein" class="tag" target="_blank" rel="noopener">#Phil-Bernstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Jim-Gray" class="tag" target="_blank" rel="noopener">#Jim-Gray</a> <a href="https://jayitha.github.io/Notes?query=tag:Jim-Melton" class="tag" target="_blank" rel="noopener">#Jim-Melton</a> <a href="https://jayitha.github.io/Notes?query=tag:Elizabeth-O" class="tag" target="_blank" rel="noopener">#Elizabeth-O</a>'Neil <a href="https://jayitha.github.io/Notes?query=tag:Patrick-O" class="tag" target="_blank" rel="noopener">#Patrick-O</a>'Neil<br>Abstract
ANSI SQL-92 [MS, ANSI] defines Isolation Levels in terms of phenomena: Dirty Reads, Non-Repeatable Reads, and Phantoms. This paper shows that these phenomena and the ANSI SQL definitions fail to properly characterize several popular isolation levels, including the standard locking implementations of the levels covered. Ambiguity in the statement of the phenomena is investigated and a more formal statement is arrived at; in addition new phenomena that better characterize isolation types are introduced. Finally, an important multiversion isolation type, called Snapshot Isolation, is defined.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/berenson1995critique.html</link><guid isPermaLink="false">Literature Notes/berenson1995critique.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:33:23 GMT</pubDate></item><item><title><![CDATA[Concurrency control in distributed database systems]]></title><description><![CDATA[ 
 <br><br>Philip A Bernstein, Nathan Goodman (1981)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Philip" class="tag" target="_blank" rel="noopener">#Philip</a> <a href="https://jayitha.github.io/Notes?query=tag:A-Bernstein" class="tag" target="_blank" rel="noopener">#A-Bernstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Nathan-Goodman" class="tag" target="_blank" rel="noopener">#Nathan-Goodman</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/bernstein1981concurrency.html</link><guid isPermaLink="false">Literature Notes/bernstein1981concurrency.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:01:40 GMT</pubDate></item><item><title><![CDATA[Orleans: Distributed virtual actors for programmability and scalability]]></title><description><![CDATA[ 
 <br><br>Phil Bernstein, Sergey Bykov, Alan Geller, Gabriel Kliot, Jorgen Thelin (2014)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/bernstein2014orleans.html</link><guid isPermaLink="false">Literature Notes/bernstein2014orleans.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:46 GMT</pubDate></item><item><title><![CDATA[SPIN: An extensible microkernel for application-specific operating system services]]></title><description><![CDATA[ 
 <br><br>Brian N Bershad, Craig Chambers, Susan Eggers, Chris Maeda, Dylan McNamee, Przemyslaw Pardyak, Stefan Savage, Emin Gün Sirer (1994)<br>Tags: <br>Abstract
Application domains such as multimedia, databases, and parallel computing, require operating system services with high performance and high functionality. Existing operating systems provide fixed interfaces and implementations to system services and resources. This makes them inappropriate for applications whose resource demands and usage patterns are poorly matched by the services provided. The SPIN operating system enables system services to be defined in an application-specific fashion through an extensible microkernel. It offers applications fine-grained control over a machine's logical and physical resources through run-time adaptation of the system to application requirements.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bershad1994spin.html</link><guid isPermaLink="false">Literature Notes/bershad1994spin.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:08 GMT</pubDate></item><item><title><![CDATA[When is “Nearest neighbor” meaningful?]]></title><description><![CDATA[ 
 <br><br>Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, Uri Shaft (1999)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Kevin-Beyer" class="tag" target="_blank" rel="noopener">#Kevin-Beyer</a> <a href="https://jayitha.github.io/Notes?query=tag:Jonathan-Goldstein" class="tag" target="_blank" rel="noopener">#Jonathan-Goldstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Raghu-Ramakrishnan" class="tag" target="_blank" rel="noopener">#Raghu-Ramakrishnan</a> <a href="https://jayitha.github.io/Notes?query=tag:Uri-Shaft" class="tag" target="_blank" rel="noopener">#Uri-Shaft</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
We explore the effect of dimensionality on the “nearest neighbor” problem. We show that under a broad set of conditions (much broader than independent and identically distributed dimensions), as dimensionality increases, the distance to the nearest data point approaches the distance to the farthest data point. To provide a practical perspective, we present empirical results on both real and synthetic data sets that demonstrate that this effect can occur for as few as 10–15 dimensions. These results should not be interpreted to mean that high-dimensional indexing is never meaningful; we illustrate this point by identifying some high-dimensional workloads for which this effect does not occur. However, our results do emphasize that the methodology used almost universally in the database literature to evaluate high-dimensional indexing techniques is flawed, and should be modified. In particular, most such techniques proposed in the literature are not evaluated versus simple linear scan, and are evaluated over workloads for which nearest neighbor is not meaningful. Often, even the reported experiments, when analyzed carefully, show that linear scan would outperform the techniques being proposed on the workloads studied in high (10–15) dimensionality!
<br>
<br><a data-href="Unstable Nearest Neighbor Query" href="https://jayitha.github.io/Notes/glossary/unstable-nearest-neighbor-query.html" class="internal-link" target="_self" rel="noopener">Unstable Nearest Neighbor Query</a>
<br><a data-href="Converges in Probability" href="https://jayitha.github.io/Notes/glossary/converges-in-probability.html" class="internal-link" target="_self" rel="noopener">Converges in Probability</a>
<br><a data-href="Slutsky's Theorem" href="https://jayitha.github.io/Notes/glossary/slutsky's-theorem.html" class="internal-link" target="_self" rel="noopener">Slutsky's Theorem</a>
<br><a data-href="Weak Law of Large Numbers" href="https://jayitha.github.io/Notes/glossary/weak-law-of-large-numbers.html" class="internal-link" target="_self" rel="noopener">Weak Law of Large Numbers</a>
<br>Notation:<br><br>Instability Result
If<br>
Then for every <br>

<br>If the distance distribution behaves a certain way as  increases (which is apparently common), then according to the <a data-tooltip-position="top" aria-label="^1318ad" data-href="#^1318ad" href="https://jayitha.github.io/Notes/#^1318ad" class="internal-link" target="_self" rel="noopener">Instability Result</a>, all points converge to the same distance from the query point<br>Posted question <a data-tooltip-position="top" aria-label="https://hackmd.io/@PjzB85_5Tum5GEZrVPegjw/BJZVZhrRp" rel="noopener" class="external-link" href="https://hackmd.io/@PjzB85_5Tum5GEZrVPegjw/BJZVZhrRp" target="_blank">here</a>]]></description><link>https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html</link><guid isPermaLink="false">Literature Notes/beyer1999nearest.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 18 Mar 2024 14:37:39 GMT</pubDate></item><item><title><![CDATA[Cilk: An efficient multithreaded runtime system]]></title><description><![CDATA[ 
 <br><br>Robert D Blumofe, Christopher F Joerg, Bradley C Kuszmaul, Charles E Leiserson, Keith H Randall, Yuli Zhou (1995)<br>Tags: <br>Abstract
Cilk (pronounced “silk”) is a C-based runtime system for multi-threaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the “work” and “critical path” of a Cilk computation can be used to accurately model performance. Consequently, a Cilk programmer can focus on reducing the work and critical path of his computation, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of “fully strict” (well-structured) programs, the Cilk scheduler achieves space, time and communication bounds all within a constant factor of optimal. The Cilk runtime system currently runs on the Connection Machine CM5 MPP, the Intel Paragon MPP, the Silicon Graphics Power Challenge SMP, and the MIT Phish network of workstations. Applications written in Cilk include protein folding, graphic rendering, backtrack search, and the *Socrates chess program, which won third prize in the 1994 ACM International Computer Chess Championship.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/blumofe1995cilk.html</link><guid isPermaLink="false">Literature Notes/blumofe1995cilk.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:26 GMT</pubDate></item><item><title><![CDATA[Rust temporary lifetimes and "Super Let"]]></title><description><![CDATA[ 
 <br><br>Mara Bos (2023)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:read" class="tag" target="_blank" rel="noopener">#read</a><br>Abstract
The lifetime of temporaries in Rust is a complicated but often ignored topic. In simple cases, Rust keeps temporaries around for exactly long enough, such that we don't have to think about them. However, there are plenty of cases were we might not get exactly what we want, right away. In this post, we (re)discover the rules for the lifetime of temporaries, go over a few use cases for temporary lifetime extension, and explore a new language idea, super let, to give us more control.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bos2023rust.html</link><guid isPermaLink="false">Literature Notes/bos2023rust.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 04 Dec 2023 06:12:31 GMT</pubDate></item><item><title><![CDATA[CAP twelve years later: How the" Rules" have changed]]></title><description><![CDATA[ 
 <br><br>Eric Brewer (2012)<br>Tags: <br>Abstract
The CAP theorem asserts that any networked shared-data system can have only two of three desirable properties. However, by explicitly handling partitions, designers can optimize consistency and availability, thereby achieving some trade-off of all three. The featured Web extra is a podcast from Software Engineering Radio, in which the host interviews Dwight Merriman about the emerging NoSQL movement, the three types of nonrelational data stores, Brewer's CAP theorem, and much more.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/brewer2012cap.html</link><guid isPermaLink="false">Literature Notes/brewer2012cap.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:30:09 GMT</pubDate></item><item><title><![CDATA[Making databases work: The pragmatic wisdom of Michael Stonebraker]]></title><description><![CDATA[ 
 <br><br>Michael L Brodie (2018)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael" class="tag" target="_blank" rel="noopener">#Michael</a> <a href="https://jayitha.github.io/Notes?query=tag:L-Brodie" class="tag" target="_blank" rel="noopener">#L-Brodie</a><br>Abstract
At the ACM Awards banquet in June 2017, during the 50th anniversary celebration of the A.M. Turing Award, ACM announced the launch of the ACM A.M. Turing Book Series, a sub-series of ACM Books, to celebrate the winners of the A.M. Turing Award, computing's highest honor, the "Nobel Prize" for computing. This series aims to highlight the accomplishments of awardees, explaining their major contributions of lasting importance in computing. "Making Databases Work: The Pragmatic Wisdom of Michael Stonebraker," the first book in the series, celebrates Mike's contributions and impact. What accomplishments warranted computing's highest honor? How did Stonebraker do it? Who is Mike Stonebraker—researcher, professor, CTO, lecturer, innovative product developer, serial entrepreneur, and decades-long leader, and research evangelist for the database community. This book describes Mike's many contributions and evaluates them in light of the Turing Award. The book describes, in 36 chapters, the unique nature, significance, and impact of Mike's achievements in advancing modern database systems over more than 40 years. The stories involve technical concepts, projects, people, prototype systems, failures, lucky accidents, crazy risks, startups, products, venture capital, and lots of applications that drove Mike Stonebraker's achievements and career. Even if you have no interest in databases at all, you'll gain insights into the birth and evolution of Turing Award-worthy achievements from the perspectives of 39 remarkable computer scientists and professionals. Today, data is considered the world's most valuable resource ("The Economist," May 6, 2017), whether it is in the tens of millions of databases used to manage the world's businesses and governments, in the billions of databases in our smartphones and watches, or residing elsewhere, as yet unmanaged, awaiting the elusive next generation of database systems. Every one of the millions or billions of databases includes features that are celebrated by the 2014 A.M. Turing Award and are described in this book.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/brodie2018making.html</link><guid isPermaLink="false">Literature Notes/brodie2018making.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:12:14 GMT</pubDate></item><item><title><![CDATA[Teaching an old elephant new tricks]]></title><description><![CDATA[ 
 <br><br>Nicolas Bruno (2009)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Nicolas-Bruno" class="tag" target="_blank" rel="noopener">#Nicolas-Bruno</a><br>Abstract
In recent years, column stores (or C-stores for short) have emerged as a novel approach to deal with read-mostly data warehousing applications. Experimental evidence suggests that, for certain types of queries, the new features of C-stores result in orders of magnitude improvement over traditional relational engines. At the same time, some C-store proponents argue that C-stores are fundamentally different from traditional engines, and therefore their benefits cannot be incorporated into a relational engine short of a complete rewrite. In this paper we challenge this claim and show that many of the benefits of C-stores can indeed be simulated in traditional engines with no changes whatsoever. We then identify some limitations of our ?pure-simulation? approach for the case of more complex queries. Finally, we predict that traditional relational engines will eventually leverage most of the benefits of C-stores natively, as is currently happening in other domains such as XML data.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bruno2009teaching.html</link><guid isPermaLink="false">Literature Notes/bruno2009teaching.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:42 GMT</pubDate></item><item><title><![CDATA[Disco: Running commodity operating systems on scalable multiprocessors]]></title><description><![CDATA[ 
 <br><br>Edouard Bugnion, Scott Devine, Kinshuk Govil, Mendel Rosenblum (1997)<br>Tags: <br>Abstract
In this article we examine the problem of extending modern operating systems to run efficiently on large-scale shared-memory multiprocessors without a large implementation effort. Our approach brings back an idea popular in the 1970s: virtual machine monitors. We use virtual machines to run multiple commodity operating systems on a scalable multiprocessor. This solution addresses many of the challenges facing the system software for these machines. We demonstrate our approach with a prototype called Disco that runs multiple copies of Silicon Graphics' IRIX operating system on a multiprocessor. Our experience shows that the overheads of the monitor are small and that the approach provides scalability as well as the ability to deal with the nonuniform memory access time of these systems. To reduce the memory overheads associated with running multiple operating systems, virtual machines transparently share major data structures such as the program code and the file system buffer cache. We use the distributed-system support of modern operating systems to export a partial single system image to the users. The overall solution achieves most of the benefits of operating systems customized for scalable multiprocessors, yet it can be achieved with a significantly smaller implementation effort.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/bugnion1997disco.html</link><guid isPermaLink="false">Literature Notes/bugnion1997disco.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:57 GMT</pubDate></item><item><title><![CDATA[The Chubby lock service for loosely-coupled distributed systems]]></title><description><![CDATA[ 
 <br><br>Mike Burrows (2006)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mike-Burrows" class="tag" target="_blank" rel="noopener">#Mike-Burrows</a><br>Abstract
We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. Chubby provides an interface much like a distributed file system with advisory locks, but the design emphasis is on availability and reliability, as opposed to high performance. Many instances of the service have been used for over a year, with several of them each handling a few tens of thousands of clients concurrently. The paper describes the initial design and expected use, compares it with actual use, and explains how the design had to be modified to accommodate the differences.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/burrows2006chubby.html</link><guid isPermaLink="false">Literature Notes/burrows2006chubby.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:29 GMT</pubDate></item><item><title><![CDATA[The architecture of the EXODUS extensible DBMS]]></title><description><![CDATA[ 
 <br><br>Michael J Carey, David J DeWitt, Daniel Frank, Goetz Graefe, Joel E Richardson, Eugene J Shekita, M Muralikrlshna (1991)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael" class="tag" target="_blank" rel="noopener">#Michael</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Carey" class="tag" target="_blank" rel="noopener">#J-Carey</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:J-DeWitt" class="tag" target="_blank" rel="noopener">#J-DeWitt</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel-Frank" class="tag" target="_blank" rel="noopener">#Daniel-Frank</a> <a href="https://jayitha.github.io/Notes?query=tag:Goetz-Graefe" class="tag" target="_blank" rel="noopener">#Goetz-Graefe</a> <a href="https://jayitha.github.io/Notes?query=tag:Joel" class="tag" target="_blank" rel="noopener">#Joel</a> <a href="https://jayitha.github.io/Notes?query=tag:E-Richardson" class="tag" target="_blank" rel="noopener">#E-Richardson</a> <a href="https://jayitha.github.io/Notes?query=tag:Eugene" class="tag" target="_blank" rel="noopener">#Eugene</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Shekita" class="tag" target="_blank" rel="noopener">#J-Shekita</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Muralikrlshna" class="tag" target="_blank" rel="noopener">#M-Muralikrlshna</a><br>Abstract
With non-traditional application areas such as engineering design, image/voice data management, scientific/statistical applications, and artificial intelligence systems all clamoring for ways to store and efficiently process larger and larger volumes of data, it is clear that traditional database technology has been pushed to its limits. It also seems clear that no single database system will be capable of simultaneously meeting the functionality and performance requirements of such a diverse set of applications. In this paper we describe the initial design of EXODUS, an extensible database system that will facilitate the fast development of high-performance, application-specific database systems. EXODUS provides certain kernel facilities, including a versatile storage manager and a type manager. In addition, it provides an architectural framework for building application-specific database systems, tools to partially automate the generation of such systems, and libraries of software components (e.g., access methods) that are likely to be useful for many application domains.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/carey1991architecture.html</link><guid isPermaLink="false">Literature Notes/carey1991architecture.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:59:39 GMT</pubDate></item><item><title><![CDATA[Practical byzantine fault tolerance]]></title><description><![CDATA[ 
 <br><br>Miguel Castro, Barbara Liskov, others (1999)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Miguel-Castro" class="tag" target="_blank" rel="noopener">#Miguel-Castro</a> <a href="https://jayitha.github.io/Notes?query=tag:Barbara-Liskov" class="tag" target="_blank" rel="noopener">#Barbara-Liskov</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/castro1999practical.html</link><guid isPermaLink="false">Literature Notes/castro1999practical.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:49 GMT</pubDate></item><item><title><![CDATA[Proactive recovery in a {byzantine-Fault-Tolerant} system]]></title><description><![CDATA[ 
 <br><br>Miguel Castro, Barbara Liskov (2000)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Miguel-Castro" class="tag" target="_blank" rel="noopener">#Miguel-Castro</a> <a href="https://jayitha.github.io/Notes?query=tag:Barbara-Liskov" class="tag" target="_blank" rel="noopener">#Barbara-Liskov</a><br>Abstract
This paper describes an asynchronous state-machine replication system that tolerates Byzantine faults, which can be caused by malicious attacks or software errors. Our system is the first to recover Byzantine-faulty replicas proactively and it performs well because it uses symmetric rather than public-key cryptography for authentication. The recovery mechanism allows us to tolerate any number of faults over the lifetime of the system provided fewer than 1/3 of the replicas become faulty within a window of vulnerability that is small under normal conditions. The window may increase under a denial-of-service attack but we can detect and respond to such attacks. The paper presents results of experiments showing that overall performance is good and that even a small window of vulnerability has little impact on service latency.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/castro2000proactive.html</link><guid isPermaLink="false">Literature Notes/castro2000proactive.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:03 GMT</pubDate></item><item><title><![CDATA[SEQUEL: A structured english query language]]></title><description><![CDATA[ 
 <br><br>Donald D Chamberlin, Raymond F Boyce (1974)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Donald" class="tag" target="_blank" rel="noopener">#Donald</a> <a href="https://jayitha.github.io/Notes?query=tag:D-Chamberlin" class="tag" target="_blank" rel="noopener">#D-Chamberlin</a> <a href="https://jayitha.github.io/Notes?query=tag:Raymond" class="tag" target="_blank" rel="noopener">#Raymond</a> <a href="https://jayitha.github.io/Notes?query=tag:F-Boyce" class="tag" target="_blank" rel="noopener">#F-Boyce</a><br>Abstract
In this paper we present the data manipulation facility for a structured English query language (SEQUEL) which can be used for accessing data in an integrated relational data base. Without resorting to the concepts of bound variables and quantifiers SEQUEL identifies a set of simple operations on tabular structures, which can be shown to be of equivalent power to the first order predicate calculus. A SEQUEL user is presented with a consistent set of keyword English templates which reflect how people use tables to obtain information. Moreover, the SEQUEL user is able to compose these basic templates in a structured manner in order to form more complex queries. SEQUEL is intended as a data base sublanguage for both the professional programmer and the more infrequent data base user.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/chamberlin1974sequel.html</link><guid isPermaLink="false">Literature Notes/chamberlin1974sequel.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:24:46 GMT</pubDate></item><item><title><![CDATA[Views, authorization, and locking in a relational data base system]]></title><description><![CDATA[ 
 <br><br>Donald D Chamberlin, Jim N Gray, Irving L Traiger (1975)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Donald" class="tag" target="_blank" rel="noopener">#Donald</a> <a href="https://jayitha.github.io/Notes?query=tag:D-Chamberlin" class="tag" target="_blank" rel="noopener">#D-Chamberlin</a> <a href="https://jayitha.github.io/Notes?query=tag:Jim" class="tag" target="_blank" rel="noopener">#Jim</a> <a href="https://jayitha.github.io/Notes?query=tag:N-Gray" class="tag" target="_blank" rel="noopener">#N-Gray</a> <a href="https://jayitha.github.io/Notes?query=tag:Irving" class="tag" target="_blank" rel="noopener">#Irving</a> <a href="https://jayitha.github.io/Notes?query=tag:L-Traiger" class="tag" target="_blank" rel="noopener">#L-Traiger</a><br>Abstract
In the interest of brevity we assume that the reader is familiar with the notion of a relational data base. In particular, we assume a familiarity with the work of Codd or Boyce and Chamberlin. The examples in this paper will be drawn from a data base which describes a department store and consists of three relations: EMP(NAME, SAL, MGR, DEPT) SALES(DEPT, ITEM, VOL) LOC(DEPT, FLOOR)
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chamberlin1975views.html</link><guid isPermaLink="false">Literature Notes/chamberlin1975views.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 10:55:36 GMT</pubDate></item><item><title><![CDATA[A history and evaluation of System R]]></title><description><![CDATA[ 
 <br><br>Donald D Chamberlin, Morton M Astrahan, Michael W Blasgen, James N Gray, W Frank King, Bruce G Lindsay, Raymond Lorie, James W Mehl, Thomas G Price, Franco Putzolu, others (1981)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Donald" class="tag" target="_blank" rel="noopener">#Donald</a> <a href="https://jayitha.github.io/Notes?query=tag:D-Chamberlin" class="tag" target="_blank" rel="noopener">#D-Chamberlin</a> <a href="https://jayitha.github.io/Notes?query=tag:Morton" class="tag" target="_blank" rel="noopener">#Morton</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Astrahan" class="tag" target="_blank" rel="noopener">#M-Astrahan</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael" class="tag" target="_blank" rel="noopener">#Michael</a> <a href="https://jayitha.github.io/Notes?query=tag:W-Blasgen" class="tag" target="_blank" rel="noopener">#W-Blasgen</a> <a href="https://jayitha.github.io/Notes?query=tag:James" class="tag" target="_blank" rel="noopener">#James</a> <a href="https://jayitha.github.io/Notes?query=tag:N-Gray" class="tag" target="_blank" rel="noopener">#N-Gray</a> <a href="https://jayitha.github.io/Notes?query=tag:W" class="tag" target="_blank" rel="noopener">#W</a> <a href="https://jayitha.github.io/Notes?query=tag:Frank-King" class="tag" target="_blank" rel="noopener">#Frank-King</a> <a href="https://jayitha.github.io/Notes?query=tag:Bruce" class="tag" target="_blank" rel="noopener">#Bruce</a> <a href="https://jayitha.github.io/Notes?query=tag:G-Lindsay" class="tag" target="_blank" rel="noopener">#G-Lindsay</a> <a href="https://jayitha.github.io/Notes?query=tag:Raymond-Lorie" class="tag" target="_blank" rel="noopener">#Raymond-Lorie</a> <a href="https://jayitha.github.io/Notes?query=tag:W-Mehl" class="tag" target="_blank" rel="noopener">#W-Mehl</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas" class="tag" target="_blank" rel="noopener">#Thomas</a> <a href="https://jayitha.github.io/Notes?query=tag:G-Price" class="tag" target="_blank" rel="noopener">#G-Price</a> <a href="https://jayitha.github.io/Notes?query=tag:Franco-Putzolu" class="tag" target="_blank" rel="noopener">#Franco-Putzolu</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract
System R, an experimental database system, was constructed to demonstrate that the usability advantages of the relational data model can be realized in a system with the complete function and high performance required for everyday production use. This paper describes the three principal phases of the System R project and discusses some of the lessons learned from System R about the design of relational systems and database systems in general.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chamberlin1981history.html</link><guid isPermaLink="false">Literature Notes/chamberlin1981history.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:07:13 GMT</pubDate></item><item><title><![CDATA[Paxos made live: An engineering perspective]]></title><description><![CDATA[ 
 <br><br>Tushar D Chandra, Robert Griesemer, Joshua Redstone (2007)<br>Tags: <br>Abstract
We describe our experience in building a fault-tolerant data-base using the Paxos consensus algorithm. Despite the existing literature in the field, building such a database proved to be non-trivial. We describe selected algorithmic and engineering problems encountered, and the solutions we found for them. Our measurements indicate that we have built a competitive system.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chandra2007paxos.html</link><guid isPermaLink="false">Literature Notes/chandra2007paxos.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:07 GMT</pubDate></item><item><title><![CDATA[Bigtable: A distributed storage system for structured data]]></title><description><![CDATA[ 
 <br><br>Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C Hsieh, Deborah A Wallach, Mike Burrows, Tushar Chandra, Andrew Fikes, Robert E Gruber (2008)<br>Tags: <br>Abstract
Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this article, we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chang2008bigtable.html</link><guid isPermaLink="false">Literature Notes/chang2008bigtable.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:20 GMT</pubDate></item><item><title><![CDATA[Using Crash Hoare logic for certifying the FSCQ file system]]></title><description><![CDATA[ 
 <br><br>Haogang Chen, Daniel Ziegler, Tej Chajed, Adam Chlipala, M Frans Kaashoek, Nickolai Zeldovich (2015)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Haogang-Chen" class="tag" target="_blank" rel="noopener">#Haogang-Chen</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel-Ziegler" class="tag" target="_blank" rel="noopener">#Daniel-Ziegler</a> <a href="https://jayitha.github.io/Notes?query=tag:Tej-Chajed" class="tag" target="_blank" rel="noopener">#Tej-Chajed</a> <a href="https://jayitha.github.io/Notes?query=tag:Adam-Chlipala" class="tag" target="_blank" rel="noopener">#Adam-Chlipala</a> <a href="https://jayitha.github.io/Notes?query=tag:M" class="tag" target="_blank" rel="noopener">#M</a> <a href="https://jayitha.github.io/Notes?query=tag:Frans-Kaashoek" class="tag" target="_blank" rel="noopener">#Frans-Kaashoek</a> <a href="https://jayitha.github.io/Notes?query=tag:Nickolai-Zeldovich" class="tag" target="_blank" rel="noopener">#Nickolai-Zeldovich</a><br>Abstract
FSCQ is the first file system with a machine-checkable proof (using the Coq proof assistant) that its implementation meets its specification and whose specification includes crashes. FSCQ provably avoids bugs that have plagued previous file systems, such as performing disk writes without sufficient barriers or forgetting to zero out directory blocks. If a crash happens at an inopportune time, these bugs can lead to data loss. FSCQ's theorems prove that, under any sequence of crashes followed by reboots, FSCQ will recover the file system correctly without losing data. To state FSCQ's theorems, this paper introduces the Crash Hoare logic (CHL), which extends traditional Hoare logic with a crash condition, a recovery procedure, and logical address spaces for specifying disk states at different abstraction levels. CHL also reduces the proof effort for developers through proof automation. Using CHL, we developed, specified, and proved the correctness of the FSCQ file system. Although FSCQ's design is relatively simple, experiments with FSCQ running as a user-level file system show that it is sufficient to run Unix applications with usable performance. FSCQ's specifications and proofs required significantly more work than the implementation, but the work was manageable even for a small team of a few researchers.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chen2015using.html</link><guid isPermaLink="false">Literature Notes/chen2015using.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:56 GMT</pubDate></item><item><title><![CDATA[Optimizing database-backed applications with query synthesis]]></title><description><![CDATA[ 
 <br><br>Alvin Cheung, Armando Solar-Lezama, Samuel Madden (2013)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Alvin-Cheung" class="tag" target="_blank" rel="noopener">#Alvin-Cheung</a> <a href="https://jayitha.github.io/Notes?query=tag:Armando-Solar-Lezama" class="tag" target="_blank" rel="noopener">#Armando-Solar-Lezama</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel-Madden" class="tag" target="_blank" rel="noopener">#Samuel-Madden</a><br>Abstract
Object-relational mapping libraries are a popular way for applications to interact with databases because they provide transparent access to the database using the same language as the application. Unfortunately, using such frameworks often leads to poor performance, as modularity concerns encourage developers to implement relational operations in application code. Such application code does not take advantage of the optimized relational implementations that database systems provide, such as efficient implementations of joins or push down of selection predicates. In this paper we present QBS, a system that automatically transforms fragments of application logic into SQL queries. QBS differs from traditional compiler optimizations as it relies on synthesis technology to generate invariants and postconditions for a code fragment. The postconditions and invariants are expressed using a new theory of ordered relations that allows us to reason precisely about both the contents and order of the records produced complex code fragments that compute joins and aggregates. The theory is close in expressiveness to SQL, so the synthesized postconditions can be readily translated to SQL queries. Using 75 code fragments automatically extracted from over 120k lines of open-source code written using the Java Hibernate ORM, we demonstrate that our approach can convert a variety of imperative constructs into relational specifications and significantly improve application performance asymptotically by orders of magnitude.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/cheung2013optimizing.html</link><guid isPermaLink="false">Literature Notes/cheung2013optimizing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:51 GMT</pubDate></item><item><title><![CDATA[Attested append-only memory: Making adversaries stick to their word]]></title><description><![CDATA[ 
 <br><br>Byung-Gon Chun, Petros Maniatis, Scott Shenker, John Kubiatowicz (2007)<br>Tags: <br>Abstract
Researchers have made great strides in improving the fault tolerance of both centralized and replicated systems against arbitrary (Byzantine) faults. However, there are hard limits to how much can be done with entirely untrusted components; for example, replicated state machines cannot tolerate more than a third of their replica population being Byzantine. In this paper, we investigate how minimal trusted abstractions can push through these hard limits in practical ways. We propose Attested Append-Only Memory (A2M), a trusted system facility that is small, easy to implement and easy to verify formally. A2M provides the programming abstraction of a trusted log, which leads to protocol designs immune to equivocation – the ability of a faulty host to lie in different ways to different clients or servers – which is a common source of Byzantine headaches. Using A2M, we improve upon the state of the art in Byzantine-fault tolerant replicated state machines, producing A2M-enabled protocols (variants of Castro and Liskov's PBFT) that remain correct (linearizable) and keep making progress (live) even when half the replicas are faulty, in contrast to the previous upper bound. We also present an A2M-enabled single-server shared storage protocol that guarantees linearizability despite server faults. We implement A2M and our protocols, evaluate them experimentally through micro- and macro-benchmarks, and argue that the improved fault tolerance is cost-effective for a broad range of uses, opening up new avenues for practical, more reliable services.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/chun2007attested.html</link><guid isPermaLink="false">Literature Notes/chun2007attested.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:59 GMT</pubDate></item><item><title><![CDATA[Live migration of virtual machines]]></title><description><![CDATA[ 
 <br><br>Christopher Clark, Keir Fraser, Steven Hand, Jacob Gorm Hansen, Eric Jul, Christian Limpach, Ian Pratt, Andrew Warfield (2005)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Christopher-Clark" class="tag" target="_blank" rel="noopener">#Christopher-Clark</a> <a href="https://jayitha.github.io/Notes?query=tag:Keir-Fraser" class="tag" target="_blank" rel="noopener">#Keir-Fraser</a> <a href="https://jayitha.github.io/Notes?query=tag:Steven-Hand" class="tag" target="_blank" rel="noopener">#Steven-Hand</a> <a href="https://jayitha.github.io/Notes?query=tag:Jacob" class="tag" target="_blank" rel="noopener">#Jacob</a> <a href="https://jayitha.github.io/Notes?query=tag:Gorm-Hansen" class="tag" target="_blank" rel="noopener">#Gorm-Hansen</a> <a href="https://jayitha.github.io/Notes?query=tag:Eric-Jul" class="tag" target="_blank" rel="noopener">#Eric-Jul</a> <a href="https://jayitha.github.io/Notes?query=tag:Christian-Limpach" class="tag" target="_blank" rel="noopener">#Christian-Limpach</a> <a href="https://jayitha.github.io/Notes?query=tag:Ian-Pratt" class="tag" target="_blank" rel="noopener">#Ian-Pratt</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Warfield" class="tag" target="_blank" rel="noopener">#Andrew-Warfield</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/clark2005live.html</link><guid isPermaLink="false">Literature Notes/clark2005live.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:27 GMT</pubDate></item><item><title><![CDATA[A relational model of data for large shared data banks]]></title><description><![CDATA[ 
 <br><br>Edgar F Codd (1970)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Edgar-F-Codd" class="tag" target="_blank" rel="noopener">#Edgar-F-Codd</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.<br>
Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on&nbsp;n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/codd1970relational.html</link><guid isPermaLink="false">Literature Notes/codd1970relational.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:24:17 GMT</pubDate></item><item><title><![CDATA[A data base sublanguage founded on the relational calculus]]></title><description><![CDATA[ 
 <br><br>Edgar F Codd (1971)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Edgar" class="tag" target="_blank" rel="noopener">#Edgar</a> <a href="https://jayitha.github.io/Notes?query=tag:F-Codd" class="tag" target="_blank" rel="noopener">#F-Codd</a><br>Abstract
Three principal types of language for data base manipulation are identified: the low-level, procedure-oriented (typified by the CODASYL-proposed DML), the intermediate level, algebraic (typified by the Project MAC MacAIMS language), and the high level, relational calculus-based data sublanguage, an example of which is described in this paper. The language description is informal and stresses concepts and principles. Following this, arguments are presented for the superiority of the calculus-based type of data base sub-language over the algebraic, and for the algebraic over the low-level procedural. These arguments are particularly relevant to the questions of inter-system compatibility and standardization.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/codd1971data.html</link><guid isPermaLink="false">Literature Notes/codd1971data.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 10:54:45 GMT</pubDate></item><item><title><![CDATA[Logic and lattices for distributed programming]]></title><description><![CDATA[ 
 <br><br>Neil Conway, William R Marczak, Peter Alvaro, Joseph M Hellerstein, David Maier (2012)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Neil-Conway" class="tag" target="_blank" rel="noopener">#Neil-Conway</a> <a href="https://jayitha.github.io/Notes?query=tag:William" class="tag" target="_blank" rel="noopener">#William</a> <a href="https://jayitha.github.io/Notes?query=tag:R-Marczak" class="tag" target="_blank" rel="noopener">#R-Marczak</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Alvaro" class="tag" target="_blank" rel="noopener">#Peter-Alvaro</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:David-Maier" class="tag" target="_blank" rel="noopener">#David-Maier</a><br>Abstract
In recent years there has been interest in achieving application-level consistency criteria without the latency and availability costs of strongly consistent storage infrastructure. A standard technique is to adopt a vocabulary of commutative operations; this avoids the risk of inconsistency due to message reordering. Another approach was recently captured by the CALM theorem, which proves that logically monotonic programs are guaranteed to be eventually consistent. In logic languages such as Bloom, CALM analysis can automatically verify that programs achieve consistency without coordination. In this paper we present BloomL, an extension to Bloom that takes inspiration from both of these traditions. BloomL generalizes Bloom to support lattices and extends the power of CALM analysis to whole programs containing arbitrary lattices. We show how the Bloom interpreter can be generalized to support efficient evaluation of lattice-based code using well-known strategies from logic programming. Finally, we use BloomL to develop several practical distributed programs, including a key-value store similar to Amazon Dynamo, and show how BloomL encourages the safe composition of small, easy-to-analyze lattices into larger programs.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/conway2012logic.html</link><guid isPermaLink="false">Literature Notes/conway2012logic.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:36:29 GMT</pubDate></item><item><title><![CDATA[Spanner: Google's globally distributed database]]></title><description><![CDATA[ 
 <br><br>James C Corbett, Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, Jeffrey John Furman, Sanjay Ghemawat, Andrey Gubarev, Christopher Heiser, Peter Hochschild, others (2013)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:James" class="tag" target="_blank" rel="noopener">#James</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Corbett" class="tag" target="_blank" rel="noopener">#C-Corbett</a> <a href="https://jayitha.github.io/Notes?query=tag:Jeffrey-Dean" class="tag" target="_blank" rel="noopener">#Jeffrey-Dean</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Epstein" class="tag" target="_blank" rel="noopener">#Michael-Epstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Fikes" class="tag" target="_blank" rel="noopener">#Andrew-Fikes</a> <a href="https://jayitha.github.io/Notes?query=tag:Christopher-Frost" class="tag" target="_blank" rel="noopener">#Christopher-Frost</a> <a href="https://jayitha.github.io/Notes?query=tag:Jeffrey" class="tag" target="_blank" rel="noopener">#Jeffrey</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Furman" class="tag" target="_blank" rel="noopener">#John-Furman</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanjay-Ghemawat" class="tag" target="_blank" rel="noopener">#Sanjay-Ghemawat</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrey-Gubarev" class="tag" target="_blank" rel="noopener">#Andrey-Gubarev</a> <a href="https://jayitha.github.io/Notes?query=tag:Christopher-Heiser" class="tag" target="_blank" rel="noopener">#Christopher-Heiser</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Hochschild" class="tag" target="_blank" rel="noopener">#Peter-Hochschild</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
Spanner is Google's scalable, multiversion, globally distributed, and synchronously replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This article describes how Spanner is structured, its feature set, the rationale underlying various design decisions, and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: nonblocking reads in the past, lock-free snapshot transactions, and atomic schema changes, across all of Spanner.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/corbett2013spanner.html</link><guid isPermaLink="false">Literature Notes/corbett2013spanner.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 13 Feb 2024 17:04:23 GMT</pubDate></item><item><title><![CDATA[Data sketching]]></title><description><![CDATA[ 
 <br><br>Graham Cormode (2017)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Graham-Cormode" class="tag" target="_blank" rel="noopener">#Graham-Cormode</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/cormode2017data.html</link><guid isPermaLink="false">Literature Notes/cormode2017data.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:07 GMT</pubDate></item><item><title><![CDATA[Seeing is believing: A client-centric specification of database isolation]]></title><description><![CDATA[ 
 <br><br>Natacha Crooks, Youer Pu, Lorenzo Alvisi, Allen Clement (2017)<br>Tags: <br>Abstract
This paper introduces the first state-based formalization of isolation guarantees. Our approach is premised on a simple observation: applications view storage systems as black-boxes that transition through a series of states, a subset of which are observed by applications. Defining isolation guarantees in terms of these states frees definitions from implementation-specific assumptions. It makes immediately clear what anomalies, if any, applications can expect to observe, thus bridging the gap that exists today between how isolation guarantees are defined and how they are perceived. The clarity that results from definitions based on client-observable states brings forth several benefits. First, it allows us to easily compare the guarantees of distinct, but semantically close, isolation guarantees. We find that several well-known guarantees, previously thought to be distinct, are in fact equivalent, and that many previously incomparable flavors of snapshot isolation can be organized in a clean hierarchy. Second, freeing definitions from implementation-specific artefacts can suggest more efficient implementations of the same isolation guarantee. We show how a client-centric implementation of parallel snapshot isolation can be more resilient to slowdown cascades, a common phenomenon in large-scale datacenters.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/crooks2017seeing.html</link><guid isPermaLink="false">Literature Notes/crooks2017seeing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:26:37 GMT</pubDate></item><item><title><![CDATA[MapReduce: Simplified data processing on large clusters]]></title><description><![CDATA[ 
 <br><br>Jeffrey Dean, Sanjay Ghemawat (2008)<br>Tags: <br>Abstract
MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/dean2008mapreduce.html</link><guid isPermaLink="false">Literature Notes/dean2008mapreduce.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:46 GMT</pubDate></item><item><title><![CDATA[Dynamo: Amazon's highly available key-value store]]></title><description><![CDATA[ 
 <br><br>Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, Gunavardhan Kakulapati, Avinash Lakshman, Alex Pilchin, Swaminathan Sivasubramanian, Peter Vosshall, Werner Vogels (2007)<br>Tags: <br>Abstract
Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazon's core services use to provide an "always-on" experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/decandia2007dynamo.html</link><guid isPermaLink="false">Literature Notes/decandia2007dynamo.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:03:30 GMT</pubDate></item><item><title><![CDATA[Analysis and simulation of a fair queueing algorithm]]></title><description><![CDATA[ 
 <br><br>Alan Demers, Srinivasan Keshav, Scott Shenker (1989)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Alan-Demers" class="tag" target="_blank" rel="noopener">#Alan-Demers</a> <a href="https://jayitha.github.io/Notes?query=tag:Srinivasan-Keshav" class="tag" target="_blank" rel="noopener">#Srinivasan-Keshav</a> <a href="https://jayitha.github.io/Notes?query=tag:Scott-Shenker" class="tag" target="_blank" rel="noopener">#Scott-Shenker</a><br>Abstract
We discuss gateway queueing algorithms and their role in controlling congestion in datagram networks. A fair queueing algorithm, based on an earlier suggestion by Nagle, is proposed. Analysis and simulations are used to compare this algorithm to other congestion control schemes. We find that fair queueing provides several important advantages over the usual first-come-first-serve queueing algorithm: fair allocation of bandwidth, lower delay for sources using less than their full share of bandwidth, and protection from ill-behaved sources.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/demers1989analysis.html</link><guid isPermaLink="false">Literature Notes/demers1989analysis.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:46 GMT</pubDate></item><item><title><![CDATA[Lifting the burden of history from adaptive query processing]]></title><description><![CDATA[ 
 <br><br>Amol Deshpande, Joseph M Hellerstein, others (2004)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Amol-Deshpande" class="tag" target="_blank" rel="noopener">#Amol-Deshpande</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/deshpande2004lifting.html</link><guid isPermaLink="false">Literature Notes/deshpande2004lifting.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:44:55 GMT</pubDate></item><item><title><![CDATA[The Gamma database machine project]]></title><description><![CDATA[ 
 <br><br>David J DeWitt, Shahram Ghandeharizadeh, Donovan A Schneider, Allan Bricker, Hui-I Hsiao, Rick Rasmussen (1990)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:J-DeWitt" class="tag" target="_blank" rel="noopener">#J-DeWitt</a> <a href="https://jayitha.github.io/Notes?query=tag:Shahram-Ghandeharizadeh" class="tag" target="_blank" rel="noopener">#Shahram-Ghandeharizadeh</a> <a href="https://jayitha.github.io/Notes?query=tag:Donovan" class="tag" target="_blank" rel="noopener">#Donovan</a> <a href="https://jayitha.github.io/Notes?query=tag:A-Schneider" class="tag" target="_blank" rel="noopener">#A-Schneider</a> <a href="https://jayitha.github.io/Notes?query=tag:Allan-Bricker" class="tag" target="_blank" rel="noopener">#Allan-Bricker</a> <a href="https://jayitha.github.io/Notes?query=tag:Hui-I-Hsiao" class="tag" target="_blank" rel="noopener">#Hui-I-Hsiao</a> <a href="https://jayitha.github.io/Notes?query=tag:Rick-Rasmussen" class="tag" target="_blank" rel="noopener">#Rick-Rasmussen</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/dewitt1990gamma.html</link><guid isPermaLink="false">Literature Notes/dewitt1990gamma.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:59:34 GMT</pubDate></item><item><title><![CDATA[Kepler: Robust learning for parametric query optimization]]></title><description><![CDATA[ 
 <br><br>Lyric Doshi, Vincent Zhuang, Gaurav Jain, Ryan Marcus, Haoyu Huang, Deniz Altinbüken, Eugene Brevdo, Campbell Fraser (2023)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Lyric-Doshi" class="tag" target="_blank" rel="noopener">#Lyric-Doshi</a> <a href="https://jayitha.github.io/Notes?query=tag:Vincent-Zhuang" class="tag" target="_blank" rel="noopener">#Vincent-Zhuang</a> <a href="https://jayitha.github.io/Notes?query=tag:Gaurav-Jain" class="tag" target="_blank" rel="noopener">#Gaurav-Jain</a> <a href="https://jayitha.github.io/Notes?query=tag:Ryan-Marcus" class="tag" target="_blank" rel="noopener">#Ryan-Marcus</a> <a href="https://jayitha.github.io/Notes?query=tag:Haoyu-Huang" class="tag" target="_blank" rel="noopener">#Haoyu-Huang</a> <a href="https://jayitha.github.io/Notes?query=tag:Deniz-Altinbüken" class="tag" target="_blank" rel="noopener">#Deniz-Altinbüken</a> <a href="https://jayitha.github.io/Notes?query=tag:Eugene-Brevdo" class="tag" target="_blank" rel="noopener">#Eugene-Brevdo</a> <a href="https://jayitha.github.io/Notes?query=tag:Campbell-Fraser" class="tag" target="_blank" rel="noopener">#Campbell-Fraser</a><br>Abstract
Most existing parametric query optimization (PQO) techniques rely on traditional query optimizer cost models, which are often inaccurate and result in suboptimal query performance. We propose Kepler, an end-to-end learning-based approach to PQO that demonstrates significant speedups in query latency over a traditional query optimizer. Central to our method is Row Count Evolution (RCE), a novel plan generation algorithm based on perturbations in the sub-plan cardinality space. While previous approaches require accurate cost models, we bypass this requirement by evaluating candidate plans via actual execution data and training anML model to predict the fastest plan given parameter binding values. Our models leverage recent advances in neural network uncertainty in order to robustly predict faster plans while avoiding regressions in query performance. Experimentally, we show that Kepler achieves significant improvements in query runtime on multiple datasets on PostgreSQL.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/doshi2023kepler.html</link><guid isPermaLink="false">Literature Notes/doshi2023kepler.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:17:46 GMT</pubDate></item><item><title><![CDATA[Introducing go: Build reliable, scalable programs]]></title><description><![CDATA[ 
 <br><br>Caleb Doxsey (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a><br>Abstract
Perfect for beginners familiar with programming basics, this hands-on guide provides an easy introduction to Go, the general-purpose programming language from Google. Author Caleb Doxsey covers the language's core features with step-by-step instructions and exercises in each chapter to help you practice what you learn. Go is a general-purpose programming language with a clean syntax and advanced features, including concurrency. This book provides the one-on-one support you need to get started with the language, with short, easily digestible chapters that build on one another. By the time you finish this book, not only will you be able to write real Go programs, you'll be ready to tackle advanced techniques. Jump into Go basics, including data types, variables, and control structures Learn complex types, such as slices, functions, structs, and interfaces Explore Go's core library and learn how to create your own package Write tests for your code by using the language's go test program Learn how to run programs concurrently with goroutines and channels Get suggestions to help you master the craft of programming
]]></description><link>https://jayitha.github.io/Notes/literature-notes/doxsey2016introducing.html</link><guid isPermaLink="false">Literature Notes/doxsey2016introducing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sat, 04 Nov 2023 10:24:26 GMT</pubDate></item><item><title><![CDATA[ReVirt: Enabling intrusion analysis through virtual-machine logging and replay]]></title><description><![CDATA[ 
 <br><br>George W Dunlap, Samuel T King, Sukru Cinar, Murtaza A Basrai, Peter M Chen (2002)<br>Tags: <br>Abstract
Current system loggers have two problems: they depend on the integrity of the operating system being logged, and they do not save sufficient information to replay and analyze attacks that include any non-deterministic events. ReVirt removes the dependency on the target operating system by moving it into a virtual machine and logging below the virtual machine. This allows ReVirt to replay the system's execution before, during, and after an intruder compromises the system, even if the intruder replaces the target operating system. ReVirt logs enough information to replay a long-term execution of the virtual machine instruction-by-instruction. This enables it to provide arbitrarily detailed observations about what transpired on the system, even in the presence of non-deterministic attacks and executions. ReVirt adds reasonable time and space overhead. Overheads due to virtualization are imperceptible for interactive use and CPU-bound workloads, and 13–58% for kernel-intensive workloads. Logging adds 0–8% overhead, and logging traffic for our workloads can be stored on a single disk for several months.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/dunlap2002revirt.html</link><guid isPermaLink="false">Literature Notes/dunlap2002revirt.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:46 GMT</pubDate></item><item><title><![CDATA[Labels and event processes in the Asbestos operating system]]></title><description><![CDATA[ 
 <br><br>Petros Efstathopoulos, Maxwell Krohn, Steve VanDeBogart, Cliff Frey, David Ziegler, Eddie Kohler, David Mazieres, Frans Kaashoek, Robert Morris (2005)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Petros-Efstathopoulos" class="tag" target="_blank" rel="noopener">#Petros-Efstathopoulos</a> <a href="https://jayitha.github.io/Notes?query=tag:Maxwell-Krohn" class="tag" target="_blank" rel="noopener">#Maxwell-Krohn</a> <a href="https://jayitha.github.io/Notes?query=tag:Steve-VanDeBogart" class="tag" target="_blank" rel="noopener">#Steve-VanDeBogart</a> <a href="https://jayitha.github.io/Notes?query=tag:Cliff-Frey" class="tag" target="_blank" rel="noopener">#Cliff-Frey</a> <a href="https://jayitha.github.io/Notes?query=tag:David-Ziegler" class="tag" target="_blank" rel="noopener">#David-Ziegler</a> <a href="https://jayitha.github.io/Notes?query=tag:Eddie-Kohler" class="tag" target="_blank" rel="noopener">#Eddie-Kohler</a> <a href="https://jayitha.github.io/Notes?query=tag:David-Mazieres" class="tag" target="_blank" rel="noopener">#David-Mazieres</a> <a href="https://jayitha.github.io/Notes?query=tag:Frans-Kaashoek" class="tag" target="_blank" rel="noopener">#Frans-Kaashoek</a> <a href="https://jayitha.github.io/Notes?query=tag:Robert-Morris" class="tag" target="_blank" rel="noopener">#Robert-Morris</a><br>Abstract
Asbestos, a new prototype operating system, provides novel labeling and isolation mechanisms that help contain the effects of exploitable software flaws. Applications can express a wide range of policies with Asbestos's kernel-enforced label mechanism, including controls on inter-process communication and system-wide information flow. A new event process abstraction provides lightweight, isolated contexts within a single process, allowing the same process to act on behalf of multiple users while preventing it from leaking any single user's data to any other user. A Web server that uses Asbestos labels to isolate user data requires about 1.5 memory pages per user, demonstrating that additional security can come at an acceptable cost.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/efstathopoulos2005labels.html</link><guid isPermaLink="false">Literature Notes/efstathopoulos2005labels.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:49 GMT</pubDate></item><item><title><![CDATA[Exokernel: An operating system architecture for application-level resource management]]></title><description><![CDATA[ 
 <br><br>Dawson R Engler, M Frans Kaashoek, James O'Toole Jr (1995)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/engler1995exokernel.html</link><guid isPermaLink="false">Literature Notes/engler1995exokernel.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:04 GMT</pubDate></item><item><title><![CDATA[Adopting worst-case optimal joins in relational database systems]]></title><description><![CDATA[ 
 <br><br>Michael Freitag, Maximilian Bandle, Tobias Schmidt, Alfons Kemper, Thomas Neumann (2020)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Freitag" class="tag" target="_blank" rel="noopener">#Michael-Freitag</a> <a href="https://jayitha.github.io/Notes?query=tag:Maximilian-Bandle" class="tag" target="_blank" rel="noopener">#Maximilian-Bandle</a> <a href="https://jayitha.github.io/Notes?query=tag:Tobias-Schmidt" class="tag" target="_blank" rel="noopener">#Tobias-Schmidt</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a><br>Abstract
Worst-case optimal join algorithms are attractive from a theoretical point of view, as they offer asymptotically better runtime than binary joins on certain types of queries. In particular, they avoid enumerating large intermediate results by processing multiple input relations in a single multi-way join. However, existing implementations incur a sizable overhead in practice, primarily since they rely on suitable ordered index structures on their input. Systems that support worst-case optimal joins often focus on a specific problem domain, such as read-only graph analytic queries, where extensive precomputation allows them to mask these costs. In this paper, we present a comprehensive implementation approach for worst-case optimal joins that is practical within general-purpose relational database management systems supporting both hybrid transactional and analytical workloads. The key component of our approach is a novel hash-based worst-case optimal join algorithm that relies only on data structures that can be built efficiently during query execution. Furthermore, we implement a hybrid query optimizer that intelligently and transparently combines both binary and multi-way joins within the same query plan. We demonstrate that our approach far outperforms existing systems when worst-case optimal joins are beneficial while sacrificing no performance when they are not.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/freitag2020adopting.html</link><guid isPermaLink="false">Literature Notes/freitag2020adopting.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:31 GMT</pubDate></item><item><title><![CDATA[Will carbon nanotube memory replace DRAM?]]></title><description><![CDATA[ 
 <br><br>Bill Gervasi (2019)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Bill-Gervasi" class="tag" target="_blank" rel="noopener">#Bill-Gervasi</a><br>Abstract
In this paper, we discuss an exciting memory technology made from carbon nanotubes. Carbon nanotubes provide a predictable resistive element that can be used to fabricate very dense and very fast-switching memory cells. Nantero NRAM employs electrostatic forces to connect and disconnect these nanotubes in a memory design notably impervious to external effects including heat, shock and vibration, magnetism, and radiation. NRAM maintains its state permanently and may be rewritten arbitrarily many times without degrading. Not only NRAM is well positioned to replace DRAM in existing applications, but also its combination of high speed, persistence, density, and low power enables a slew of exciting new applications. Production of NRAM devices is on track for near-term commercialization through Nantero licensees.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/gervasi2019will.html</link><guid isPermaLink="false">Literature Notes/gervasi2019will.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:29:11 GMT</pubDate></item><item><title><![CDATA[The google file system]]></title><description><![CDATA[ 
 <br><br>Sanjay Ghemawat, Howard Gobioff, Shun-Tak Leung (2003)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanjay-Ghemawat" class="tag" target="_blank" rel="noopener">#Sanjay-Ghemawat</a> <a href="https://jayitha.github.io/Notes?query=tag:Howard-Gobioff" class="tag" target="_blank" rel="noopener">#Howard-Gobioff</a> <a href="https://jayitha.github.io/Notes?query=tag:Shun-Tak-Leung" class="tag" target="_blank" rel="noopener">#Shun-Tak-Leung</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/ghemawat2003google.html</link><guid isPermaLink="false">Literature Notes/ghemawat2003google.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:15 GMT</pubDate></item><item><title><![CDATA[Dominant resource fairness: Fair allocation of multiple resource types]]></title><description><![CDATA[ 
 <br><br>Ali Ghodsi, Matei Zaharia, Benjamin Hindman, Andy Konwinski, Scott Shenker, Ion Stoica (2011)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/ghodsi2011dominant.html</link><guid isPermaLink="false">Literature Notes/ghodsi2011dominant.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:41 GMT</pubDate></item><item><title><![CDATA[Priority-driven scheduling of periodic task systems on multiprocessors]]></title><description><![CDATA[ 
 <br><br>Joël Goossens, Shelby Funk, Sanjoy Baruah (2003)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Joël-Goossens" class="tag" target="_blank" rel="noopener">#Joël-Goossens</a> <a href="https://jayitha.github.io/Notes?query=tag:Shelby-Funk" class="tag" target="_blank" rel="noopener">#Shelby-Funk</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanjoy-Baruah" class="tag" target="_blank" rel="noopener">#Sanjoy-Baruah</a><br>Abstract
The scheduling of systems of periodic tasks upon multiprocessor platforms is considered. Utilization-based conditions are derived for determining whether a periodic task system meets all deadlines when scheduled using the earliest deadline first scheduling algorithm (EDF) upon a given multiprocessor platform. A new priority-driven algorithm is proposed for scheduling periodic task systems upon multiprocessor platforms: this algorithm is shown to successfully schedule some task systems for which EDF may fail to meet all deadlines.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/goossens2003priority.html</link><guid isPermaLink="false">Literature Notes/goossens2003priority.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:49:54 GMT</pubDate></item><item><title><![CDATA[A survey of B-tree logging and recovery techniques]]></title><description><![CDATA[ 
 <br><br>Goetz Graefe (2012)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Goetz-Graefe" class="tag" target="_blank" rel="noopener">#Goetz-Graefe</a><br>Abstract
B-trees have been ubiquitous in database management systems for several decades, and they serve in many other storage systems as well. Their basic structure and their basic operations are well understood including search, insertion, and deletion. However, implementation of transactional guarantees such as all-or-nothing failure atomicity and durability in spite of media and system failures seems to be difficult. High-performance techniques such as pseudo-deleted records, allocation-only logging, and transaction processing during crash recovery are widely used in commercial B-tree implementations but not widely understood. This survey collects many of these techniques as a reference for students, researchers, system architects, and software developers. Central in this discussion are physical data independence, separation of logical database contents and physical representation, and the concepts of user transactions and system transactions. Many of the techniques discussed are applicable beyond B-trees.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/graefe2012survey.html</link><guid isPermaLink="false">Literature Notes/graefe2012survey.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:36:39 GMT</pubDate></item><item><title><![CDATA[Granularity of locks and degrees of consistency]]></title><description><![CDATA[ 
 <br><br>R Lorie J Gray, GF Putzolu, IL Traiger (1976)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:R-Lorie" class="tag" target="_blank" rel="noopener">#R-Lorie</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Gray" class="tag" target="_blank" rel="noopener">#J-Gray</a> <a href="https://jayitha.github.io/Notes?query=tag:GF-Putzolu" class="tag" target="_blank" rel="noopener">#GF-Putzolu</a> <a href="https://jayitha.github.io/Notes?query=tag:IL-Traiger" class="tag" target="_blank" rel="noopener">#IL-Traiger</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/gray1976granularity.html</link><guid isPermaLink="false">Literature Notes/gray1976granularity.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:24:58 GMT</pubDate></item><item><title><![CDATA[The transaction concept: Virtues and limitations]]></title><description><![CDATA[ 
 <br><br>Jim Gray, others (1981)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/gray1981transaction.html</link><guid isPermaLink="false">Literature Notes/gray1981transaction.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:33:50 GMT</pubDate></item><item><title><![CDATA[Logic, algebra and databases]]></title><description><![CDATA[ 
 <br><br>Peter Gray (1984)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br>I have this nagging feeling there's something very fundamental in database systems that I don't seem to understand.<br><br>I'll skim through most of the first two chapters since I mostly know the content.<br>
<br>Rules of inference - chain rule and Modus Ponens (or mod pons)
<br>Modus Ponens

Given truth of   A
and of           A -&gt; B
deduce           B

Chain Rule

Given truth of   A -&gt; B
and of           B -&gt; C
deduce           A -&gt; C
Copy<br>
<br>
 (it is true that) ()

<br>
 (it is universally true that) () - for tautologies

<br>
The problem of proofs is to prove a formula  given the truth of formulae  to 

<br>There are two ways of proving<br>
<br>Generate a long truth table for each boolean variable - impractical
<br>Write down premises and use rules of inference to deduce other true formulae
<br>Three different proof strategies<br>
<br>Proof by adopting a premise - to prove an implication of form , assume  is true by adopting  as a premise and prove . This is equivalent to 
<br>Reductio Ad Absurdum (reduce to an absurdity) - When applying a chains of inference to a premise, it is possible to get sidetracked and prove irrelevant statements. This is called forward chaining. Instead, you can alternatively try proving the contrapositive () called backward chaining. You can also use both, i.e. assume both  and  are true i.e. both forward and backward chaining until you reach a contradiction.
<br>Proof by Resolution - 
<br>Proof by Resolution

1. Convert the Reductio Ad Absurdum premise to Conjunctive Normal Form (CNF)
2. Take two clauses which contain the same atom with opposite signs and apply resolution to combine the two clauses and eliminate the atom
3. Continue till you get the conjunction of the same atom with different signs
Copy<br>Let's try an exercise<br>
STEP 1<br>
Converting the premise<br>
Converting conclusion to normal form<br>STEP 2<br>
So far we have<br>
The statement can be reduced by resolution <br>STEP 3<br>
We end up with  which is a contradiction ()<br>Advantages of the resolution method are<br>
<br>Do not have to use equivalences to rearrange atoms as all clauses are in normal form and resolution rule doesn't care about the position
<br>Only one rule to remember
<br>Easy to mechanize
<br>However, it is possible to go round in circles and the normal form makes all the clauses look alike(?)<br><br>
<br>A usual rule of thumb is that the existential quantifier () goes with conjunction and the universal quantifier () goes with implication
<br>A unary predicate (taking only one argument) is true for a subset of the universe of discourse (). This subset is called the extension of the predicate and the predicate is called the Characteristic Function of the subset
<br>To negate a quantified expression, change the quantifier, change the signs and change the operators
<br>Predicate calculus can be used to form queries about stored data i.e. we want the extension of the predicate. Predicates are also used to "encode" integrity constraints
<br>You can convert quantified expressions to Conjunctive Normal Form as well (CNF)

<br>Remove equivalences ( =&gt; )
<br>Remove implications ( =&gt; )
<br>Move negation signs from outside to in front of the atoms using De Morgan's laws
<br>Remove existential quantifiers using Skolemisation - If a variable x is existentially quantified and not nested below a universal quantifier, every occurrence of x is replaced by an unknown Skolem Constant (say ) denoting one value of x for which the statement is true. If  is nested under a universal quantifier (), you replace all instances of  with a Skolem Function  
<br>Pull out universal quantifiers
<br>Multiply out bracketed conjunctions - 


<br>You can use this CNF form to again use the Resolution method from the first chapter. However, there are some formulae that are "undecidable" and can trick computers to go in circles
<br>When using resolution, you can use an answer clause along with the conclusion to keep track of the solution 
<br>To avoid circles, we provide computer programs with heuristics

<br>Unit Preference - It is best to use at least one unit clause in resolution
<br>Set of support - You must use specific facts from the problem not just general axioms
<br>Choose unique literals - Attempt to resolve with literals that appear less frequently and appears in the conclusion
<br>Planning - A human will usually plan out the proof first, providing meta-information about which axioms are important to drive the proof


<br>In the resolution method, the process of finding a substitution which makes two literals clash is called Unification
<br>
<br><br>
<br>One class of database languages is based on predicate calculus (SQL), others are based on 'Applicative' or 'Functional' languages
<br>Partial functions - Functions not defined over their whole domain
<br>Restriction and Union of functions

G(x) = if P(x) then F1(x) else F2(x)

Translates to 

G = (F1 restrict P) union (F2 restrict not P)

Where (F1 restrict P) translates to function P defined on the intersection between the domain of F1 and the extension of P
Copy<br>
<br>When evaluating restrictions, the extension of the predicate  is evaluated first since  can be a partial function
<br>In Lambda Calculus, Constructor of new functions is done using the greek symbol  and the process is called function abstraction
<br><br>
<br>A lambda expression denotes an unnamed function
<br>In the functional model, iteration is done using recursion
<br>fac = lambda n. if n = 0 then 1 else n * fac(n - 1)*
Copy<br>
<br>There are two version of recursion

<br>Down-going - Breaks the problem down into smaller problems where the result of the smaller problem is needed to build the answer from the answer from the smaller problems
<br>Up-going - Intermediate results are computed and passed down to the smaller subproblems using a workspace parameter where the final answer is built and is simply passed back through the call chain (for instance, you can do tail-call elimination maybe from <a data-tooltip-position="top" aria-label="ierusalimschy2006programming" data-href="ierusalimschy2006programming" href="https://jayitha.github.io/Notes/literature-notes/ierusalimschy2006programming.html" class="internal-link" target="_self" rel="noopener">Programming in Lua</a>)


<br>A list is a sequence of items that are accessed sequentially. There are two functions used to access lists

<br>car(list): list -&gt; element - returns the first element of the list
<br>cdr(list): list -&gt; list - returns a list of all but the first element of the list


<br>car([2, 3, 4]) = 2
cdr([2, 3, 4]) = [3, 4]
car(cdr([2, 3, 4])) = 3

-- suppose you want to get the nth element of the list
select(n, l) = lambda n,l. if n = 1 then car(s) else select(n-1, cdr(s))
Copy<br>
<br>You can represent trees using nested lists - used for indices like B-Trees
<br>To construct a list you can use the cons(&lt;element&gt;, &lt;list&gt;) function which prepends element to the list
<br>cons(paste, [jam, butter]) = [paste, jam, butter]
Copy<br>
<br>The abstract Lists concept is usually implemented using a linked representation, with a pointer to a list node containing the first item, which has a pointer pointing to the next node and so on
<br>It's possible to prepend a list with more than one item using the cons function. Therefore, it's important to copy the original list before cons if you want to create two different lists
<br>There are two versions of recursion - down-going and up-going
<br>--- function to copy list
-- down-going
dcopy = lambda s. if s = [] then []
				  else cons(car(s), dcopy(cdr(s)))
dcopy([2, 5, 7]) = [2, 5, 7]
-- up-going
ucopy = lambda s. ucop(s, [])
ucop = lambda s,w. if s = [] then w
				   else ucop(cdr(s), cons(car(s), w))
ucopy([2, 5, 7]) = [7, 5, 2]
--- intuitively, the down-going version has access to the last element before it constructs the final list which is not the case with the up-going version
Copy<br>
<br>Predicate atom(l) returns true if l is atomic i.e. not a list or the empty list [] and false otherwise ex. atom(2) = atom([]) = true; atom([2]) = false
<br>The book goes on to discuss how down-going recursion might be slower to execute because of all the space occupied on the stack. In fact, up-going recursion functions can be compiled into iteration + assignment programs ==&gt; removing tail recursion
<br>-- Other list and set processing operators
member(x, s) -&gt; checks if x is in s or is a subset of s
A orelse B -&gt; if A then true else B
A andif B -&gt; if not A then false else B
intsec(la, lb) -&gt; intersection
subset(la, lb)
equal(la, lb)
Copy<br><br><br><br>: ]]></description><link>https://jayitha.github.io/Notes/literature-notes/gray1984logic.html</link><guid isPermaLink="false">Literature Notes/gray1984logic.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:25:15 GMT</pubDate></item><item><title><![CDATA[SBFT: A scalable and decentralized trust infrastructure]]></title><description><![CDATA[ 
 <br><br>Guy Golan Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas, Michael Reiter, Dragos-Adrian Seredinschi, Orr Tamir, Alin Tomescu (2019)<br>Tags: <br>Abstract
SBFT is a state of the art Byzantine fault tolerant state machine replication system that addresses the challenges of scalability, decentralization and global geo-replication. SBFT is optimized for decentralization and is experimentally evaluated on a deployment of more than 200 active replicas withstanding a malicious adversary controlling f=64 replicas. Our experiments show how the different algorithmic ingredients of SBFT contribute to its performance and scalability. The results show that SBFT simultaneously provides almost 2x better throughput and about 1.5x better latency relative to a highly optimized system that implements the PBFT protocol. To achieve this performance improvement, SBFT uses a combination of four ingredients: using collectors and threshold signatures to reduce communication to linear, using an optimistic fast path, reducing client communication and utilizing redundant servers for the fast path. SBFT is the first system to implement a correct dual-mode view change protocol that allows to efficiently run either an optimistic fast path or a fallback slow path without incurring a view change to switch between modes.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/gueta2019sbft.html</link><guid isPermaLink="false">Literature Notes/gueta2019sbft.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:54 GMT</pubDate></item><item><title><![CDATA[You can teach elephants to dance: Agile VM handoff for edge computing]]></title><description><![CDATA[ 
 <br><br>Kiryong Ha, Yoshihisa Abe, Thomas Eiszler, Zhuo Chen, Wenlu Hu, Brandon Amos, Rohit Upadhyaya, Padmanabhan Pillai, Mahadev Satyanarayanan (2017)<br>Tags: <br>Abstract
M handoff enables rapid and transparent placement changes to executing code in edge computing use cases where the safety and management attributes of VM encapsulation are important. This versatile primitive offers the functionality of classic live migration but is highly optimized for the edge. Over WAN bandwidths ranging from 5 to 25 Mbps, VM handoff migrates a running 8 GB VM in about a minute, with a downtime of a few tens of seconds. By dynamically adapting to varying network bandwidth and processing load, VM handoff is more than an order of magnitude faster than live migration at those bandwidths.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/ha2017you.html</link><guid isPermaLink="false">Literature Notes/ha2017you.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:06 GMT</pubDate></item><item><title><![CDATA[Principles of transaction-oriented database recovery]]></title><description><![CDATA[ 
 <br><br>Theo Haerder, Andreas Reuter (1983)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Theo-Haerder" class="tag" target="_blank" rel="noopener">#Theo-Haerder</a> <a href="https://jayitha.github.io/Notes?query=tag:Andreas-Reuter" class="tag" target="_blank" rel="noopener">#Andreas-Reuter</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/haerder1983principles.html</link><guid isPermaLink="false">Literature Notes/haerder1983principles.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:33:33 GMT</pubDate></item><item><title><![CDATA[Are virtual machine monitors microkernels done right?]]></title><description><![CDATA[ 
 <br><br>Steven Hand, Andrew Warfield, Keir Fraser, Evangelos Kotsovinos, Daniel J Magenheimer (2005)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Steven-Hand" class="tag" target="_blank" rel="noopener">#Steven-Hand</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Warfield" class="tag" target="_blank" rel="noopener">#Andrew-Warfield</a> <a href="https://jayitha.github.io/Notes?query=tag:Keir-Fraser" class="tag" target="_blank" rel="noopener">#Keir-Fraser</a> <a href="https://jayitha.github.io/Notes?query=tag:Evangelos-Kotsovinos" class="tag" target="_blank" rel="noopener">#Evangelos-Kotsovinos</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel" class="tag" target="_blank" rel="noopener">#Daniel</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Magenheimer" class="tag" target="_blank" rel="noopener">#J-Magenheimer</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/hand2005virtual.html</link><guid isPermaLink="false">Literature Notes/hand2005virtual.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:11 GMT</pubDate></item><item><title><![CDATA[Building on quicksand]]></title><description><![CDATA[ 
 <br><br>Pat Helland, David Campbell (2009)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Pat-Helland" class="tag" target="_blank" rel="noopener">#Pat-Helland</a> <a href="https://jayitha.github.io/Notes?query=tag:David-Campbell" class="tag" target="_blank" rel="noopener">#David-Campbell</a><br>Abstract
Reliable systems have always been built out of unreliable components. Early on, the reliable components were small such as mirrored disks or ECC (Error Correcting Codes) in core memory. These systems were designed such that failures of these small components were transparent to the application. Later, the size of the unreliable components grew larger and semantic challenges crept into the application when failures occurred. As the granularity of the unreliable component grows, the latency to communicate with a backup becomes unpalatable. This leads to a more relaxed model for fault tolerance. The primary system will acknowledge the work request and its actions without waiting to ensure that the backup is notified of the work. This improves the responsiveness of the system. There are two implications of asynchronous state capture: 1) Everything promised by the primary is probabilistic. There is always a chance that an untimely failure shortly after the promise results in a backup proceeding without knowledge of the commitment. Hence, nothing is guaranteed! 2) Applications must ensure eventual consistency. Since work may be stuck in the primary after a failure and reappear later, the processing order for work cannot be guaranteed. Platform designers are struggling to make this easier for their applications. Emerging patterns of eventual consistency and probabilistic execution may soon yield a way for applications to express requirements for a "looser" form of consistency while providing availability in the face of ever larger failures. This paper recounts portions of the evolution of these trends, attempts to show the patterns that span these changes, and talks about future directions as we continue to "build on quicksand".
]]></description><link>https://jayitha.github.io/Notes/literature-notes/helland2009building.html</link><guid isPermaLink="false">Literature Notes/helland2009building.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:36:24 GMT</pubDate></item><item><title><![CDATA[Online aggregation]]></title><description><![CDATA[ 
 <br><br>Joseph M Hellerstein, Peter J Haas, Helen J Wang (1997)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter" class="tag" target="_blank" rel="noopener">#Peter</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Haas" class="tag" target="_blank" rel="noopener">#J-Haas</a> <a href="https://jayitha.github.io/Notes?query=tag:Helen" class="tag" target="_blank" rel="noopener">#Helen</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Wang" class="tag" target="_blank" rel="noopener">#J-Wang</a><br>Abstract
Aggregation in traditional database systems is performed in batch mode: a query is submitted, the system processes a large volume of data over a long period of time, and, eventually, the final answer is returned. This archaic approach is frustrating to users and has been abandoned in most other areas of computing. In this paper we propose a new online aggregation interface that permits users to both observe the progress of their aggregation queries and control execution on the fly. After outlining usability and performance requirements for a system supporting online aggregation, we present a suite of techniques that extend a database system to meet these requirements. These include methods for returning the output in random order, for providing control over the relative rate at which different aggregates are computed, and for computing running confidence intervals. Finally, we report on an initial implementation of online aggregation in POSTGRES.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellerstein1997online.html</link><guid isPermaLink="false">Literature Notes/hellerstein1997online.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:41 GMT</pubDate></item><item><title><![CDATA[Interactive data analysis: The Control project]]></title><description><![CDATA[ 
 <br><br>J.M. Hellerstein, R. Avnur, A. Chou, C. Hidber, C. Olston, V. Raman, T. Roth, P.J. Haas (1999)<br>Tags: <br>Abstract
Data analysis is fundamentally an iterative process in which you issue a query, receive a response, formulate the next query based on the response, and repeat. You usually don't issue a single, perfectly chosen query and get the information you want from a database; indeed, the purpose of data analysis is to extract unknown information, and in most situations, there is no one perfect query. People naturally start by asking broad, big-picture questions and then continually refine their questions based on feedback and domain knowledge. In the Control (Continuous Output and Navigation Technology with Refinement Online) project at the University of California, Berkeley, the authors are working with collaborators at IBM, Informix, and elsewhere to explore ways to improve human-computer interaction during data analysis. The Control project's goal is to develop interactive, intuitive techniques for analyzing massive data sets.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellerstein1999interactive.html</link><guid isPermaLink="false">Literature Notes/hellerstein1999interactive.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:13 GMT</pubDate></item><item><title><![CDATA[Architecture of a database system]]></title><description><![CDATA[ 
 <br><br>Joseph M Hellerstein, Michael Stonebraker, James Hamilton, others (2007)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Stonebraker" class="tag" target="_blank" rel="noopener">#Michael-Stonebraker</a> <a href="https://jayitha.github.io/Notes?query=tag:James-Hamilton" class="tag" target="_blank" rel="noopener">#James-Hamilton</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract
Database Management Systems (DBMSs) are a ubiquitous and critical component of modern computing, and the result of decades of research and development in both academia and industry. Historically, DBMSs were among the earliest multi-user server systems to be developed, and thus pioneered many systems design techniques for scalability and reliability now in use in many other contexts. While many of the algorithms and abstractions used by a DBMS are textbook material, there has been relatively sparse coverage in the literature of the systems design issues that make a DBMS work. This paper presents an architectural discussion of DBMS design principles, including process models, parallel architecture, storage system design, transaction system implementation, query processor and optimizer architectures, and typical shared components and utilities. Successful commercial and open-source systems are used as points of reference, particularly when multiple alternative designs have been adopted by different groups.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellerstein2007architecture.html</link><guid isPermaLink="false">Literature Notes/hellerstein2007architecture.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:13:32 GMT</pubDate></item><item><title><![CDATA[Looking back at postgres]]></title><description><![CDATA[ 
 <br><br>Joseph M Hellerstein (2018)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a><br>Abstract
This is a recollection of the UC Berkeley Postgres project, which was led by Mike Stonebraker from the mid-1980's to the mid-1990's. The article was solicited for Stonebraker's Turing Award book, as one of many personal/historical recollections. As a result it focuses on Stonebraker's design ideas and leadership. But Stonebraker was never a coder, and he stayed out of the way of his development team. The Postgres codebase was the work of a team of brilliant students and the occasional university "staff programmers" who had little more experience (and only slightly more compensation) than the students. I was lucky to join that team as a student during the latter years of the project. I got helpful input on this writeup from some of the more senior students on the project, but any errors or omissions are mine. If you spot any such, please contact me and I will try to fix them.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellerstein2018looking.html</link><guid isPermaLink="false">Literature Notes/hellerstein2018looking.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:56:45 GMT</pubDate></item><item><title><![CDATA[Keeping CALM: When distributed consistency is easy]]></title><description><![CDATA[ 
 <br><br>Joseph M Hellerstein, Peter Alvaro (2020)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellerstein2020keeping.html</link><guid isPermaLink="false">Literature Notes/hellerstein2020keeping.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:30:13 GMT</pubDate></item><item><title><![CDATA[XFS: The big storage file system for Linux]]></title><description><![CDATA[ 
 <br><br>Christoph Hellwig (2009)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/hellwig2009xfs.html</link><guid isPermaLink="false">Literature Notes/hellwig2009xfs.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:21:51 GMT</pubDate></item><item><title><![CDATA[Column sketches: A scan accelerator for rapid and robust predicate evaluation]]></title><description><![CDATA[ 
 <br><br>Brian Hentschel, Michael S Kester, Stratos Idreos (2018)<br>Tags: <br>Abstract
While numerous indexing and storage schemes have been developed to address the core functionality of predicate evaluation in data systems, they all require specific workload properties (query selectivity, data distribution, data clustering) to provide good performance and fail in other cases. We present a new class of indexing scheme, termed a Column Sketch, which improves the performance of predicate evaluation independently of workload properties. Column Sketches work primarily through the use of lossy compression schemes which are designed so that the index ingests data quickly, evaluates any query performantly, and has small memory footprint. A Column Sketch works by applying this lossy compression on a value-by-value basis, mapping base data to a representation of smaller fixed width codes. Queries are evaluated affirmatively or negatively for the vast majority of values using the compressed data, and only if needed check the base data for the remaining values. Column Sketches work over column, row, and hybrid storage layouts. We demonstrate that by using a Column Sketch, the select operator in modern analytic systems attains better CPU efficiency and less data movement than state-of-the-art storage and indexing schemes. Compared to standard scans, Column Sketches provide an improvement of 3x-6x for numerical attributes and 2.7x for categorical attributes. Compared to state-of-the-art scan accelerators such as Column Imprints and BitWeaving, Column Sketches perform 1.4 - 4.8× better.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/hentschel2018column.html</link><guid isPermaLink="false">Literature Notes/hentschel2018column.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:33:31 GMT</pubDate></item><item><title><![CDATA[Opportunities for optimism in contended main-memory multicore transactions]]></title><description><![CDATA[ 
 <br><br>Yihe Huang, William Qian, Eddie Kohler, Barbara Liskov, Liuba Shrira (2020)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Yihe-Huang" class="tag" target="_blank" rel="noopener">#Yihe-Huang</a> <a href="https://jayitha.github.io/Notes?query=tag:William-Qian" class="tag" target="_blank" rel="noopener">#William-Qian</a> <a href="https://jayitha.github.io/Notes?query=tag:Eddie-Kohler" class="tag" target="_blank" rel="noopener">#Eddie-Kohler</a> <a href="https://jayitha.github.io/Notes?query=tag:Barbara-Liskov" class="tag" target="_blank" rel="noopener">#Barbara-Liskov</a> <a href="https://jayitha.github.io/Notes?query=tag:Liuba-Shrira" class="tag" target="_blank" rel="noopener">#Liuba-Shrira</a><br>Abstract
Optimistic concurrency control, or OCC, can achieve excellent performance on uncontended workloads for main-memory transactional databases. Contention causes OCC's performance to degrade, however, and recent concurrency control designs, such as hybrid OCC/locking systems and variations on multiversion concurrency control (MVCC), have claimed to outperform the best OCC systems. We evaluate several concurrency control designs under varying contention and varying workloads, including TPCC, and find that implementation choices unrelated to concurrency control may explain much of OCC's previously-reported degradation. When these implementation choices are made sensibly, OCC performance does not collapse on high-contention TPC-C. We also present two optimization techniques, commit-time updates and timestamp splitting, that can dramatically improve the highcontention performance of both OCC and MVCC. Though these techniques are known, we apply them in a new context and highlight their potency: when combined, they lead to performance gains of 3:4 for MVCC and 3:6 for OCC in a TPC-C workload.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/huang2020opportunities.html</link><guid isPermaLink="false">Literature Notes/huang2020opportunities.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:09 GMT</pubDate></item><item><title><![CDATA[Database cracking.]]></title><description><![CDATA[ 
 <br><br>Stratos Idreos, Martin L Kersten, Stefan Manegold, others (2007)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Stratos-Idreos" class="tag" target="_blank" rel="noopener">#Stratos-Idreos</a> <a href="https://jayitha.github.io/Notes?query=tag:Martin" class="tag" target="_blank" rel="noopener">#Martin</a> <a href="https://jayitha.github.io/Notes?query=tag:L-Kersten" class="tag" target="_blank" rel="noopener">#L-Kersten</a> <a href="https://jayitha.github.io/Notes?query=tag:Stefan-Manegold" class="tag" target="_blank" rel="noopener">#Stefan-Manegold</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/idreos2007database.html</link><guid isPermaLink="false">Literature Notes/idreos2007database.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:53 GMT</pubDate></item><item><title><![CDATA[Programming in lua]]></title><description><![CDATA[<a class="tag" href="https://jayitha.github.io/Notes/?query=tag:todo" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#todo</a> 
 <br><br>Roberto Ierusalimschy (2006)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:todo" class="tag" target="_blank" rel="noopener">#todo</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br><br>
<br>Tables are the only data structures in Lua. Even a function from a library like math.sin actually translates to "index table named math using string sin as key"
<br>Tables are not values or variables, they are objects. Variables reference tables, when a table has no references the garbage collector deletes the table
<br>&gt; a = {}
&gt; a["x"] = 10
&gt; b = a -- 'b' refers to the same table as 'a'
&gt; b["x"] --&gt; 10
&gt; b["x"] = 20
&gt; a["x"] --&gt; 20
&gt; a = nil
&gt; b = nil -- table dropped
Copy<br>
<br>Structures are represented using field names as indices
<br>&gt; a = {}
&gt; a.x = 10 -- same as a["x"] = 10
&gt; a.x --&gt; 10
Copy<br>
<br>When used as a key, any float value that can be converted to an integer is converted
<br>&gt; a = {}
&gt; a[2.0] = 10
&gt; a[2] --&gt; 10
Copy<br>
<br>Creating a table with a proper constructor is more efficient because the table is created with the right size
<br>There is a general form constructor format where indices are written as expressions between square brackets
<br>opnames = {
["+"]  = "add",
["-"]  = "sub",
["*"]  = "mul",
["/"]  = "div",
}
Copy<br>
<br>A sequence is a table where the positive numeric keys comprise a set  for some  i.e. none of the indices store nil values (a key with nil is technically not in the table)
<br>A table with no numeric keys is a sequence with length zero
<br>The length operator (#) behaves well for sequences but not tables with holes
<br>You can traverse all key-value pairs using the pairs iterator however the order is undefined
<br>-- for tables
t = {10, print, x = 12, k = "hi"}
for k, v in pairs(t) do
	print(k, v)
end
--[[
1 10
k hi
2 function: xxxx
x 12
--]]

-- for lists use ipairs, here order is preserved
t = {10, print, 12, "hi"}
for k, v in ipairs(t) do
	print(k, v)
end
--[[
1 10
2 function: xxxx
3 12
4 hi
--]]

-- for sequences
for k = 1,#t do
	print(k, t[k])
end
Copy<br>
<br>Suppose you want to know if a given function exists in a given library (lib.foo) you can use lib and lib.foo. In C#, you can instead use the safe navigation operator (?). For a?.b if a is nil so is a?.b. You can emulate this behavior in Lua by generating an empty table if a is nil -- (a or {}).b
<br>zip = company and company.director and company.director.address and company.director.address.zipcode

-- In C#, you can instead use ? but not in Lua
zip = company?.director?.address?.zipcode

-- In Lua, you can emulate it
zip = (((company or {}).director or {}).address or {}).zipcode
Copy<br>
<br>Table operations are not efficient since they involve moving i.e. copying elements to fill gaps
<br>table.insert(t, &lt;index&gt;, value) -- inserts value at index moving elements down, defaults to end

table.remove(t, &lt;index&gt;) -- removes element from position moving all elements up, defaults to end

table.move(t, start, end, position, &lt;table2&gt;) -- moves elements in table from index start until end (inclusive) to position

table.move(a, 1, #a, 1, {}) -- copies table a into provided table and returns table

table.move(a, 1, #a, #b + 1, b) -- appends all elements from list a to end of list b
Copy<br><a data-tooltip-position="top" aria-label="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_5.lua" rel="noopener" class="external-link" href="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_5.lua" target="_blank">Exercises</a><br>
<br>Why does table.concat perform better? How is this function implemented?
<br><br>
<br>Parentheses are optional if function has only one argument that is either a string literal or a table constructor
<br>print "Hello World"
f{x=10, y=20}
type{}
Copy<br>
<br>A Lua program can use functions in both Lua and C (or any other host language). Typically, C is used for better performance and to access facilities not easily accessible directly from Lua, like OS facilities
<br>All function arguments are optional, nils are tail-padded
<br>function incCount (n)
	n = n or 1 -- If n is nil, set n to 1, default
	globalCounter = globalCounter + n
end
Copy<br>
<br>Lua functions can return multiple values which can be destructed using multiple assignments, arguments to function calls, table constructors or return statements. 
<br>function foo()
	return a, b, c
end

x, y = foo() -- x = a, y = b
x, y, z, w = foo() -- x, y, z, w = nil
x, y = foo(), 20 -- x = a, y = 20

-- when function is last or only call to another function, all results are passed

print(x, foo()) --&gt; x a b c
print(foo(), x) --&gt; a x

-- table constructor collects all results

t = {foo()} --&gt; {a, b, c}

-- return also returns all results

return foo() --&gt; a, b, c

-- you can force use of one single argument by using parentheses

print((foo())) --&gt; a
Copy<br>
<br>Lua functions can be variadic i.e. take a variable number of arguments like print in C using the varag expression (...)
<br>--- three dots '...' (called varag expression) indicate the function is variadic

function add (...)
	local s = 0
	for _, v in ipairs{...} do
		s = s + v
	end
	return s
end

print(add(3, 4, 10, 25, 12)) --&gt; 54

--[[
local a, b = ... (truncates to first two arguments or uses nil)

function foo (a, b, c) == function foo (...) local a,b,c = ...
--]]

function fwrite(fmt, ...)
	return io.write(string.format(fmt, ...))
end
Copy<br>
<br>You can use {...} to collect all the extra arguments, however, there's no way to know if explicit trailing {lua} nil were provided as some arguments -&gt; use table.pack which also has an extra field "n" with the total number of arguments
<br>function nonils(...)
	local arg = table.pack(...)
	for i = 1, arg.n do
		if arg[i] == nil then return false end
	end
	return true
end

print(nonils(2, 3, nil)) --&gt; false
print(nonils()) --&gt; true
Copy<br>
<br>Another method to traverse extra arguments is to use the select function
<br>select(n, ...) --&gt; returns all arguments after the nth one
select("#", ...) --&gt; returns total number of extra arguments

select(1, "a", "b", "c") --&gt; a b c
select(3, "a", "b", "c") --&gt; c
select("#", "a", "b", "c") --&gt; 3

-- select typically used when number of results truncated to one
-- this version of add is faster when few arguments since it avoids creation of new table however cost of multiple selects adds up as the number increases 
-- this version has quadratic cost
function add (...)
	local s = 0
	for i = 1, select("#", ...) do
		s = s + select(i, ...) -- truncates to first argument
	end
	return s
end
Copy<br>
<br>table.unpack takes a list and returns all elements as results. Important in generic call mechanism which allows us to call any function with any arguments dynamically. Function usually works on sequences since it uses length operator however you can provide explicit limits
<br>table.unpack{10, 20, 30} --&gt; 10 20 30

print(table.unpack({"Sun", "Mon", "Tue", "Wed"}, 2, 3)) --&gt; Mon    Tue
Copy<br>
<br>Lua functions do tail-call elimination. A tail call is a goto dressed as a call. It happens when a function calls another as its last action and has nothing else to do after
<br>function f (x) x = x + 1; 
	return g(x)           -- tail call, without return it isn't a tail call since f has to discard g results
end 

--[[
The program does not need to keep any information about f on the stack once g is called. Lua eliminates f information from the stack and therefore tail calls use no stack space
]]

-- In Lua, you can use an infinite number of nested tail calls and the stack will never overflow

function foo (n)
	 if n &gt; 0 then return foo(n - 1) end
end
Copy<br><a data-tooltip-position="top" aria-label="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_6.lua" rel="noopener" class="external-link" href="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_6.lua" target="_blank">Exercises</a><br>
<br>
<a data-tooltip-position="top" aria-label="https://lua-l.lua.narkive.com/IQTSNTjf/passing-parameters-by-reference#:~:text=Passing%20Parameters%20by%20Reference&amp;text=Lua%20forces%20copy%20semantics%20for,table%2C%20userdata" rel="noopener" class="external-link" href="https://lua-l.lua.narkive.com/IQTSNTjf/passing-parameters-by-reference#:~:text=Passing%20Parameters%20by%20Reference&amp;text=Lua%20forces%20copy%20semantics%20for,table%2C%20userdata" target="_blank">Passing Parameters by Reference. Lua forces copy semantics for simple value types (nil, boolean, number, string, light userdata) and&nbsp;reference semantics for complex types (function, table, userdata).</a>.)

<br>
Exercise 6.6

<br><br>
<br>Lua doesn't offer much to communicate with the external world. Like ISO C, it only offers basic file manipulation plus some extras. Most I/O is done either by the host application or through external libraries
<br>The I/O library uses two models for file manipulations<br>
<br>Simple Model<br>
- Assumes the existence of a current input and a current output streams set using the io.input and io.output functions resp and initialized to stdin and stdout resp<br>
- io.write takes an arbitrary number of strings or numbers and writes them to the output stream (avoid explicit concatenation and avoid using print unless for dirty debugging)<br>
- io.read reads strings controlled by the arguments passed to it<br>
- Can only read from (write to) a single file at a point
<br>-- to control the conversion of numbers to string, use string.format
io.write("sin(3) = ", math.sin(3), "\n") --&gt; sin(3) = 0.14112000805987
io.write(string.format("sin(3) = %.4f\n", math.sin(3))) --&gt; sin(3) = 0.1411

--[[
-- io.read reads strings based on the arguments passed to it

a - read whole file, return empty string if file is empty
l - default; read next line dropping newline, return nil if file is empty
L - read next line keeping newline, same as above
n - reads a number skipping whitespaces; if not number, return nil
num - reads st most num chars as string if eof, returns nil

io.read(0) returns nil if eof, else empty string ""
--]]

-- Lua handles strings well, filters can be written like
t = io.read("a") -- read whole file
t = string.gsub(t, "bad", "good") -- do job
io.write(t) -- write the file

-- copy input to output with line numbers
local count = 0
for line in io.lines() do 
	count = count + 1
	io.write(string.format("%6d ", count), line, "\n")
end

-- Sort a file
local lines = {}
-- read lines to table lines
for line in io.lines() do
	lines[#lines + 1] = line
end
-- sort
table.sort(lines)
-- write
for _,l in ipairs(lines) do
	io.write(l, "\n")
end

-- Efficient: Copy input to output in blocks
while true do
	local block = io.read(2^13)           -- block size = 8K
	if not block then break end
	io.write(block)
end

-- You can call read with multiple args
while true do
	local n1, n2, n3 = io.read("n", "n", "n")
	if not n1 then break end
	print(math.max(n1, n2, n3))
end
Copy<br>
<br>Complete I/O Model 

<br>io.open(&lt;name&gt;, &lt;mode&gt;) opens file name (as a stream) in one of three modes (r - read, w - truncate and write, a - append, b - optional; binary)
<br>You can use methods  (on the stream objects) read and write to read from and write to the opened stream


<br>print(io.open("non-existent-file", "r")) --&gt; nil non-existent-file: No such file or directory 2
print(io.open("/etc/passwd", "w")) --&gt; nil /etc/passwd: Permission denied 13

-- idiomatic way
local f = assert(io.open(filename, mode)) -- error message goes to second arg of assert

-- Read whole file
local f = assert(io.open(filename, "r"))
local t = f:read("a")
f:close()

-- Accessing predefined C streams - io.stdin, io.stdout and io.stderr
io.stderr:write(message)

-- Mix both models by setting streams
local temp = io.input() -- save current input stream (which is returned when no args are passed)
io.input("newinput") -- open new current stream
-- do something with stream
io.input():close() -- close current stream
io.input(temp) -- restore original input stream

-- io.read(args) === io.input():read(args)
-- io.write(args) === io.output():write(args)

-- io.lines provides an iterator that reads from a stream
-- You can provide a file name to io.lines which will open a stream over the file in read mode and will close it after reachine eof
-- iterate over blocks
for block in io.input():lines(2^13) so -- lines accepts same args as read
	io.write(block)
end
Copy<br>
<br>Other operations on files include

<br>io.tmpfile - returns stream over temporary file that gets deleted when program ends
<br>flush - executes all pending write to file
<br>setvbuf - sets buffering mode; accepts two arguments - 1. ("no" - no buffering, "full" - write when buffer is full and "line" - write when newline is output) 2. Size of buffer

<br>io.stderr is not buffered and io.stdout is line buffered


<br>f:seek(whence, offset) - seek can both get and set the current position of a stream; 

<br>whence: 

<br>"set" - offsets related to beginning of file, 
<br>"cur" - default; offsets relative to current position and 
<br>"end" - offsets relative to end of file)


<br>offset

<br>0 - default


<br>Returns current position of stream measured in bytes from the beginning of the file. 


<br>os.rename - changes name of file
<br>os.remove - deletes a file
<br>All functions return nil + error message in case of errors


<br>-- file:seek(whence, offset)
file:seek() --&gt; current stream position
file:seek("set") --&gt; resets position to beginning and returns 0
file:seek("end") --&gt; sets position to eof and returns its size

function fsize (file)
	local current = file:seek()   -- save current position
	local size = file:seek("end") -- get file size
	file:seek("set", current)     -- restore position
	return size
end
Copy<br>Other system calls:<br>
<br>os.exit(status) - terminates execution of program

<br>status - (0/true - successful execution)


<br>os.getenv(var) - gets value of an environment variable; returns nil for undefined variables
<br>os.execute - runs a system command and returns command status; returns three results

<br>Boolean 

<br>true - program exited with no errors


<br>String 

<br>"exit" - terminated normally
<br>"signal" - interrupted by a signal


<br>return status if terminated normally or the number of the signal that terminated the program


<br>os.popen - also runs system command but also connects the command output (or input) to a new local stream and returns that stream
<br>For more extended capabilities, use libraries LuaFileSystem and luaposix<br>--- os.getenv
print(os.getenv("HOME")) --&gt; /home/lua

-- Create new directories
function createDir (dirname)
	os.execute("mkdir " .. disname)
end

-- Build table with entries in current directories
local f = io.popen("ls .", "r") -- "r" means to read; default
local dir = {}
for entry in f:lines() so
	dir[#dir + 1] = entry
end

-- Send email
local subject = "some news"
local address = "someone@somewhere.org"
local cmd = string.format("mail -s '%s' '%s'", subject, address)
local f = io.popen(cmd, "w") -- in write mode
f:write([[
Nothing important to say.
-- me
]])
f:close()
Copy<br><a data-tooltip-position="top" aria-label="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_7.lua" rel="noopener" class="external-link" href="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_7.lua" target="_blank">Exercises</a><br>
<br>7.3 I'm not sure about the exact answer to the second part. This <a data-tooltip-position="top" aria-label="https://luajit.org/ext_buffer.html#:~:text=The%20maximum%20size%20of%20a,memory%20limit%20of%20your%20OS." rel="noopener" class="external-link" href="https://luajit.org/ext_buffer.html#:~:text=The%20maximum%20size%20of%20a,memory%20limit%20of%20your%20OS." target="_blank">Link</a> says the maximum size of the Lua string is just under 2GB 
<br><br>Local variables and blocks:<br>
<br>By default, variables are global in Lua.
<br>Local variables are scope-limited to the declaration block
<br>in interactive mode each line is a chunk, so if you were to use local a = 1, a goes out of scope immediately after
<br>To define blocks as in other languages using {}, you can use do ... end blocks in Lua
<br>It is good programming practice to use Local variables to avoid cluttering the global environment
<br>Book encourages declarations in the middle of blocks so we don't forget to initialize them
<br>-- blocks
do
	-- something
end

-- common idiom
local foo = foo -- done to preserve global foo
Copy<br>Control Structures<br>
<br>if then else:

<br>Lua has no switch statement


<br>while
<br>repeat-until

<br>An interesting aspect of Lua's repeat clause is that local variables declared in the repeat block are accessible in the until condition


<br>Numerical for

<br>for var = expr1, expr2, expr3 where expr3 is the step size. 
<br>All three expressions are computed only once at the beginning of the loop
<br>expr3 is optional; default 1
<br>The control variable is local to the loop and should not be reassigned inside the loop; it'll lead to unexpected behavior


<br>Generic for

<br>Traverses all values returned by an iterator function
<br>Covered in detail in <a data-tooltip-position="top" aria-label="ierusalimschy2006programming > 18 Iterators and the Generic For" data-href="ierusalimschy2006programming#18 Iterators and the Generic For" href="https://jayitha.github.io/Notes/literature-notes/ierusalimschy2006programming.html#18_Iterators_and_the_Generic_For" class="internal-link" target="_self" rel="noopener">18 Iterators and the Generic For</a>


<br>break
<br>return

<br>Implicit return at end of every function
<br>return can only appear as the last statement of a block
<br>If you want to use return in the middle of a block, use a do ... end block


<br>goto

<br>Labels have a (intentionally) convoluted syntax ::label::
<br>Labels follow the usual visibility rules; cannot jump into a block because a label inside a block is not visible outside it
<br>Cannot jump out of a function (why?)
<br>Cannot jump into the scope of a local variable (labels are void statements). Scope of a local variable ends on the last non-void statement of the block where the label is defined
<br>Usually used to simulate programming constructs from other languages like redo and continue
<br>Good at directly translating state machines


<br>-- if then else
if op == '+' then
	r = a + b
elseif op == '-' then
	r = a - b
else -- optional
	error("invalid operation")

-- while
local i = 1
while a[i] do
	print(a[i])
	i = i + 1
end

-- repeat-until
-- computes square root of 'x' using Newton-Raphson method
local sqr = x / 2
repeat
	sqr = (sqr + x/sqr) / 2
	local error = math.abs(sqr^2 - x)
until error &lt; x / 10000                -- local 'error' 

-- Numerical for
-- syntax
for var = expr2, expr2, expr3 do
	-- something
end

-- when you want a loop without an upper limit, use math.huge
for i = 1, math.huge do                 -- what's the value of math.huge?
	-- something
end

--- goto
-- simulate redo and continue
while some_condition do
	::redo::
	if some_other_condition then goto continue
	else if yet_another_condition then goto redo
	end
	-- some code
	::continue::
end

-- labels are void statements
while some_condition do
	if some_other_condition then goto continue end
	local var = something
	::continue::                  -- scope of 'var' ends before continue
end

-- state machine to check if input has even number of zeros
::s1:: do                 -- does this not automatically start executing?
	local c = io.read(1)
	if c == '0' then goto s2
	elseif c == nil then print "ok"; return
	else goto s1
	end
end

::s2:: do
	local c = io.read(1)
	if c == '0' then goto s1
	elseif c == nil then print "not ok"; return
	else goto s2
	end
end

goto s1            -- not needed to start the program
Copy<br><a data-tooltip-position="top" aria-label="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_8.lua" rel="noopener" class="external-link" href="https://github.com/Jayitha/Notes/blob/main/Misc/Lua/chapter_8.lua" target="_blank">Exercises</a><br>
<br>what's the value of math.huge ?
<br>The <a data-tooltip-position="top" aria-label="http://lua-users.org/wiki/MathLibraryTutorial" rel="noopener" class="external-link" href="http://lua-users.org/wiki/MathLibraryTutorial" target="_blank">Link</a> says math.huge is a constant and represents infinity
<br><br><a href="https://jayitha.github.io/Notes?query=tag:todo" class="tag" target="_blank" rel="noopener">#todo</a><br><br><br>: ]]></description><link>https://jayitha.github.io/Notes/literature-notes/ierusalimschy2006programming.html</link><guid isPermaLink="false">Literature Notes/ierusalimschy2006programming.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:25:47 GMT</pubDate></item><item><title><![CDATA[Wrangler: Interactive visual specification of data transformation scripts]]></title><description><![CDATA[ 
 <br><br>Sean Kandel, Andreas Paepcke, Joseph Hellerstein, Jeffrey Heer (2011)<br>Tags: <br>Abstract
Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such "data wrangling" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kandel2011wrangler.html</link><guid isPermaLink="false">Literature Notes/kandel2011wrangler.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:14:42 GMT</pubDate></item><item><title><![CDATA[Hyper: Hybrid OLTP&amp;OLAP high performance database system]]></title><description><![CDATA[ 
 <br><br>Alfons Kemper, Thomas Neumann (2010)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
The two areas of online transaction processing (OLTP) and online analytical processing (OLAP) present different challenges for database architectures. Currently, customers with high rates of mission-critical transactions have split their data into two separate systems, one database for OLTP and one so-called data warehouse for OLAP. While allowing for decent transaction rates, this separation has many disadvantages including data freshness issues due to the delay caused by only periodically initiating the Extract Transform Load-data staging and excessive resource consumption due to maintaining two separate information systems. We present an efficient hybrid system, called HyPer, that can handle both OLTP and OLAP simultaneously by using hardware-assisted replication mechanisms to maintain consistent snapshots of the transactional data. HyPer is a main-memory database system that guarantees the ACID properties of OLTP transactions and executes OLAP query sessions (multiple queries) on the same, arbitrarily current and consistent snapshot. The utilization of the processor-inherent support for virtual memory management (address transalation, caching, copy on update) yields both at the same time: unprecedented high transaction rates as high as several 100000 per second and ultra-low OLAP query response times of as low as 10 ms  all on a commodity desktop server. Even the creation of a fresh, transaction-consistent snapshot can be achieved in 10 ms.
<br>OLTP<br>
<br>Online transaction processing
<br>transactions access and process only a small portion of the entire data
<br>OLAP<br>
<br>Online Analytical Processing
<br>Brought about from BI-applications (Business Intelligence)
<br>Process substantial portions of the data to generate reports for BI
<br>Initial approaches to perform OLAP on OLTP databases were dismissed since OLAP query processing led to resource contentions hurting transaction processing<br>A separate Data Warehouse system is installed for BI. Periodically, OLTP database changes are Extracted, Transformed and Loaded (ETL) into the data warehouse. <br><img alt="Pasted image 20240202140825.png" src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240202140825.png"><br>This approach has several drawbacks:<br>
<br>stale data - ETL is only executed periodically
<br>redundancy - cost of maintaining redundant copies of two systems. However, two systems enables customized models for execution - normalized tables for OLTP and star-schema for OLAP
<br>high investments - maintaining two systems has economic penalty (hardware, software...)
<br>Strong arguments for real time business intelligence advocates for removing the separation (from this point, simply dubbed "the gap") between OLTP and OLAP systems.<br>Paper argues that the performance improvements needed to bridge the gap can be achieved through main memory database.<br>Paper argues that critical transactional database volume is limited is size. Furthermore, the size of the main memory is expected to grow faster than the largest business customer's requirements.<br>HyPer uses a main-memory architecture for transaction processing using a single-threading (cite:[15]) approach where OLTP transactions are executed sequentially.<br>Hyper Features

<br>Main-Memory Architecture for transaction processing
<br>Single-threaded processing

<br>Obviates the need for locking and latching



<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/kemper2010hyper.html</link><guid isPermaLink="false">Literature Notes/kemper2010hyper.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 02 Feb 2024 16:40:17 GMT</pubDate><enclosure url="https://jayitha.github.io/Notes/lib/media/pasted-image-20240202140825.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240202140825.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Everything you always wanted to know about compiled and vectorized queries but were afraid to ask]]></title><description><![CDATA[ 
 <br><br>Timo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz (2018)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Timo-Kersten" class="tag" target="_blank" rel="noopener">#Timo-Kersten</a> <a href="https://jayitha.github.io/Notes?query=tag:Viktor-Leis" class="tag" target="_blank" rel="noopener">#Viktor-Leis</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Pavlo" class="tag" target="_blank" rel="noopener">#Andrew-Pavlo</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Boncz" class="tag" target="_blank" rel="noopener">#Peter-Boncz</a><br>Abstract
The query engines of most modern database systems are either based on vectorization or data-centric code generation. These two state-of-the-art query processing paradigms are fundamentally different in terms of system structure and query execution code. Both paradigms were used to build fast systems. However, until today it is not clear which paradigm yields faster query execution, as many implementation-specific choices obstruct a direct comparison of architectures. In this paper, we experimentally compare the two models by implementing both within the same test system. This allows us to use for both models the same query processing algorithms, the same data structures, and the same parallelization framework to ultimately create an apples-to-apples comparison. We find that both are efficient, but have different strengths and weaknesses. Vectorization is better at hiding cache miss latency, whereas data-centric compilation requires fewer CPU instructions, which benefits cache-resident workloads. Besides raw, single-threaded performance, we also investigate SIMD as well as multi-core parallelization and different hardware architectures. Finally, we analyze qualitative differences as a guide for system architects.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kersten2018everything.html</link><guid isPermaLink="false">Literature Notes/kersten2018everything.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:30:55 GMT</pubDate></item><item><title><![CDATA[How to read a paper]]></title><description><![CDATA[ 
 <br><br>Srinivasan Keshav (2007)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Srinivasan-Keshav" class="tag" target="_blank" rel="noopener">#Srinivasan-Keshav</a> <a href="https://jayitha.github.io/Notes?query=tag:read" class="tag" target="_blank" rel="noopener">#read</a><br>Abstract
Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.
<br>
<br>Three-pass method for reading research papers

<br>The First Pass

<br>Quick scan to get bird's eye view of paper
<br>Should take upto 5-10 mins
<br>Consists of the following steps

<br>Carefully read title, abstract and introduction (and related work if writing a survey)
<br>Read section and sub-section headings only
<br>Skim math to see if you have the theoretical foundations
<br>Read conclusion
<br>Skim references to take stock of which ones you've read


<br>After first pass you should be able to answer the five Cs

<br>Category - type of paper
<br>Context - related papers
<br>Correctness
<br>Contributions
<br>Clarity


<br>If a reviewer cannot understand your paper after the first pass, it is likely to be rejected; advocates graphical abstracts (summarize paper with a single figure)


<br>The Second Pass

<br>Read paper ignoring details like proofs
<br>Should take upto an hour (for an exp. reader)
<br>Jot down key points
<br>Note down terms you don't understand
<br>Note down questions you might want to ask the author
<br>If you're reviewing, pay special attention to the figures, diagrams, illustrations and plots

<br>Make sure conclusions are drawn from statistically significant plots


<br>Mark unread references for future reading


<br>The Third Pass

<br>Attempt to virtually re-implement the paper
<br>Can take many hours for a beginner and 2 or more for an exp. reader
<br>By re-creating the work you may better understand where the work fails and if invalid (or implicit) assumptions were made
<br>Challenge every assumption in every statement
<br>Jot down ideas for future work
<br>You should be able to reconstruct the entire paper from memory and identify weak and strong points
<br>You should also be able to point out missing citations and issues with experimental and analytical content




<br>Literature Survey

<br>Use GoogleScholar and some key words to find 5 recent highly-cited papers
<br>Do the first pass over these papers and the related work section
<br>If a survey exists, read the survey
<br>Else, find shared citations and repeated authors. Track down important conferences and journals
<br>Go through these venues to find high quality related work
<br>Make two passes through these papers, generating the first version of your survey
<br>Identify unread key papers from set and iterate as necessary


<br><img alt="Pasted image 20231226173413.png" src="https://jayitha.github.io/Notes/lib/media/pasted-image-20231226173413.png"><br>
Source: From Paper<br>Resources<br>
<br>
<a data-tooltip-position="top" aria-label="roscoe2007writing" data-href="roscoe2007writing" href="https://jayitha.github.io/Notes/literature-notes/roscoe2007writing.html" class="internal-link" target="_self" rel="noopener">Writing reviews for systems conferences</a>

<br>
<a data-tooltip-position="top" aria-label="http://www.cs.columbia.edu/%E2%88%BChgs/etc/writing-style.html" rel="noopener" class="external-link" href="http://www.cs.columbia.edu/%E2%88%BChgs/etc/writing-style.html" target="_blank">H. Schulzrinne, “Writing Technical Articles”</a>

<br>
[G.M. Whitesides, “Whitesides’ Group: Writing a Paper”](<a data-tooltip-position="top" aria-label="http://www.ee.ucr.edu/%E2%88%BCrlake/Whitesides" rel="noopener" class="external-link" href="http://www.ee.ucr.edu/%E2%88%BCrlake/Whitesides" target="_blank">http://www.ee.ucr.edu/∼rlake/Whitesides</a> writing res paper.pdf)

<br>
[S. Peyton Jones, “Research Skills”](<a rel="noopener" class="external-link" href="http://research.microsoft.com/en-" target="_blank">http://research.microsoft.com/en-</a> us/um/people/simonpj/papers/giving-a-talk/giving-a- talk.htm)

<br>
]]></description><link>https://jayitha.github.io/Notes/literature-notes/keshav2007read.html</link><guid isPermaLink="false">Literature Notes/keshav2007read.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 26 Dec 2023 12:10:49 GMT</pubDate><enclosure url="https://jayitha.github.io/Notes/lib/media/pasted-image-20231226173413.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://jayitha.github.io/Notes/lib/media/pasted-image-20231226173413.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Learned cardinalities: Estimating correlated joins with deep learning]]></title><description><![CDATA[ 
 <br><br>Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, Alfons Kemper (2018)<br>Tags: <br>Abstract
We describe a new deep learning approach to cardinality estimation. MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities. MSCN builds on sampling-based estimation, addressing its weaknesses when no sampled tuples qualify a predicate, and in capturing join-crossing correlations. Our evaluation of MSCN using a real-world dataset shows that deep learning significantly enhances the quality of cardinality estimation, which is the core problem in query optimization.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kipf2018learned.html</link><guid isPermaLink="false">Literature Notes/kipf2018learned.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:47 GMT</pubDate></item><item><title><![CDATA[seL4: Formal verification of an OS kernel]]></title><description><![CDATA[ 
 <br><br>Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe, Kai Engelhardt, Rafal Kolanski, Michael Norrish, others (2009)<br>Tags: <br>Abstract
Complete formal verification is the only known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/klein2009sel4.html</link><guid isPermaLink="false">Literature Notes/klein2009sel4.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:16 GMT</pubDate></item><item><title><![CDATA[Comprehensive formal verification of an OS microkernel]]></title><description><![CDATA[ 
 <br><br>Gerwin Klein, June Andronick, Kevin Elphinstone, Toby Murray, Thomas Sewell, Rafal Kolanski, Gernot Heiser (2014)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Gerwin-Klein" class="tag" target="_blank" rel="noopener">#Gerwin-Klein</a> <a href="https://jayitha.github.io/Notes?query=tag:June-Andronick" class="tag" target="_blank" rel="noopener">#June-Andronick</a> <a href="https://jayitha.github.io/Notes?query=tag:Kevin-Elphinstone" class="tag" target="_blank" rel="noopener">#Kevin-Elphinstone</a> <a href="https://jayitha.github.io/Notes?query=tag:Toby-Murray" class="tag" target="_blank" rel="noopener">#Toby-Murray</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Sewell" class="tag" target="_blank" rel="noopener">#Thomas-Sewell</a> <a href="https://jayitha.github.io/Notes?query=tag:Rafal-Kolanski" class="tag" target="_blank" rel="noopener">#Rafal-Kolanski</a> <a href="https://jayitha.github.io/Notes?query=tag:Gernot-Heiser" class="tag" target="_blank" rel="noopener">#Gernot-Heiser</a><br>Abstract
We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel. We discuss the kernel design we used to make its verification tractable. We then describe the functional correctness proof of the kernel's C implementation and we cover further steps that transform this result into a comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary code of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a proof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and an automatic initialiser for user-level systems that connects kernel-level access-control enforcement with reasoning about system behaviour. We summarise these results and show how they integrate to form a coherent overall analysis, backed by machine-checked, end-to-end theorems. The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully formally verified to this degree. It is also the only example of formal proof of this scale that is kept current as the requirements, design and implementation of the system evolve over almost a decade. We report on our experience in maintaining this evolving formally verified code base.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/klein2014comprehensive.html</link><guid isPermaLink="false">Literature Notes/klein2014comprehensive.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:23 GMT</pubDate></item><item><title><![CDATA[Designing data-intensive applications: The big ideas behind reliable, scalable, and maintainable systems]]></title><description><![CDATA[ 
 <br><br>Martin Kleppmann (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Martin-Kleppmann" class="tag" target="_blank" rel="noopener">#Martin-Kleppmann</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br><br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/kleppmann2014designing.html</link><guid isPermaLink="false">Literature Notes/kleppmann2014designing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 14 Mar 2024 13:31:22 GMT</pubDate></item><item><title><![CDATA[Spectre attacks: Exploiting speculative execution]]></title><description><![CDATA[ 
 <br><br>Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, others (2020)<br>Tags: <br>Abstract
Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side-channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, such as operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems because vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. Although makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kocher2020spectre.html</link><guid isPermaLink="false">Literature Notes/kocher2020spectre.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:37:11 GMT</pubDate></item><item><title><![CDATA[Concurrency and recovery in generalized search trees]]></title><description><![CDATA[ 
 <br><br>Marcel Kornacker, C Mohan, Joseph M Hellerstein (1997)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Marcel-Kornacker" class="tag" target="_blank" rel="noopener">#Marcel-Kornacker</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Mohan" class="tag" target="_blank" rel="noopener">#C-Mohan</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a><br>Abstract
This paper presents general algorithms for concurrency control in tree-based access methods as well as a recovery protocol and a mechanism for ensuring repeatable read. The algorithms are developed in the context of the Generalized Search Tree (GiST) data structure, an index structure supporting an extensible set of queries and data types. Although developed in a GiST context, the algorithms are generally applicable to many tree-based access methods. The concurrency control protocol is based on an extension of the link technique originally developed for B-trees, and completely avoids holding node locks during I/Os. Repeatable read isolation is achieved with a novel combination of predicate locks and two-phase locking of data records. To our knowledge, this is the first time that isolation issues have been addressed outside the context of B-trees. A discussion of the fundamental structural differences between B-trees and more general tree structures like GiSTs explains why the algorithms developed here deviate from their B-tree counterparts. An implementation of GiSTs emulating B-trees in DB2/Common Server is underway.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kornacker1997concurrency.html</link><guid isPermaLink="false">Literature Notes/kornacker1997concurrency.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:07:20 GMT</pubDate></item><item><title><![CDATA[The case for learned index structures]]></title><description><![CDATA[ 
 <br><br>Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, Neoklis Polyzotis (2018)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Kraska" class="tag" target="_blank" rel="noopener">#Tim-Kraska</a> <a href="https://jayitha.github.io/Notes?query=tag:Alex-Beutel" class="tag" target="_blank" rel="noopener">#Alex-Beutel</a> <a href="https://jayitha.github.io/Notes?query=tag:Ed" class="tag" target="_blank" rel="noopener">#Ed</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Chi" class="tag" target="_blank" rel="noopener">#H-Chi</a> <a href="https://jayitha.github.io/Notes?query=tag:Jeffrey-Dean" class="tag" target="_blank" rel="noopener">#Jeffrey-Dean</a> <a href="https://jayitha.github.io/Notes?query=tag:Neoklis-Polyzotis" class="tag" target="_blank" rel="noopener">#Neoklis-Polyzotis</a><br>Abstract
Indexes are models: a \btree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term \em learned indexes. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show that our learned indexes can have significant advantages over traditional indexes. More importantly, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work provides just a glimpse of what might be possible.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kraska2018case.html</link><guid isPermaLink="false">Literature Notes/kraska2018case.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:34:30 GMT</pubDate></item><item><title><![CDATA[Activeclean: Interactive data cleaning for statistical modeling]]></title><description><![CDATA[ 
 <br><br>Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J Franklin, Ken Goldberg (2016)<br>Tags: <br>Abstract
Analysts often clean dirty data iteratively–cleaning some data, executing the analysis, and then cleaning more data based on the results. We explore the iterative cleaning process in the context of statistical model training, which is an increasingly popular form of data analytics. We propose ActiveClean, which allows for progressive and iterative cleaning in statistical modeling problems while preserving convergence guarantees. ActiveClean supports an important class of models called convex loss models (e.g., linear regression and SVMs), and prioritizes cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, IMDB, and Dollars For Docs with both real and synthetic errors. The results show that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget and on all real dirty datasets, ActiveClean returns more accurate models than uniform sampling and Active Learning.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/krishnan2016activeclean.html</link><guid isPermaLink="false">Literature Notes/krishnan2016activeclean.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:15:07 GMT</pubDate></item><item><title><![CDATA[The case for a learned sorting algorithm]]></title><description><![CDATA[ 
 <br><br>Ani Kristo, Kapil Vaidya, Ugur Çetintemel, Sanchit Misra, Tim Kraska (2020)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Ani-Kristo" class="tag" target="_blank" rel="noopener">#Ani-Kristo</a> <a href="https://jayitha.github.io/Notes?query=tag:Kapil-Vaidya" class="tag" target="_blank" rel="noopener">#Kapil-Vaidya</a> <a href="https://jayitha.github.io/Notes?query=tag:Ugur-Çetintemel" class="tag" target="_blank" rel="noopener">#Ugur-Çetintemel</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanchit-Misra" class="tag" target="_blank" rel="noopener">#Sanchit-Misra</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Kraska" class="tag" target="_blank" rel="noopener">#Tim-Kraska</a><br>Abstract
Sorting is one of the most fundamental algorithms in Computer Science and a common operation in databases not just for sorting query results but also as part of joins (i.e., sort-merge-join) or indexing. In this work, we introduce a new type of distribution sort that leverages a learned model of the empirical CDF of the data. Our algorithm uses a model to efficiently get an approximation of the scaled empirical CDF for each record key and map it to the corresponding position in the output array. We then apply a deterministic sorting algorithm that works well on nearly-sorted arrays (e.g., Insertion Sort) to establish a totally sorted order. We compared this algorithm against common sorting approaches and measured its performance for up to 1 billion normally-distributed double-precision keys. The results show that our approach yields an average 3.38x performance improvement over C++ STL sort, which is an optimized Quicksort hybrid, 1.49x improvement over sequential Radix Sort, and 5.54x improvement over a C++ implementation of Timsort, which is the default sorting function for Java and Python.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kristo2020case.html</link><guid isPermaLink="false">Literature Notes/kristo2020case.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:14 GMT</pubDate></item><item><title><![CDATA[Oceanstore: An architecture for global-scale persistent storage]]></title><description><![CDATA[ 
 <br><br>John Kubiatowicz, David Bindel, Yan Chen, Steven Czerwinski, Patrick Eaton, Dennis Geels, Ramakrishna Gummadi, Sean Rhea, Hakim Weatherspoon, Westley Weimer, others (2000)<br>Tags: <br>Abstract
OceanStore is a utility infrastructure designed to span the globe and provide continuous access to persistent information. Since this infrastructure is comprised of untrusted servers, data is protected through redundancy and cryptographic techniques. To improve performance, data is allowed to be cached anywhere, anytime. Additionally, monitoring of usage patterns allows adaptation to regional outages and denial of service attacks; monitoring also enhances performance through pro-active movement of data. A prototype implementation is currently under development.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kubiatowicz2000oceanstore.html</link><guid isPermaLink="false">Literature Notes/kubiatowicz2000oceanstore.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:03:45 GMT</pubDate></item><item><title><![CDATA[An optimality theory of concurrency control for databases]]></title><description><![CDATA[ 
 <br><br>Hsing-Tsung Kung, Christos H Papadimitriou (1979)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Hsing-Tsung-Kung" class="tag" target="_blank" rel="noopener">#Hsing-Tsung-Kung</a> <a href="https://jayitha.github.io/Notes?query=tag:Christos" class="tag" target="_blank" rel="noopener">#Christos</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Papadimitriou" class="tag" target="_blank" rel="noopener">#H-Papadimitriou</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/kung1979optimality.html</link><guid isPermaLink="false">Literature Notes/kung1979optimality.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:04:04 GMT</pubDate></item><item><title><![CDATA[Model and verification of a data manager based on ARIES]]></title><description><![CDATA[ 
 <br><br>Dean Kuo (1996)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Dean-Kuo" class="tag" target="_blank" rel="noopener">#Dean-Kuo</a><br>Abstract
In this article, we model and verify a data manager whose algorithm is based on ARIES. The work uses the I/O automata method as the formal model and the definition of correctness is defined on the interface between the scheduler and the data manager.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/kuo1996model.html</link><guid isPermaLink="false">Literature Notes/kuo1996model.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:36:34 GMT</pubDate></item><item><title><![CDATA[Keep CALM and CRDT on]]></title><description><![CDATA[ 
 <br><br>Shadaj Laddad, Conor Power, Mae Milano, Alvin Cheung, Natacha Crooks, Joseph M Hellerstein (2022)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Shadaj-Laddad" class="tag" target="_blank" rel="noopener">#Shadaj-Laddad</a> <a href="https://jayitha.github.io/Notes?query=tag:Conor-Power" class="tag" target="_blank" rel="noopener">#Conor-Power</a> <a href="https://jayitha.github.io/Notes?query=tag:Mae-Milano" class="tag" target="_blank" rel="noopener">#Mae-Milano</a> <a href="https://jayitha.github.io/Notes?query=tag:Alvin-Cheung" class="tag" target="_blank" rel="noopener">#Alvin-Cheung</a> <a href="https://jayitha.github.io/Notes?query=tag:Natacha-Crooks" class="tag" target="_blank" rel="noopener">#Natacha-Crooks</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a><br>Abstract
Despite decades of research and practical experience, developers have few tools for programming reliable distributed applications without resorting to expensive coordination techniques. Conflict-free replicated datatypes (CRDTs) are a promising line of work that enable coordination-free replication and offer certain eventual consistency guarantees in a relatively simple object-oriented API. Yet CRDT guarantees extend only to data updates; observations of CRDT state are unconstrained and unsafe. We propose an agenda that embraces the simplicity of CRDTs, but provides richer, more uniform guarantees. We extend CRDTs with a query model that reasons about which queries are safe without coordination by applying monotonicity results from the CALM Theorem, and lay out a larger agenda for developing CRDT data stores that let developers safely and efficiently interact with replicated application state.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/laddad2022keep.html</link><guid isPermaLink="false">Literature Notes/laddad2022keep.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:18:49 GMT</pubDate></item><item><title><![CDATA[Snowflock: Rapid virtual machine cloning for cloud computing]]></title><description><![CDATA[ 
 <br><br>Horacio Andrés Lagar-Cavilla, Joseph Andrew Whitney, Adin Matthew Scannell, Philip Patchin, Stephen M Rumble, Eyal De Lara, Michael Brudno, Mahadev Satyanarayanan (2009)<br>Tags: <br>Abstract
Virtual Machine (VM) fork is a new cloud computing abstraction that instantaneously clones a VM into multiple replicas running on different hosts. All replicas share the same initial state, matching the intuitive semantics of stateful worker creation. VM fork thus enables the straightforward creation and efficient deployment of many tasks demanding swift instantiation of stateful workers in a cloud environment, e.g. excess load handling, opportunistic job placement, or parallel computing. Lack of instantaneous stateful cloning forces users of cloud computing into ad hoc practices to manage application state and cycle provisioning. We present SnowFlock, our implementation of the VM fork abstraction. To evaluate SnowFlock, we focus on the demanding scenario of services requiring on-the-fly creation of hundreds of parallel workers in order to solve computationally-intensive queries in seconds. These services are prominent in fields such as bioinformatics, finance, and rendering. SnowFlock provides sub-second VM cloning, scales to hundreds of workers, consumes few cloud I/O resources, and has negligible runtime overhead.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lagar2009snowflock.html</link><guid isPermaLink="false">Literature Notes/lagar2009snowflock.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:50 GMT</pubDate></item><item><title><![CDATA[The vertica analytic database: C-store 7 years later]]></title><description><![CDATA[ 
 <br><br>Andrew Lamb, Matt Fuller, Ramakrishna Varadarajan, Nga Tran, Ben Vandier, Lyric Doshi, Chuck Bear (2012)<br>Tags: <br>Abstract
This paper describes the system architecture of the Vertica Analytic Database (Vertica), a commercialization of the design of the C-Store research prototype. Vertica demonstrates a modern commercial RDBMS system that presents a classical relational interface while at the same time achieving the high performance expected from modern "web scale" analytic systems by making appropriate architectural choices. Vertica is also an instructive lesson in how academic systems research can be directly commercialized into a successful product.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lamb2012vertica.html</link><guid isPermaLink="false">Literature Notes/lamb2012vertica.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:29 GMT</pubDate></item><item><title><![CDATA[The byzantine generals problem]]></title><description><![CDATA[ 
 <br><br>Leslie Lamport, Robert Shostak, Marshall Pease (1982)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Leslie-Lamport" class="tag" target="_blank" rel="noopener">#Leslie-Lamport</a> <a href="https://jayitha.github.io/Notes?query=tag:Robert-Shostak" class="tag" target="_blank" rel="noopener">#Robert-Shostak</a> <a href="https://jayitha.github.io/Notes?query=tag:Marshall-Pease" class="tag" target="_blank" rel="noopener">#Marshall-Pease</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/lamport1982byzantine.html</link><guid isPermaLink="false">Literature Notes/lamport1982byzantine.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:44 GMT</pubDate></item><item><title><![CDATA[The part-time parliament]]></title><description><![CDATA[ 
 <br><br>Leslie Lamport (1998)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Leslie-Lamport" class="tag" target="_blank" rel="noopener">#Leslie-Lamport</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/lamport1998part.html</link><guid isPermaLink="false">Literature Notes/lamport1998part.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:13 GMT</pubDate></item><item><title><![CDATA[Paxos made simple]]></title><description><![CDATA[ 
 <br><br>Leslie Lamport (2001)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Leslie-Lamport" class="tag" target="_blank" rel="noopener">#Leslie-Lamport</a><br>Abstract
At the PODC 2001 conference, I got tired of everyone saying how difficult it was to understand the Paxos algorithm, published in [122]. Although people got so hung up in the pseudo-Greek names that they found the paper hard to understand, the algorithm itself is very simple. So, I cornered a couple of people at the conference and explained the algorithm to them orally, with no paper. When I got home, I wrote down the explanation as a short note, which I later revised based on comments from Fred Schneider and Butler Lampson. The current version is 13 pages long, and contains no formula more complicated than n1 &gt; n2.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lamport2001paxos.html</link><guid isPermaLink="false">Literature Notes/lamport2001paxos.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:17 GMT</pubDate></item><item><title><![CDATA[Time, clocks, and the ordering of events in a distributed system]]></title><description><![CDATA[ 
 <br><br>Leslie Lamport (2019)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Leslie-Lamport" class="tag" target="_blank" rel="noopener">#Leslie-Lamport</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/lamport2019time.html</link><guid isPermaLink="false">Literature Notes/lamport2019time.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:44:59 GMT</pubDate></item><item><title><![CDATA[High-performance concurrency control mechanisms for main-memory databases]]></title><description><![CDATA[ 
 <br><br>Per-Åke Larson, Spyros Blanas, Cristian Diaconu, Craig Freedman, Jignesh M Patel, Mike Zwilling (2011)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Per-Åke-Larson" class="tag" target="_blank" rel="noopener">#Per-Åke-Larson</a> <a href="https://jayitha.github.io/Notes?query=tag:Spyros-Blanas" class="tag" target="_blank" rel="noopener">#Spyros-Blanas</a> <a href="https://jayitha.github.io/Notes?query=tag:Cristian-Diaconu" class="tag" target="_blank" rel="noopener">#Cristian-Diaconu</a> <a href="https://jayitha.github.io/Notes?query=tag:Craig-Freedman" class="tag" target="_blank" rel="noopener">#Craig-Freedman</a> <a href="https://jayitha.github.io/Notes?query=tag:Jignesh" class="tag" target="_blank" rel="noopener">#Jignesh</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Patel" class="tag" target="_blank" rel="noopener">#M-Patel</a> <a href="https://jayitha.github.io/Notes?query=tag:Mike-Zwilling" class="tag" target="_blank" rel="noopener">#Mike-Zwilling</a><br>Abstract
A database system optimized for in-memory storage can support much higher transaction rates than current systems. However, standard concurrency control methods used today do not scale to the high transaction rates achievable by such systems. In this paper we introduce two efficient concurrency control methods specifically designed for main-memory databases. Both use multiversioning to isolate read-only transactions from updates but differ in how atomicity is ensured: one is optimistic and one is pessimistic. To avoid expensive context switching, transactions never block during normal processing but they may have to wait before commit to ensure correct serialization ordering. We also implemented a main-memory optimized version of single-version locking. Experimental results show that while single-version locking works well when transactions are short and contention is low performance degrades under more demanding conditions. The multiversion schemes have higher overhead but are much less sensitive to hotspots and the presence of long-running transactions.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/larson2011high.html</link><guid isPermaLink="false">Literature Notes/larson2011high.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:12:58 GMT</pubDate></item><item><title><![CDATA[Efficient locking for concurrent operations on B-trees]]></title><description><![CDATA[ 
 <br><br>Philip L Lehman, S Bing Yao (1981)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Philip" class="tag" target="_blank" rel="noopener">#Philip</a> <a href="https://jayitha.github.io/Notes?query=tag:L-Lehman" class="tag" target="_blank" rel="noopener">#L-Lehman</a> <a href="https://jayitha.github.io/Notes?query=tag:S" class="tag" target="_blank" rel="noopener">#S</a> <a href="https://jayitha.github.io/Notes?query=tag:Bing-Yao" class="tag" target="_blank" rel="noopener">#Bing-Yao</a><br>Abstract
The B-tree and its variants have been found to be highly useful (both theoretically and in practice) for storing large amounts of information, especially on secondary storage devices. We examine the problem of overcoming the inherent difficulty of concurrent operations on such structures, using a practical storage model. A single additional “link” pointer in each node allows a process to easily recover from tree modifications performed by other concurrent processes. Our solution compares favorably with earlier solutions in that the locking scheme is simpler (no read-locks are used) and only a (small) constant number of nodes are locked by any update process at any given time. An informal correctness proof for our system is given.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lehman1981efficient.html</link><guid isPermaLink="false">Literature Notes/lehman1981efficient.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:07:01 GMT</pubDate></item><item><title><![CDATA[The adaptive radix tree: ARTful indexing for main-memory databases]]></title><description><![CDATA[ 
 <br><br>Viktor Leis, Alfons Kemper, Thomas Neumann (2013)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Viktor-Leis" class="tag" target="_blank" rel="noopener">#Viktor-Leis</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a> <a href="https://jayitha.github.io/Notes?query=tag:read" class="tag" target="_blank" rel="noopener">#read</a><br>Abstract
Main memory capacities have grown up to a point where most databases fit into RAM. For main-memory database systems, index structure performance is a critical bottleneck. Traditional in-memory data structures like balanced binary search trees are not efficient on modern hardware, because they do not optimally utilize on-CPU caches. Hash tables, also often used for main-memory indexes, are fast but only support point queries. To overcome these shortcomings, we present ART, an adaptive radix tree (trie) for efficient indexing in main memory. Its lookup performance surpasses highly tuned, read-only search trees, while supporting very efficient insertions and deletions as well. At the same time, ART is very space efficient and solves the problem of excessive worst-case space consumption, which plagues most radix trees, by adaptively choosing compact and efficient data structures for internal nodes. Even though ART's performance is comparable to hash tables, it maintains the data in sorted order, which enables additional operations like range scan and prefix lookup.
<br><br>Dataview: No results to show for list query.]]></description><link>https://jayitha.github.io/Notes/literature-notes/leis2013adaptive.html</link><guid isPermaLink="false">Literature Notes/leis2013adaptive.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 25 Jan 2024 05:18:52 GMT</pubDate></item><item><title><![CDATA[Morsel-driven parallelism: A NUMA-aware query evaluation framework for the many-core age]]></title><description><![CDATA[ 
 <br><br>Viktor Leis, Peter Boncz, Alfons Kemper, Thomas Neumann (2014)<br>Tags: <br>Abstract
With modern computer architecture evolving, two problems conspire against the state-of-the-art approaches in parallel query execution: (i) to take advantage of many-cores, all query work must be distributed evenly among (soon) hundreds of threads in order to achieve good speedup, yet (ii) dividing the work evenly is difficult even with accurate data statistics due to the complexity of modern out-of-order cores. As a result, the existing approaches for plan-driven parallelism run into load balancing and context-switching bottlenecks, and therefore no longer scale. A third problem faced by many-core architectures is the decentralization of memory controllers, which leads to Non-Uniform Memory Access (NUMA). In response, we present the morsel-driven query execution framework, where scheduling becomes a fine-grained run-time task that is NUMA-aware. Morsel-driven query processing takes small fragments of input data (morsels) and schedules these to worker threads that run entire operator pipelines until the next pipeline breaker. The degree of parallelism is not baked into the plan but can elastically change during query execution, so the dispatcher can react to execution speed of different morsels but also adjust resources dynamically in response to newly arriving queries in the workload. Further, the dispatcher is aware of data locality of the NUMA-local morsels and operator state, such that the great majority of executions takes place on NUMA-local memory. Our evaluation on the TPC-H and SSB benchmarks shows extremely high absolute performance and an average speedup of over 30 with 32 cores.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/leis2014morsel.html</link><guid isPermaLink="false">Literature Notes/leis2014morsel.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:12:11 GMT</pubDate></item><item><title><![CDATA[How good are query optimizers, really?]]></title><description><![CDATA[ 
 <br><br>Viktor Leis, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, Thomas Neumann (2015)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Viktor-Leis" class="tag" target="_blank" rel="noopener">#Viktor-Leis</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrey-Gubichev" class="tag" target="_blank" rel="noopener">#Andrey-Gubichev</a> <a href="https://jayitha.github.io/Notes?query=tag:Atanas-Mirchev" class="tag" target="_blank" rel="noopener">#Atanas-Mirchev</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Boncz" class="tag" target="_blank" rel="noopener">#Peter-Boncz</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a><br>Abstract
Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/leis2015good.html</link><guid isPermaLink="false">Literature Notes/leis2015good.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:39 GMT</pubDate></item><item><title><![CDATA[LeanStore: In-memory data management beyond main memory]]></title><description><![CDATA[ 
 <br><br>Viktor Leis, Michael Haubenschild, Alfons Kemper, Thomas Neumann (2018)<br>Tags: <br>Abstract
Disk-based database systems use buffer managers in order to transparently manage data sets larger than main memory. This traditional approach is effective at minimizing the number of I/O operations, but is also the major source of overhead in comparison with in-memory systems. To avoid this overhead, in-memory database systems therefore abandon buffer management altogether, which makes handling data sets larger than main memory very difficult. In this work, we revisit this fundamental dichotomy and design a novel storage manager that is optimized for modern hardware. Our evaluation, which is based on TPC-C and micro benchmarks, shows that our approach has little overhead in comparison with a pure in-memory system when all data resides in main memory. At the same time, like a traditional buffer manager, it is fully transparent and can manage very large data sets effectively. Furthermore, due to low-overhead synchronization, our implementation is also highly scalable on multi-core CPUs.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/leis2018leanstore.html</link><guid isPermaLink="false">Literature Notes/leis2018leanstore.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:12:15 GMT</pubDate></item><item><title><![CDATA[CRDTs: Consistency without concurrency control]]></title><description><![CDATA[ 
 <br><br>Mihai Letia, Nuno Preguiça, Marc Shapiro (2009)<br>Tags: <br>Abstract
A CRDT is a data type whose operations commute when they are concurrent. Replicas of a CRDT eventually converge without any complex concurrency control. As an existence proof, we exhibit a non-trivial CRDT: a shared edit buffer called Treedoc. We outline the design, implementation and performance of Treedoc. We discuss how the CRDT concept can be generalised, and its limitations.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/letia2009crdts.html</link><guid isPermaLink="false">Literature Notes/letia2009crdts.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:42:33 GMT</pubDate></item><item><title><![CDATA[Wander join: Online aggregation via random walks]]></title><description><![CDATA[ 
 <br><br>Feifei Li, Bin Wu, Ke Yi, Zhuoyue Zhao (2016)<br>Tags: <br>Abstract
Joins are expensive, and online aggregation over joins was proposed to mitigate the cost, which offers users a nice and flexible tradeoff between query efficiency and accuracy in a continuous, online fashion. However, the state-of-the-art approach, in both internal and external memory, is based on ripple join, which is still very expensive and even needs unrealistic assumptions (e.g., tuples in a table are stored in random order). This paper proposes a new approach, the wander join algorithm, to the online aggregation problem by performing random walks over the underlying join graph. We also design an optimizer that chooses the optimal plan for conducting the random walks without having to collect any statistics a priori. Compared with ripple join, wander join is particularly efficient for equality joins involving multiple tables, but also supports θ-joins. Selection predicates and group-by clauses can be handled as well. Extensive experiments using the TPC-H benchmark have demonstrated the superior performance of wander join over ripple join. In particular, we have integrated and tested wander join in the latest version of PostgreSQL, demonstrating its practicality in a full-fledged database system.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/li2016wander.html</link><guid isPermaLink="false">Literature Notes/li2016wander.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:26 GMT</pubDate></item><item><title><![CDATA[Toward real microkernels]]></title><description><![CDATA[ 
 <br><br>Jochen Liedtke (1996)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Jochen-Liedtke" class="tag" target="_blank" rel="noopener">#Jochen-Liedtke</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/liedtke1996toward.html</link><guid isPermaLink="false">Literature Notes/liedtke1996toward.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:31 GMT</pubDate></item><item><title><![CDATA[Meltdown: Reading kernel memory from user space]]></title><description><![CDATA[ 
 <br><br>Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, others (2020)<br>Tags: <br>Abstract
Lessons learned from Meltdown's exploitation of the weaknesses in today's processors.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/lipp2020meltdown.html</link><guid isPermaLink="false">Literature Notes/lipp2020meltdown.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:37:08 GMT</pubDate></item><item><title><![CDATA[Extensions to Starburst: Objects, types, functions, and rules]]></title><description><![CDATA[ 
 <br><br>Guy M Lohman, Bruce Lindsay, Hamid Pirahesh, K Bernhard Schiefer (1991)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/lohman1991extensions.html</link><guid isPermaLink="false">Literature Notes/lohman1991extensions.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:47:53 GMT</pubDate></item><item><title><![CDATA[R* optimizer validation and performance evaluation for local queries]]></title><description><![CDATA[ 
 <br><br>Lothar F Mackert, Guy M Lohman (1986)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Lothar" class="tag" target="_blank" rel="noopener">#Lothar</a> <a href="https://jayitha.github.io/Notes?query=tag:F-Mackert" class="tag" target="_blank" rel="noopener">#F-Mackert</a> <a href="https://jayitha.github.io/Notes?query=tag:Guy" class="tag" target="_blank" rel="noopener">#Guy</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Lohman" class="tag" target="_blank" rel="noopener">#M-Lohman</a><br>Abstract
Few database query optimizer models have been validated against actual performance. This paper presents the methodology and results of a thorough validation of the optimizer and evaluation of the performance of the experimental distributed relational database management system R, which inherited and extended to a distributed environment the optimization algorithms of System R. Optimizer estimated costs and actual R resources consumed were written to database tables using new SQL commands, permitting automated control from SQL application programs of test data collection and reduction. A number of tests were run over a wide variety of dynamically-created test databases, SQL queries, and system parameters. The results for single-table access, sorting, and local 2-table joins are reported here. The tests confirmed the accuracy of the majority of the I/O cost model, the significant contribution of CPU cost to total cost, and the need to model CPU cost in more detail than was done in System R. The R* optimizer now retains cost components separately and estimates the number of CPU instructions, including those for applying different kinds of predicates. The sensitivity of I/O cost to buffer space motivated the development of more detailed models of buffer utilization unclustered index scans and nested-loop joins often benefit from pages remaining in the buffers, whereas concurrent scans of the data pages and the index pages for multiple tables during joins compete for buffer share. Without an index on the join column of the inner table, the optimizer correctly avoids the nested-loop join, confirming the need for merge-scan joins. When the join column of the inner is indexed, the optimizer overestimates the cost of the nested-loop join, whose actual performance is very sensitive to three parameters that are extremely difficult to estimate (1) the join (result) cardinality, (2) the outer table's cardinality, and (3) the number of buffer pages available to store the inner table. Suggestions are given for improved database statistics, prefetch and page replacement strategies for the buffer manager, and the use of temporary indexes and Bloom filters (hashed semijoins) to reduce access of unneeded data.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mackert1986r.html</link><guid isPermaLink="false">Literature Notes/mackert1986r.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:46:41 GMT</pubDate></item><item><title><![CDATA[Raha: A configuration-free error detection system]]></title><description><![CDATA[ 
 <br><br>Mohammad Mahdavi, Ziawasch Abedjan, Raul Castro Fernandez, Samuel Madden, Mourad Ouzzani, Michael Stonebraker, Nan Tang (2019)<br>Tags: <br>Abstract
Detecting erroneous values is a key step in data cleaning. Error detection algorithms usually require a user to provide input configurations in the form of rules or statistical parameters. However, providing a complete, yet correct, set of configurations for each new dataset is not trivial, as the user has to know about both the dataset and the error detection algorithms upfront. In this paper, we present Raha, a new configuration-free error detection system. By generating a limited number of configurations for error detection algorithms that cover various types of data errors, we can generate an expressive feature vector for each tuple value. Leveraging these feature vectors, we propose a novel sampling and classification scheme that effectively chooses the most representative values for training. Furthermore, our system can exploit historical data to filter out irrelevant error detection algorithms and configurations. In our experiments, Raha outperforms the state-of-the-art error detection techniques with no more than 20 labeled tuples on each dataset.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mahdavi2019raha.html</link><guid isPermaLink="false">Literature Notes/mahdavi2019raha.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:14:46 GMT</pubDate></item><item><title><![CDATA[Neo: A learned query optimizer]]></title><description><![CDATA[ 
 <br><br>Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh, Tim Kraska, Olga Papaemmanouil, Nesime Tatbul (2019)<br>Tags: <br>Abstract
Query optimization is one of the most challenging problems in database systems. Despite the progress made over the past decades, query optimizers remain extremely complex components that require a great deal of hand-tuning for specific workloads and datasets. Motivated by this shortcoming and inspired by recent advances in applying machine learning to data management challenges, we introduce Neo (Neural Optimizer), a novel learning-based query optimizer that relies on deep neural networks to generate query executions plans. Neo bootstraps its query optimization model from existing optimizers and continues to learn from incoming queries, building upon its successes and learning from its failures. Furthermore, Neo naturally adapts to underlying data patterns and is robust to estimation errors. Experimental results demonstrate that Neo, even when bootstrapped from a simple optimizer like PostgreSQL, can learn a model that offers similar performance to state-of-the-art commercial optimizers, and in some cases even surpass them.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/marcus2019neo.html</link><guid isPermaLink="false">Literature Notes/marcus2019neo.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:53:06 GMT</pubDate></item><item><title><![CDATA[Benchmarking learned indexes]]></title><description><![CDATA[ 
 <br><br>Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons Kemper, Thomas Neumann, Tim Kraska (2020)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Ryan-Marcus" class="tag" target="_blank" rel="noopener">#Ryan-Marcus</a> <a href="https://jayitha.github.io/Notes?query=tag:Andreas-Kipf" class="tag" target="_blank" rel="noopener">#Andreas-Kipf</a> <a href="https://jayitha.github.io/Notes?query=tag:Alexander-van" class="tag" target="_blank" rel="noopener">#Alexander-van</a> <a href="https://jayitha.github.io/Notes?query=tag:Renen" class="tag" target="_blank" rel="noopener">#Renen</a> <a href="https://jayitha.github.io/Notes?query=tag:Mihail-Stoian" class="tag" target="_blank" rel="noopener">#Mihail-Stoian</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanchit-Misra" class="tag" target="_blank" rel="noopener">#Sanchit-Misra</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Kraska" class="tag" target="_blank" rel="noopener">#Tim-Kraska</a><br>Abstract
Recent advancements in learned index structures propose replacing existing index structures, like B-Trees, with approximate learned models. In this work, we present a unified benchmark that compares well-tuned implementations of three learned index structures against several state-of-the-art "traditional" baselines. Using four real-world datasets, we demonstrate that learned index structures can indeed outperform non-learned indexes in read-only in-memory workloads over a dense array. We also investigate the impact of caching, pipelining, dataset size, and key size. We study the performance profile of learned index structures, and build an explanation for why learned models achieve such good performance. Finally, we investigate other important properties of learned index structures, such as their performance in multi-threaded systems and their build times.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/marcus2020benchmarking.html</link><guid isPermaLink="false">Literature Notes/marcus2020benchmarking.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:35:16 GMT</pubDate></item><item><title><![CDATA[Bao: Making learned query optimization practical]]></title><description><![CDATA[ 
 <br><br>Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Alizadeh, Tim Kraska (2021)<br>Tags: <br>Abstract
Recent efforts applying machine learning techniques to query optimization have shown few practical gains due to substantive training overhead, inability to adapt to changes, and poor tail performance. Motivated by these difficulties, we introduce Bao (the \underlineBa ndit \underlineo ptimizer). Bao takes advantage of the wisdom built into existing query optimizers by providing per-query optimization hints. Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm. As a result, Bao automatically learns from its mistakes and adapts to changes in query workloads, data, and schema. Experimentally, we demonstrate that Bao can quickly learn strategies that improve end-to-end query execution performance, including tail latency, for several workloads containing long-running queries. In cloud environments, we show that Bao can offer both reduced costs and better performance compared with a commercial system.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/marcus2021bao.html</link><guid isPermaLink="false">Literature Notes/marcus2021bao.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:53:13 GMT</pubDate></item><item><title><![CDATA[A fast file system for UNIX]]></title><description><![CDATA[ 
 <br><br>Marshall K McKusick, William N Joy, Samuel J Leffler, Robert S Fabry (1984)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Marshall" class="tag" target="_blank" rel="noopener">#Marshall</a> <a href="https://jayitha.github.io/Notes?query=tag:K-McKusick" class="tag" target="_blank" rel="noopener">#K-McKusick</a> <a href="https://jayitha.github.io/Notes?query=tag:William" class="tag" target="_blank" rel="noopener">#William</a> <a href="https://jayitha.github.io/Notes?query=tag:N-Joy" class="tag" target="_blank" rel="noopener">#N-Joy</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel" class="tag" target="_blank" rel="noopener">#Samuel</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Leffler" class="tag" target="_blank" rel="noopener">#J-Leffler</a> <a href="https://jayitha.github.io/Notes?query=tag:Robert" class="tag" target="_blank" rel="noopener">#Robert</a> <a href="https://jayitha.github.io/Notes?query=tag:S-Fabry" class="tag" target="_blank" rel="noopener">#S-Fabry</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/mckusick1984fast.html</link><guid isPermaLink="false">Literature Notes/mckusick1984fast.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:09:58 GMT</pubDate></item><item><title><![CDATA[Transaction management in the R* distributed database management system]]></title><description><![CDATA[ 
 <br><br>C Mohan (1986)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Mohan" class="tag" target="_blank" rel="noopener">#C-Mohan</a><br>Abstract
This paper deals with the transaction management aspects of the R distributed database system. It concentrates primarily on the description of the R commit protocols, Presumed Abort (PA) and Presumed Commit (PC). PA and PC are extensions of the well-known, two-phase (2P) commit protocol. PA is optimized for read-only transactions and a class of multisite update transactions, and PC is optimized for other classes of multisite update transactions. The optimizations result in reduced intersite message traffic and log writes, and, consequently, a better response time. The paper also discusses R*'s approach toward distributed deadlock detection and resolution.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mohan1986transaction.html</link><guid isPermaLink="false">Literature Notes/mohan1986transaction.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:46:35 GMT</pubDate></item><item><title><![CDATA[ARIES: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging]]></title><description><![CDATA[ 
 <br><br>Chandrasekaran Mohan, Don Haderle, Bruce Lindsay, Hamid Pirahesh, Peter Schwarz (1992)<br>Tags: <br>Abstract
DB2TM, IMS, and TandemTM systems. ARIES is applicable not only to database management systems but also to persistent object-oriented languages, recoverable file systems and transaction-based operating systems. ARIES has been implemented, to varying degrees, in IBM's OS/2TM Extended Edition Database Manager, DB2, Workstation Data Save Facility/VM, Starburst and QuickSilver, and in the University of Wisconsin's EXODUS and Gamma database machine.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mohan1992aries.html</link><guid isPermaLink="false">Literature Notes/mohan1992aries.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:36:27 GMT</pubDate></item><item><title><![CDATA[Repeating history beyond ARIES]]></title><description><![CDATA[ 
 <br><br>C Mohan (1999)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Mohan" class="tag" target="_blank" rel="noopener">#C-Mohan</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/mohan1999repeating.html</link><guid isPermaLink="false">Literature Notes/mohan1999repeating.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:36:30 GMT</pubDate></item><item><title><![CDATA[Toward a global data infrastructure]]></title><description><![CDATA[ 
 <br><br>Nitesh Mor, Ben Zhang, John Kolb, Douglas S Chan, Nikhil Goyal, Nicholas Sun, Ken Lutz, Eric Allman, John Wawrzynek, Edward A Lee, others (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Nitesh-Mor" class="tag" target="_blank" rel="noopener">#Nitesh-Mor</a> <a href="https://jayitha.github.io/Notes?query=tag:Ben-Zhang" class="tag" target="_blank" rel="noopener">#Ben-Zhang</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Kolb" class="tag" target="_blank" rel="noopener">#John-Kolb</a> <a href="https://jayitha.github.io/Notes?query=tag:Douglas" class="tag" target="_blank" rel="noopener">#Douglas</a> <a href="https://jayitha.github.io/Notes?query=tag:S-Chan" class="tag" target="_blank" rel="noopener">#S-Chan</a> <a href="https://jayitha.github.io/Notes?query=tag:Nikhil-Goyal" class="tag" target="_blank" rel="noopener">#Nikhil-Goyal</a> <a href="https://jayitha.github.io/Notes?query=tag:Nicholas-Sun" class="tag" target="_blank" rel="noopener">#Nicholas-Sun</a> <a href="https://jayitha.github.io/Notes?query=tag:Ken-Lutz" class="tag" target="_blank" rel="noopener">#Ken-Lutz</a> <a href="https://jayitha.github.io/Notes?query=tag:Eric-Allman" class="tag" target="_blank" rel="noopener">#Eric-Allman</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Wawrzynek" class="tag" target="_blank" rel="noopener">#John-Wawrzynek</a> <a href="https://jayitha.github.io/Notes?query=tag:Edward" class="tag" target="_blank" rel="noopener">#Edward</a> <a href="https://jayitha.github.io/Notes?query=tag:A-Lee" class="tag" target="_blank" rel="noopener">#A-Lee</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract
The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, directly connecting smart devices to the cloud has multiple disadvantages and is unlikely to keep up with the growing speed of the IoT or the diverse needs of IoT applications. Here, the authors argue that fundamental IoT properties prevent the current approach from scaling. What's missing is a well-architected system extending cloud functionality and providing seamless interplay among heterogeneous components closer to the edge in the IoT space. Raising the level of abstraction to a data-centric design – focused around the distribution, preservation, and protection of information – better matches the IoT. To address such problems with the cloud-centric architecture, the authors present their early work on a distributed platform, the Global Data Plane.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mor2016toward.html</link><guid isPermaLink="false">Literature Notes/mor2016toward.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:30 GMT</pubDate></item><item><title><![CDATA[Global data plane: A federated vision for secure data in edge computing]]></title><description><![CDATA[ 
 <br><br>Nitesh Mor, Richard Pratt, Eric Allman, Kenneth Lutz, John Kubiatowicz (2019)<br>Tags: <br>Abstract
We propose a federated edge-computing architecture for management of data. Our vision is to enable a service provider model for "data-services", where a user can enter into economic agreements with an infrastructure maintainer to provide storage and communication of data, without necessarily trusting the infrastructure provider. Toward this vision, we present cryptographically hardened cohesive collections of data items called DataCapsules, and an overview of the underlying federated architecture, called Global Data Plane.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mor2019global.html</link><guid isPermaLink="false">Literature Notes/mor2019global.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:25 GMT</pubDate></item><item><title><![CDATA[Out of the tar pit]]></title><description><![CDATA[ 
 <br><br>Ben Moseley, Peter Marks (2006)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Ben-Moseley" class="tag" target="_blank" rel="noopener">#Ben-Moseley</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Marks" class="tag" target="_blank" rel="noopener">#Peter-Marks</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
Complexity is the single major difficulty in the successful development of large-scale software systems. Following Brooks we distinguish accidental from essential difficulty, but disagree with his premise that most complexity remaining in contemporary systems is essential. We identify common causes of complexity and discuss general approaches which can be taken to eliminate them where they are accidental in nature. To make things more concrete we then give an outline for a potential complexity-minimizing approach based on functional programming and Codd’s relational model of data.
<br>Paper discusses common causes of large-scale system complexity (in understanding a system) and ways to avoid accidental complexity<br>The major contributor to the complexity in the development and maintenance of large-scale software systems is handling of the state. Other factors include code volume and flow of control through the system<br>The State problem is usually handled either using object-oriented programming (which couples state with behavior) or functional programming (does away with state and side effects)<br>Paper proposes combining both approaches along with ideas from <a data-href="The Relational Model" href="https://jayitha.github.io/Notes/glossary/the-relational-model.html" class="internal-link" target="_self" rel="noopener">The Relational Model</a><br>While there are other factors that making building large-scale systems hard, the paper reasons that complexity is the root cause of all since understanding the system can fix most other problems but complexity makes understanding hard<br>
Simplicity is Hard
<br>Two approaches to understanding systems<br>
<br>Testing 

<br>Treat system as a blackbox and draw conclusions based on system's response to certain situations
<br>Tests on one input tells you nothing about the system's behavior on another input


<br>Informal Reasoning

<br>Understand system by examining the internals


<br>
<br>The latter is considered more important since it can lead to generating less errors whereas the former can only detect more errors
<br>Have you ever performed the right tests? Negative.
<br>Causes of Complexity - sometimes complexity is inherent in the problem, sometimes not<br>
<br>Complexity caused by State (a stateful system)

<br>"try it again", "reload the document" ... the presence of state makes programs hard to understand
<br>Specifically, it is the number of possible states that makes it complex - The number of states grow exponentially; with each extra bit the number of states doubles


<br>State on Testing

<br>tests on one state tell you nothing about other states
<br>A common approach is to assume a clean initial state when testing - can't always get away with this
<br>The issues with testing, and the number of states compound


<br>State on Informal Reasoning

<br>As the number of states increase, informally reasoning by performing a mental case-by-case simulation gets out of hand
<br>Contamination - Even if a procedure is stateless on it's own, if it uses any other procedure that is even indirectly stateful, the procedure is contaminated and is again hard to reason




<br>Complexity caused by Control (Order in which things happen)

When a programmer is forced (through use of a language with implicit flow control) to specify the control, they are being forced to specify an aspect of how the system should work rather than simply what is desired, effectively over-specifying the problem


<br>When an artificial order is imposed, some compilers choose to ignore the order. However, when trying to informally reason through the code, the reader is forced to first assume the order is important, then upon further inspection, determine if it isn't (which is prone to mistakes)
<br>Another issue with control occurs with concurrency

<br>Concurrency makes it harder to reason when using shared-state concurrency (most common form) where the number of scenarios are too many
<br>Also testing is difficult since the system can exhibit different behavior on the same input and same initial state when run multiple times




<br>Complexity caused by Code Volume

<br>Mostly a side effect - managing state or specifying control
<br>Of interest because (1) easiest form of complexity to measure and (2) interacts badly with other causes of complexity

Complexity exhibits a nonlinear increase with size of code<br>
Dijkstra mused that there's some law of nature that the amount of intellectual effort needed grows with the square with the program length. He later argues that with powers of abstraction, the amount of intellectual effort needed need not grow more than proportional to program length


<br>Paper argues that with effective management of state and control, the non-linearity is uncertain


<br>Other causes include: duplicated code, dead code, unnecessary abstraction, missed abstraction, poor modularity, poor documentation...<br>
- Complexity breeds complexity (secondary causes, if you don't understand code, it is likely you'll write duplicate code),<br>
- Simplicity is Hard (effort is needed, first solution usually not simple) and<br>
- Power corrupts (the more power that a language gives the programmer, the more wary one should be of the produced code; argues that garbage collection is good)


<br>Classical approaches to manage complexity - Object-orientation, Functional Programming and Logic Programming<br>
<br>
Object-Orientation

<br>The dominant (imperative) method for general software development for traditional von-Neumann (state-based) computation
<br>In OOP, an object consists of a state with an associated set of methods that manipulate the state - encapsulation enforcing integrity constraints over an object's state
<br>Two issues with OOP

<br>If multiple methods access the object, a constraint may have to be enforced across all methods
<br>It's difficult to enforce constraints based on multiple objects and not just a single one


<br>Object Identity - In OOP, each object is a uniquely identifiable entity regardless of its attributes (intensional identity). In contrast, in relational algebra, objects have extensional identity where objects are the same if their attributes are the same

<br>Useful when using a mutable stateful abstraction - two distinct stateful objects can be mutated to contain different states even if their attributes happen to initially be the same (???????)
<br>Problematic otherwise, since now in OOPs we need procedures to check if two objects are equal based on attribute values


<br>All forms of OOPs rely on state and hence suffer from all problems associated with state
<br>Most OOPs language provide standard seq control and shared-state concurrency leading to all the pre-specified problems
<br>Some OOPs languages provide message-passing models (actor-style), however, not widespread


<br>
Functional Programming

<br>Completely stateless lambda calculus of Church
<br>Untyped lambda calculus is equivalent in power to the standard stateful abstraction of computation (the Turing machine)
<br>State

<br>Modern functional languages are either pure (no state or side-effects) or impure (discourage state and side-effects but permit use)
<br>By avoiding state - referential transparency (when providing a set of arguments, a function will always behave the same way) (testing becomes more effective)
<br>Informal reasoning is more effective as well


<br>Control

<br>Functional languages specify a left-to-right sequencing of calculation of function arguments (some implicit order) and hence, can face the same problems as with OOPs however, concurrent variants do exist


<br>In the functional style, to simulate implicit mutable states, we instead pass explicit mutable function arguments maintaining referential transparency. However, this approach soon impairs informal reasoning if the state being passed is large and complex, you end up passing irrelevant data. That being said, there are benefits to avoiding hidden, implicit, mutable state.


<br>State and Modularity<br>
<br>States can permit some forms of modularity. Within a stateful framework, you can add state to any component without adjusting the components that invoke it. In the functional framework, every component has to carry additional information
<br>The tradeoff lies in referential transparency
<br>One approach is apparently using the system of monads used by Haskell [@wadler1995monads]
<br>
<br>Logic Programming
<br>
<br>Declarative, not derived from stateful von-Neumann architecture
<br>In pure logic programming, you only make statements about the problem and desired solutions (by specifying axioms which describe the problem and the attributes satisfied by solutions)
<br>Running the system is equivalent to "constructing a valid proof for each solution"
<br>State - Pure logical programming (unlike it's extensions) makes no use of mutable state and hence has the same advantages in understandability as pure functional programming
<br>Control - pure Prolog specifies both an implicit ordering (left to right) and an implicit ordering of clause application (top down). This is not the case in ideal logic programming where there is no such order
<br>In theory, logic programming can escape from complexity problems caused by control
<br>Essential Complexity - Inherent in, and the essence of, the problem (as seen by the users)<br>
Accidental Complexity - all the rest; complexity with which the development team would not have to deal with in the ideal world<br>Ideal World<br>
<br>Not concerned with performance; language and infrastructure provide all general support
<br>State is accidental state if it can be omitted in the ideal world. Similarly for control
<br>Even in the ideal work, we need to derive formal requirements(processable by a computer) from informal requirements (from users)
<br>Informal Requirements -&gt; Formal Requirements
<br>The next step is to simply execute formal requirements directly - absolute simplicity and declarative programming
<br>State in Ideal World<br>
<br>Some data specified in the users informal requirements can give rise to state
<br>All data is either provided directly to the system (input) or derived. Further, derived data is either immutable (only intended for display) or mutable (explicitly asked to update data)

<br>Input data - included in the informal requirements and falls into one of two cases

<br>A possibility the system may need to refer to the data in the future - essential state
<br>No possibility - data need not be maintained, no state generated


<br>Essential Derived Data - Immutable

<br>Can always be re-derived from input (essential state) -&gt; Accidental State


<br>Essential Derived Data - Mutable

<br>Can be re-derived (accidental state)
<br>Mutability only makes sense when the mutating function has an inverse - otherwise it is not considered as derived data and is effectively input


<br>Accidental Derived Data

<br>State that is derived but not in requirements is accidental state




<br><img alt="Pasted image 20240105205838.png" src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240105205838.png"><br>Control in the ideal world<br>
<br>Control is considered entirely accidental
<br>
How close is it possible to get to the ideal world in the real one?
<br>Theoretical and Practical Limitations<br>
<br>Formal specifications are categorized into two categories

<br>Property-based - focus on what is required (declarative)
<br>Model-based - Construct a potential model for the system (stateful)


<br>There are two reasons why we might be forced to include some accidental state

<br>Ease of expression - sometimes it's more natural to store some accidental (mutable derivable state) instead of deriving the state from the input using logic (the position of a player in a game)
<br>Performance - Using accidental state and control can improve efficiency


<br>It's important to keep in mind, that once we introduce accidental state, however required it may be, we expose ourselves to the same problems that were discussed before
<br>Recommendations for dealing with required accidental complexity - Avoid and Separate<br><br><img alt="Pasted image 20240108115831.png" src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240108115831.png"><br>
<br>Paper advocates a high level separation into three components each specified by a different restricted language - Essential State, Essential Logic, Accidental State and Control
<br>Accidental State and Control are only there to improve performance; therefore, the system should work without this component, albeit slowly
<br>Discusses <a data-href="The Relational Model" href="https://jayitha.github.io/Notes/glossary/the-relational-model.html" class="internal-link" target="_self" rel="noopener">The Relational Model</a><br><br><br>: ]]></description><link>https://jayitha.github.io/Notes/literature-notes/moseley2006out.html</link><guid isPermaLink="false">Literature Notes/moseley2006out.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 14 Mar 2024 13:29:31 GMT</pubDate><enclosure url="https://jayitha.github.io/Notes/lib/media/pasted-image-20240105205838.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://jayitha.github.io/Notes/lib/media/pasted-image-20240105205838.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Approximate query engines: Commercial challenges and research opportunities]]></title><description><![CDATA[ 
 <br><br>Barzan Mozafari (2017)<br>Tags: <br>Abstract
Recent years have witnessed a surge of interest in Approximate Query Processing (AQP) solutions, both in academia and the commercial world. In addition to well-known open problems in this area, there are many new research challenges that have surfaced as a result of the first interaction of AQP technology with commercial and real-world customers. We categorize these into deployment, planning, and interface challenges. At the same time, AQP settings introduce many interesting opportunities that would not be possible in a database with precise answers. These opportunities create hopes for overcoming some of the major limitations of traditional database systems. For example, we discuss how a database can reuse its past work in a generic way, and become smarter as it answers new queries. Our goal in this talk is to suggest some of the exciting research directions in this field that are worth pursuing.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mozafari2017approximate.html</link><guid isPermaLink="false">Literature Notes/mozafari2017approximate.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:49 GMT</pubDate></item><item><title><![CDATA[Deep learning for entity matching: A design space exploration]]></title><description><![CDATA[ 
 <br><br>Sidharth Mudgal, Han Li, Theodoros Rekatsinas, AnHai Doan, Youngchoon Park, Ganesh Krishnan, Rohit Deep, Esteban Arcaute, Vijay Raghavendra (2018)<br>Tags: <br>Abstract
Entity matching (EM) finds data instances that refer to the same real-world entity. In this paper we examine applying deep learning (DL) to EM, to understand DL's benefits and limitations. We review many DL solutions that have been developed for related matching tasks in text processing (e.g., entity linking, textual entailment, etc.). We categorize these solutions and define a space of DL solutions for EM, as embodied by four solutions with varying representational power: SIF, RNN, Attention, and Hybrid. Next, we investigate the types of EM problems for which DL can be helpful. We consider three such problem types, which match structured data instances, textual instances, and dirty instances, respectively. We empirically compare the above four DL solutions with Magellan, a state-of-the-art learning-based EM solution. The results show that DL does not outperform current solutions on structured EM, but it can significantly outperform them on textual and dirty EM. For practitioners, this suggests that they should seriously consider using DL for textual and dirty EM problems. Finally, we analyze DL's performance and discuss future research directions.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/mudgal2018deep.html</link><guid isPermaLink="false">Literature Notes/mudgal2018deep.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:14:53 GMT</pubDate></item><item><title><![CDATA[Learning multi-dimensional indexes]]></title><description><![CDATA[ 
 <br><br>Vikram Nathan, Jialin Ding, Mohammad Alizadeh, Tim Kraska (2020)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Vikram-Nathan" class="tag" target="_blank" rel="noopener">#Vikram-Nathan</a> <a href="https://jayitha.github.io/Notes?query=tag:Jialin-Ding" class="tag" target="_blank" rel="noopener">#Jialin-Ding</a> <a href="https://jayitha.github.io/Notes?query=tag:Mohammad-Alizadeh" class="tag" target="_blank" rel="noopener">#Mohammad-Alizadeh</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Kraska" class="tag" target="_blank" rel="noopener">#Tim-Kraska</a><br>Abstract
Scanning and filtering over multi-dimensional tables are key operations in modern analytical database engines. To optimize the performance of these operations, databases often create clustered indexes over a single dimension or multi-dimensional indexes such as R-Trees, or use complex sort orders (e.g., Z-ordering). However, these schemes are often hard to tune and their performance is inconsistent across different datasets and queries. In this paper, we introduce Flood, a multi-dimensional in-memory read-optimized index that automatically adapts itself to a particular dataset and workload by jointly optimizing the index structure and data storage layout. Flood achieves up to three orders of magnitude faster performance for range scans with predicates than state-of-the-art multi-dimensional indexes or sort orders on real-world datasets and workloads. Our work serves as a building block towards an end-to-end learned database system.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/nathan2020learning.html</link><guid isPermaLink="false">Literature Notes/nathan2020learning.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:36:16 GMT</pubDate></item><item><title><![CDATA[Efficiently compiling efficient query plans for modern hardware]]></title><description><![CDATA[ 
 <br><br>Thomas Neumann (2011)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a><br>Abstract
As main memory grows, query performance is more and more determined by the raw CPU costs of query processing itself. The classical iterator style query processing technique is very simple and exible, but shows poor performance on modern CPUs due to lack of locality and frequent instruction mispredictions. Several techniques like batch oriented processing or vectorized tuple processing have been proposed in the past to improve this situation, but even these techniques are frequently out-performed by hand-written execution plans. In this work we present a novel compilation strategy that translates a query into compact and efficient machine code using the LLVM compiler framework. By aiming at good code and data locality and predictable branch layout the resulting code frequently rivals the performance of hand-written C++ code. We integrated these techniques into the HyPer main memory database system and show that this results in excellent query performance while requiring only modest compilation time.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/neumann2011efficiently.html</link><guid isPermaLink="false">Literature Notes/neumann2011efficiently.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:29:31 GMT</pubDate></item><item><title><![CDATA[Fast serializable multi-version concurrency control for main-memory database systems]]></title><description><![CDATA[ 
 <br><br>Thomas Neumann, Tobias Mühlbauer, Alfons Kemper (2015)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Thomas-Neumann" class="tag" target="_blank" rel="noopener">#Thomas-Neumann</a> <a href="https://jayitha.github.io/Notes?query=tag:Tobias-Mühlbauer" class="tag" target="_blank" rel="noopener">#Tobias-Mühlbauer</a> <a href="https://jayitha.github.io/Notes?query=tag:Alfons-Kemper" class="tag" target="_blank" rel="noopener">#Alfons-Kemper</a><br>Abstract
Multi-Version Concurrency Control (MVCC) is a widely employed concurrency control mechanism, as it allows for execution modes where readers never block writers. However, most systems implement only snapshot isolation (SI) instead of full serializability. Adding serializability guarantees to existing SI implementations tends to be prohibitively expensive. We present a novel MVCC implementation for main-memory database systems that has very little overhead compared to serial execution with single-version concurrency control, even when maintaining serializability guarantees. Updating data in-place and storing versions as before-image deltas in undo buffers not only allows us to retain the high scan performance of single-version systems but also forms the basis of our cheap and fine-grained serializability validation mechanism. The novel idea is based on an adaptation of precision locking and verifies that the (extensional) writes of recently committed transactions do not intersect with the (intensional) read predicate space of a committing transaction. We experimentally show that our MVCC model allows very fast processing of transactions with point accesses as well as read-heavy transactions and that there is little need to prefer SI over full serializability any longer.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/neumann2015fast.html</link><guid isPermaLink="false">Literature Notes/neumann2015fast.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:04 GMT</pubDate></item><item><title><![CDATA[The log-structured merge-tree (LSM-tree)]]></title><description><![CDATA[ 
 <br><br>Patrick O'Neil, Edward Cheng, Dieter Gawlick, Elizabeth O'Neil (1996)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a><br>Abstract
High-performance transaction system applications typically insert rows in a History table to provide an activity trace; at the same time the transaction system generates log records for purposes of system recovery. Both types of generated information can benefit from efficient indexing. An example in a well-known setting is the TPC-A benchmark application, modified to support efficient queries on the history for account activity for specific accounts. This requires an index by account-id on the fast-growing History table. Unfortunately, standard disk-based index structures such as the B-tree will effectively double the I/O cost of the transaction to maintain an index such as this in real time, increasing the total system cost up to fifty percent. Clearly a method for maintaining a real-time index at low cost is desirable. The log-structured mergetree (LSM-tree) is a disk-based data structure designed to provide low-cost indexing for a file experiencing a high rate of record inserts (and deletes) over an extended period. The LSM-tree uses an algorithm that defers and batches index changes, cascading the changes from a memory-based component through one or more disk components in an efficient manner reminiscent of merge sort. During this process all index values are continuously accessible to retrievals (aside from very short locking periods), either through the memory component or one of the disk components. The algorithm has greatly reduced disk arm movements compared to a traditional access methods such as B-trees, and will improve cost-performance in domains where disk arm costs for inserts with traditional access methods overwhelm storage media costs. The LSM-tree approach also generalizes to operations other than insert and delete. However, indexed finds requiring immediate response will lose I/O efficiency in some cases, so the LSM-tree is most useful in applications where index inserts are more common than finds that retrieve the entries. This seems to be a common property for history tables and log files, for example. The conclusions of Sect. 6 compare the hybrid use of memory and disk components in the LSM-tree access method with the commonly understood advantage of the hybrid method to buffer disk pages in memory.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/o1996log.html</link><guid isPermaLink="false">Literature Notes/o1996log.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sat, 04 Nov 2023 09:38:34 GMT</pubDate></item><item><title><![CDATA[Improved query performance with variant indexes]]></title><description><![CDATA[ 
 <br><br>Patrick O'Neil, Dallan Quass (1997)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Patrick-O" class="tag" target="_blank" rel="noopener">#Patrick-O</a>'Neil <a href="https://jayitha.github.io/Notes?query=tag:Dallan-Quass" class="tag" target="_blank" rel="noopener">#Dallan-Quass</a><br>Abstract
The read-mostly environment of data warehousing makes it possible to use more complex indexes to speed up queries than in situations where concurrent updates are present. The current paper presents a short review of current indexing technology, including row-set representation by Bitmaps, and then introduces two approaches we call Bit-Sliced indexing and Projection indexing. A Projection index materializes all values of a column in RID order, and a Bit-Sliced index essentially takes an orthogonal bit-by-bit view of the same data. While some of these concepts started with the MODEL 204 product, and both Bit-Sliced and Projection indexing are now fully realized in Sybase IQ, this is the first rigorous examination of such indexing capabilities in the literature. We compare algorithms that become feasible with these variant index types against algorithms using more conventional indexes. The analysis demonstrates important performance advantages for variant indexes in some types of SQL aggregation, predicate evaluation, and grouping. The paper concludes by introducing a new method whereby multi-dimensional group-by queries, reminiscent of OLAP/Datacube queries but with more flexibility, can be very efficiently performed.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/o1997improved.html</link><guid isPermaLink="false">Literature Notes/o1997improved.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:07:06 GMT</pubDate></item><item><title><![CDATA[In search of an understandable consensus algorithm]]></title><description><![CDATA[ 
 <br><br>Diego Ongaro, John Ousterhout (2014)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Diego-Ongaro" class="tag" target="_blank" rel="noopener">#Diego-Ongaro</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Ousterhout" class="tag" target="_blank" rel="noopener">#John-Ousterhout</a><br>Abstract
Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/ongaro2014search.html</link><guid isPermaLink="false">Literature Notes/ongaro2014search.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:33:27 GMT</pubDate></item><item><title><![CDATA[Indexing the Edges—a simple and yet efficient approach to high-dimensional indexing]]></title><description><![CDATA[ 
 <br><br>Beng Chin Ooi, Kian-Lee Tan, Cui Yu, Stephane Bressan (2000)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
In this paper, we propose a new tunable index scheme, called iMinMax(O), that maps points in high dimensional spaces to single dimension values determined by their maximum or minimum values among all dimensions. By varying the tuning “knob” O, we can obtain different family of iMinMax structures that are optimized for different distributions of data sets. For a d-dimensional space, a range query need to be transformed into d subqueries. However, some of these subqueries can be pruned away without evaluation, further enhancing the efficiency of the scheme. Experimental results show that iMinMax(O) can outperform the more complex Pyramid technique by a wide margin.
<br>Proposes <a data-href="iMinMax" href="https://jayitha.github.io/Notes/glossary/iminmax.html" class="internal-link" target="_self" rel="noopener">iMinMax</a><br>
The performance of hierarchical indexing structures like R-trees and R*-trees deteriorates rapidly with increasing dimensionality<br>
The curse of dimensionality is so severe that the performance of hierarchical indexing structures is worse than a linear scan cite:[4, 5]<br>
Some other approaches are the VA-file cite:[4] and the <a data-href="Pyramid Technique" href="https://jayitha.github.io/Notes/glossary/pyramid-technique.html" class="internal-link" target="_self" rel="noopener">Pyramid Technique</a> cite:[5]<br><br><br>: <br>: ]]></description><link>https://jayitha.github.io/Notes/literature-notes/ooi2000indexing.html</link><guid isPermaLink="false">Literature Notes/ooi2000indexing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:25:57 GMT</pubDate></item><item><title><![CDATA[Lithe: Enabling efficient composition of parallel libraries]]></title><description><![CDATA[ 
 <br><br>Heidi Pan, Benjamin Hindman, Krste Asanovic (2009)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/pan2009lithe.html</link><guid isPermaLink="false">Literature Notes/pan2009lithe.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:34 GMT</pubDate></item><item><title><![CDATA[Composing parallel software efficiently with lithe]]></title><description><![CDATA[ 
 <br><br>Heidi Pan, Benjamin Hindman, Krste Asanović (2010)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Heidi-Pan" class="tag" target="_blank" rel="noopener">#Heidi-Pan</a> <a href="https://jayitha.github.io/Notes?query=tag:Benjamin-Hindman" class="tag" target="_blank" rel="noopener">#Benjamin-Hindman</a> <a href="https://jayitha.github.io/Notes?query=tag:Krste-Asanović" class="tag" target="_blank" rel="noopener">#Krste-Asanović</a><br>Abstract
Applications composed of multiple parallel libraries perform poorly when those libraries interfere with one another by obliviously using the same physical cores, leading to destructive resource oversubscription. This paper presents the design and implementation of Lithe, a low-level substrate that provides the basic primitives and a standard interface for composing parallel codes efficiently. Lithe can be inserted underneath the runtimes of legacy parallel libraries to provide bolt-on composability without needing to change existing application code. Lithe can also serve as the foundation for building new parallel abstractions and libraries that automatically interoperate with one another. In this paper, we show versions of Threading Building Blocks (TBB) and OpenMP perform competitively with their original implementations when ported to Lithe. Furthermore, for two applications composed of multiple parallel libraries, we show that leveraging our substrate outperforms their original, even expertly tuned, implementations.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/pan2010composing.html</link><guid isPermaLink="false">Literature Notes/pan2010composing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:00:19 GMT</pubDate></item><item><title><![CDATA[A reconfigurable FTL (flash translation layer) architecture for NAND flash-based applications]]></title><description><![CDATA[ 
 <br><br>Chanik Park, Wonmoon Cheon, Jeonguk Kang, Kangho Roh, Wonhee Cho, Jin-Soo Kim (2008)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Chanik-Park" class="tag" target="_blank" rel="noopener">#Chanik-Park</a> <a href="https://jayitha.github.io/Notes?query=tag:Wonmoon-Cheon" class="tag" target="_blank" rel="noopener">#Wonmoon-Cheon</a> <a href="https://jayitha.github.io/Notes?query=tag:Jeonguk-Kang" class="tag" target="_blank" rel="noopener">#Jeonguk-Kang</a> <a href="https://jayitha.github.io/Notes?query=tag:Kangho-Roh" class="tag" target="_blank" rel="noopener">#Kangho-Roh</a> <a href="https://jayitha.github.io/Notes?query=tag:Wonhee-Cho" class="tag" target="_blank" rel="noopener">#Wonhee-Cho</a> <a href="https://jayitha.github.io/Notes?query=tag:Jin-Soo-Kim" class="tag" target="_blank" rel="noopener">#Jin-Soo-Kim</a><br>Abstract
In this article, a novel FTL (flash translation layer) architecture is proposed for NAND flash-based applications such as MP3 players, DSCs (digital still cameras) and SSDs (solid-state drives). Although the basic function of an FTL is to translate a logical sector address to a physical sector address in flash memory, efficient algorithms of an FTL have a significant impact on performance as well as the lifetime. After the dominant parameters that affect the performance and endurance are categorized, the design space of the FTL architecture is explored based on a diverse workload analysis. With the proposed FTL architectural framework, it is possible to decide which configuration of FTL mapping parameters yields the best performance, depending on the differing characteristics of various NAND flash-based applications.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/park2008reconfigurable.html</link><guid isPermaLink="false">Literature Notes/park2008reconfigurable.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:29:07 GMT</pubDate></item><item><title><![CDATA[Verdictdb: Universalizing approximate query processing]]></title><description><![CDATA[ 
 <br><br>Yongjoo Park, Barzan Mozafari, Joseph Sorenson, Junhao Wang (2018)<br>Tags: <br>Abstract
Despite 25 years of research in academia, approximate query processing (AQP) has had little industrial adoption. One of the major causes of this slow adoption is the reluctance of traditional vendors to make radical changes to their legacy codebases, and the preoccupation of newer vendors (e.g., SQL-on-Hadoop products) with implementing standard features. Additionally, the few AQP engines that are available are each tied to a specific platform and require users to completely abandon their existing databases—an unrealistic expectation given the infancy of the AQP technology. Therefore, we argue that a universal solution is needed: a database-agnostic approximation engine that will widen the reach of this emerging technology across various platforms. Our proposal, called VerdictDB, uses a middleware architecture that requires no changes to the backend database, and thus, can work with all off-the-shelf engines. Operating at the driver-level, VerdictDB intercepts analytical queries issued to the database and rewrites them into another query that, if executed by any standard relational engine, will yield sufficient information for computing an approximate answer. VerdictDB uses the returned result set to compute an approximate answer and error estimates, which are then passed on to the user or application. However, lack of access to the query execution layer introduces significant challenges in terms of generality, correctness, and efficiency. This paper shows how VerdictDB overcomes these challenges and delivers up to 171× speedup (18.45× on average) for a variety of existing engines, such as Impala, Spark SQL, and Amazon Redshift, while incurring less than 2.6% relative error. VerdictDB is open-sourced under Apache License.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/park2018verdictdb.html</link><guid isPermaLink="false">Literature Notes/park2018verdictdb.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:37 GMT</pubDate></item><item><title><![CDATA[A case for redundant arrays of inexpensive disks (RAID)]]></title><description><![CDATA[ 
 <br><br>David A Patterson, Garth Gibson, Randy H Katz (1988)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:A-Patterson" class="tag" target="_blank" rel="noopener">#A-Patterson</a> <a href="https://jayitha.github.io/Notes?query=tag:Garth-Gibson" class="tag" target="_blank" rel="noopener">#Garth-Gibson</a> <a href="https://jayitha.github.io/Notes?query=tag:Randy" class="tag" target="_blank" rel="noopener">#Randy</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Katz" class="tag" target="_blank" rel="noopener">#H-Katz</a><br>Abstract
Increasing performance of CPUs and memories will be squandered if not matched by a similar performance increase in I/O. While the capacity of Single Large Expensive Disks (SLED) has grown rapidly, the performance improvement of SLED has been modest. Redundant Arrays of Inexpensive Disks (RAID), based on the magnetic disk technology developed for personal computers, offers an attractive alternative to SLED, promising improvements of an order of magnitude in performance, reliability, power consumption, and scalability. This paper introduces five levels of RAIDs, giving their relative cost/performance, and compares RAID to an IBM 3380 and a Fujitsu Super Eagle.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/patterson1988case.html</link><guid isPermaLink="false">Literature Notes/patterson1988case.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:18:25 GMT</pubDate></item><item><title><![CDATA[A comparison of approaches to large-scale data analysis]]></title><description><![CDATA[ 
 <br><br>Andrew Pavlo, Erik Paulson, Alexander Rasin, Daniel J Abadi, David J DeWitt, Samuel Madden, Michael Stonebraker (2009)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Pavlo" class="tag" target="_blank" rel="noopener">#Andrew-Pavlo</a> <a href="https://jayitha.github.io/Notes?query=tag:Erik-Paulson" class="tag" target="_blank" rel="noopener">#Erik-Paulson</a> <a href="https://jayitha.github.io/Notes?query=tag:Alexander-Rasin" class="tag" target="_blank" rel="noopener">#Alexander-Rasin</a> <a href="https://jayitha.github.io/Notes?query=tag:Daniel" class="tag" target="_blank" rel="noopener">#Daniel</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Abadi" class="tag" target="_blank" rel="noopener">#J-Abadi</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:J-DeWitt" class="tag" target="_blank" rel="noopener">#J-DeWitt</a> <a href="https://jayitha.github.io/Notes?query=tag:Samuel-Madden" class="tag" target="_blank" rel="noopener">#Samuel-Madden</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Stonebraker" class="tag" target="_blank" rel="noopener">#Michael-Stonebraker</a><br>Abstract
There is currently considerable enthusiasm around the MapReduce (MR) paradigm for large-scale data analysis [17]. Although the basic control flow of this framework has existed in parallel SQL database management systems (DBMS) for over 20 years, some have called MR a dramatically new computing model [8, 17]. In this paper, we describe and compare both paradigms. Furthermore, we evaluate both kinds of systems in terms of performance and development complexity. To this end, we define a benchmark consisting of a collection of tasks that we have run on an open source version of MR as well as on two parallel DBMSs. For each task, we measure each system's performance for various degrees of parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs. Although the process to load data into and tune the execution of parallel DBMSs took much longer than the MR system, the observed performance of these DBMSs was strikingly better. We speculate about the causes of the dramatic performance difference and consider implementation concepts that future systems should take from both kinds of architectures.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/pavlo2009comparison.html</link><guid isPermaLink="false">Literature Notes/pavlo2009comparison.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:41 GMT</pubDate></item><item><title><![CDATA[Self-driving database management systems.]]></title><description><![CDATA[ 
 <br><br>Andrew Pavlo, Gustavo Angulo, Joy Arulraj, Haibin Lin, Jiexi Lin, Lin Ma, Prashanth Menon, Todd C Mowry, Matthew Perron, Ian Quah, others (2017)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrew-Pavlo" class="tag" target="_blank" rel="noopener">#Andrew-Pavlo</a> <a href="https://jayitha.github.io/Notes?query=tag:Gustavo-Angulo" class="tag" target="_blank" rel="noopener">#Gustavo-Angulo</a> <a href="https://jayitha.github.io/Notes?query=tag:Joy-Arulraj" class="tag" target="_blank" rel="noopener">#Joy-Arulraj</a> <a href="https://jayitha.github.io/Notes?query=tag:Haibin-Lin" class="tag" target="_blank" rel="noopener">#Haibin-Lin</a> <a href="https://jayitha.github.io/Notes?query=tag:Jiexi-Lin" class="tag" target="_blank" rel="noopener">#Jiexi-Lin</a> <a href="https://jayitha.github.io/Notes?query=tag:Lin-Ma" class="tag" target="_blank" rel="noopener">#Lin-Ma</a> <a href="https://jayitha.github.io/Notes?query=tag:Prashanth-Menon" class="tag" target="_blank" rel="noopener">#Prashanth-Menon</a> <a href="https://jayitha.github.io/Notes?query=tag:Todd" class="tag" target="_blank" rel="noopener">#Todd</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Mowry" class="tag" target="_blank" rel="noopener">#C-Mowry</a> <a href="https://jayitha.github.io/Notes?query=tag:Matthew-Perron" class="tag" target="_blank" rel="noopener">#Matthew-Perron</a> <a href="https://jayitha.github.io/Notes?query=tag:Ian-Quah" class="tag" target="_blank" rel="noopener">#Ian-Quah</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/pavlo2017self.html</link><guid isPermaLink="false">Literature Notes/pavlo2017self.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:53:33 GMT</pubDate></item><item><title><![CDATA[Database Internals: A deep dive into how distributed data systems work]]></title><description><![CDATA[ 
 <br><br>Alex Petrov (2019)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Alex-Petrov" class="tag" target="_blank" rel="noopener">#Alex-Petrov</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/petrov2019database.html</link><guid isPermaLink="false">Literature Notes/petrov2019database.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 23 Feb 2024 13:48:30 GMT</pubDate></item><item><title><![CDATA[Analysis and evolution of journaling file systems.]]></title><description><![CDATA[ 
 <br><br>Vijayan Prabhakaran, Andrea C Arpaci-Dusseau, Remzi H Arpaci-Dusseau (2005)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Vijayan-Prabhakaran" class="tag" target="_blank" rel="noopener">#Vijayan-Prabhakaran</a> <a href="https://jayitha.github.io/Notes?query=tag:Andrea" class="tag" target="_blank" rel="noopener">#Andrea</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Arpaci-Dusseau" class="tag" target="_blank" rel="noopener">#C-Arpaci-Dusseau</a> <a href="https://jayitha.github.io/Notes?query=tag:Remzi" class="tag" target="_blank" rel="noopener">#Remzi</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Arpaci-Dusseau" class="tag" target="_blank" rel="noopener">#H-Arpaci-Dusseau</a><br>Abstract
We develop and apply two new methods for analyzing file system behavior and evaluating file system changes. First, semantic block-level analysis (SBA) combines knowledge of on-disk data structures with a trace of disk traffic to infer file system behavior; in contrast to standard benchmarking approaches, SBA enables users to understand why the file system behaves as it does. Second, semantic trace playback (STP) enables traces of disk traffic to be easily modified to represent changes in the file system implementation; in contrast to directly modifying the file system, STP enables users to rapidly gauge the benefits of new policies. We use SBA to analyze Linux ext3, ReiserFS, JFS, and Windows NTFS; in the process, we uncover many strengths and weaknesses of these journaling file systems. We also apply STP to evaluate several modifications to ext3, demonstrating the benefits of various optimizations without incurring the costs of a real implementation.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/prabhakaran2005analysis.html</link><guid isPermaLink="false">Literature Notes/prabhakaran2005analysis.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:11:36 GMT</pubDate></item><item><title><![CDATA[I've seen" Enough" incrementally improving visualizations to support rapid decision making]]></title><description><![CDATA[ 
 <br><br>Sajjadur Rahman, Maryam Aliakbarpour, Ha Kyung Kong, Eric Blais, Karrie Karahalios, Aditya Parameswaran, Ronitt Rubinfield (2017)<br>Tags: <br>Abstract
Data visualization is an effective mechanism for identifying trends, insights, and anomalies in data. On large datasets, however, generating visualizations can take a long time, delaying the extraction of insights, hampering decision making, and reducing exploration time. One solution is to use online sampling-based schemes to generate visualizations faster while improving the displayed estimates incrementally, eventually converging to the exact visualization computed on the entire data. However, the intermediate visualizations are approximate, and often fluctuate drastically, leading to potentially incorrect decisions. We propose sampling-based incremental visualization algorithms that reveal the "salient" features of the visualization quickly—with a 46× speedup relative to baselines—while minimizing error, thus enabling rapid and error-free decision making. We demonstrate that these algorithms are optimal in terms of sample complexity, in that given the level of interactivity, they generate approximations that take as few samples as possible. We have developed the algorithms in the context of an incremental visualization tool, titled IncVisage, for trendline and heatmap visualizations. We evaluate the usability of IncVisage via user studies and demonstrate that users are able to make effective decisions with incrementally improving visualizations, especially compared to vanilla online-sampling based schemes.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rahman2017ve.html</link><guid isPermaLink="false">Literature Notes/rahman2017ve.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:32 GMT</pubDate></item><item><title><![CDATA[Partial results for online query processing]]></title><description><![CDATA[ 
 <br><br>Vijayshankar Raman, Joseph M Hellerstein (2002)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Vijayshankar-Raman" class="tag" target="_blank" rel="noopener">#Vijayshankar-Raman</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a><br>Abstract
Traditional query processors generate full, accurate query results, either in batch or in pipelined fashion. We argue that this strict model is too rigid for exploratory queries over diverse and distributed data sources, such as sources on the Internet. Instead, we propose a looser model of querying in which a user submits a broad initial query outline, and the system continually generates partial result tuples that may contain values for only some of the output fields. The user can watch these partial results accumulate at the user interface, and accordingly refine the query by specifying their interest in different kinds of partial results.After describing our querying model and user interface, we present a query processing architecture for this model which is implemented in the Telegraph dataflow system. Our architecture is designed to generate partial results quickly, and to adapt query execution to changing user interests. The crux of this architecture is a dataflow operator that supports two kinds of reorderings: reordering of intermediate tuples within a dataflow, and reordering of query plan operators through which tuples flow. We study reordering policies that optimize for the quality of partial results delivered over time, and experimentally demonstrate the benefits of our architecture in this context.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/raman2002partial.html</link><guid isPermaLink="false">Literature Notes/raman2002partial.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:11:45 GMT</pubDate></item><item><title><![CDATA[Making B+-Trees cache conscious in main memory]]></title><description><![CDATA[ 
 <br><br>Jun Rao, Kenneth A Ross (2000)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Jun-Rao" class="tag" target="_blank" rel="noopener">#Jun-Rao</a> <a href="https://jayitha.github.io/Notes?query=tag:Kenneth" class="tag" target="_blank" rel="noopener">#Kenneth</a> <a href="https://jayitha.github.io/Notes?query=tag:A-Ross" class="tag" target="_blank" rel="noopener">#A-Ross</a><br>Abstract
Previous research has shown that cache behavior is important for main memory index structures. Cache conscious index structures such as Cache Sensitive Search Trees (CSS-Trees) perform lookups much faster than binary search and T-Trees. However, CSS-Trees are designed for decision support workloads with relatively static data. Although B+-Trees are more cache conscious than binary search and T-Trees, their utilization of a cache line is low since half of the space is used to store child pointers. Nevertheless, for applications that require incremental updates, traditional B+-Trees perform well. Our goal is to make B+-Trees as cache conscious as CSS-Trees without increasing their update cost too much. We propose a new indexing technique called “Cache Sensitive B+-Trees” (CSB+-Trees). It is a variant of B+-Trees that stores all the child nodes of any given node contiguously, and keeps only the address of the first child in each node. The rest of the children can be found by adding an offset to that address. Since only one child pointer is stored explicitly, the utilization of a cache line is high. CSB+-Trees support incremental updates in a way similar to B+-Trees. We also introduce two variants of CSB+-Trees. Segmented CSB+-Trees divide the child nodes into segments. Nodes within the same segment are stored contiguously and only pointers to the beginning of each segment are stored explicitly in each node. Segmented CSB+-Trees can reduce the copying cost when there is a split since only one segment needs to be moved. Full CSB+-Trees preallocate space for the full node group and thus reduce the split cost. Our performance studies show that CSB+-Trees are useful for a wide range of applications.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rao2000making.html</link><guid isPermaLink="false">Literature Notes/rao2000making.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:32:16 GMT</pubDate></item><item><title><![CDATA[Microkernel operating system architecture and mach]]></title><description><![CDATA[ 
 <br><br>RICHARD F RAsHD, RıcARD P DRAvEs, RANDALL W DEAN (1991)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:RICHARD" class="tag" target="_blank" rel="noopener">#RICHARD</a> <a href="https://jayitha.github.io/Notes?query=tag:F-RAsHD" class="tag" target="_blank" rel="noopener">#F-RAsHD</a> <a href="https://jayitha.github.io/Notes?query=tag:RıcARD" class="tag" target="_blank" rel="noopener">#RıcARD</a> <a href="https://jayitha.github.io/Notes?query=tag:P-DRAvEs" class="tag" target="_blank" rel="noopener">#P-DRAvEs</a> <a href="https://jayitha.github.io/Notes?query=tag:RANDALL" class="tag" target="_blank" rel="noopener">#RANDALL</a> <a href="https://jayitha.github.io/Notes?query=tag:W-DEAN" class="tag" target="_blank" rel="noopener">#W-DEAN</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/rashd1991microkernel.html</link><guid isPermaLink="false">Literature Notes/rashd1991microkernel.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:28 GMT</pubDate></item><item><title><![CDATA[Holoclean: Holistic data repairs with probabilistic inference]]></title><description><![CDATA[ 
 <br><br>Theodoros Rekatsinas, Xu Chu, Ihab F Ilyas, Christopher Ré (2017)<br>Tags: <br>Abstract
We introduce HoloClean, a framework for holistic data repairing driven by probabilistic inference. HoloClean unifies existing qualitative data repairing approaches, which rely on integrity constraints or external data sources, with quantitative data repairing methods, which leverage statistical properties of the input data. Given an inconsistent dataset as input, HoloClean automatically generates a probabilistic program that performs data repairing. Inspired by recent theoretical advances in probabilistic inference, we introduce a series of optimizations which ensure that inference over HoloClean's probabilistic model scales to instances with millions of tuples. We show that HoloClean scales to instances with millions of tuples and find data repairs with an average precision of ~90% and an average recall of above ~76% across a diverse array of datasets exhibiting different types of errors. This yields an average F1 improvement of more than 2x against state-of-the-art methods.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rekatsinas2017holoclean.html</link><guid isPermaLink="false">Literature Notes/rekatsinas2017holoclean.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:14:58 GMT</pubDate></item><item><title><![CDATA[Precisely serializable snapshot isolation (PSSI)]]></title><description><![CDATA[ 
 <br><br>Stephen Revilak, Patrick O'Neil, Elizabeth O'Neil (2011)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Stephen-Revilak" class="tag" target="_blank" rel="noopener">#Stephen-Revilak</a> <a href="https://jayitha.github.io/Notes?query=tag:Patrick-O" class="tag" target="_blank" rel="noopener">#Patrick-O</a>'Neil <a href="https://jayitha.github.io/Notes?query=tag:Elizabeth-O" class="tag" target="_blank" rel="noopener">#Elizabeth-O</a>'Neil<br>Abstract
Many popular database management systems provide snapshot isolation (SI) for concurrency control, either in addition to or in place of full serializability based on locking. Snapshot isolation was introduced in 1995, with noted anomalies that can lead to serializability violations. Full serializability was provided in 2008 and improved in 2009 by aborting transactions in dangerous structures, which had been shown in 2005 to be precursors to potential SI anomalies. This approach resulted in a runtime environment guaranteeing a serializable form of snapshot isolation (which we call SSI or ESSI) for arbitrary applications. But transactions in a dangerous structure frequently do not cause true anomalies so, as the authors point out, their method is conservative: it can cause unnecessary aborts. In the current paper, we demonstrate our PSSI algorithm to detect cycles in a snapshot isolation dependency graph and abort transactions to break the cycle. This algorithm provides a much more precise criterion to perform aborts. We have implemented our algorithm in an open source production database system (MySQL/InnoDB), and our performance study shows that PSSI throughput improves on ESSI, with significantly fewer aborts.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/revilak2011precisely.html</link><guid isPermaLink="false">Literature Notes/revilak2011precisely.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:26:41 GMT</pubDate></item><item><title><![CDATA[Pond: The {OceanStore} prototype]]></title><description><![CDATA[ 
 <br><br>Sean Rhea, Patrick Eaton, Dennis Geels, Hakim Weatherspoon, Ben Zhao, John Kubiatowicz (2003)<br>Tags: <br>Abstract
OceanStore is an Internet-scale, persistent data store designed for incremental scalability, secure sharing, and long-term durability. Pond is the OceanStore prototype; it contains many of the features of a complete system including location-independent routing, Byzantine update commitment, push-based update of cached copies through an overlay multicast network, and continuous archiving to erasure-coded form. In the wide area, Pond outperforms NFS by up to a factor of 4.6 on read-intensive phases of the Andrew benchmark, but underperforms NFS by as much as a factor of 7.3 on write-intensive phases. Microbenchmarks show that write performance is limited by the speed of erasure coding and threshold signature generation, two important areas of future research. Further microbenchmarks show that Pond manages replica consistency in a bandwidth-efficient manner and quantify the latency cost imposed by this bandwidth savings.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rhea2003pond.html</link><guid isPermaLink="false">Literature Notes/rhea2003pond.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:03:41 GMT</pubDate></item><item><title><![CDATA[Handling churn in a DHT]]></title><description><![CDATA[ 
 <br><br>Sean Rhea, Dennis Geels, Timothy Roscoe, John Kubiatowicz, others (2004)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Sean-Rhea" class="tag" target="_blank" rel="noopener">#Sean-Rhea</a> <a href="https://jayitha.github.io/Notes?query=tag:Dennis-Geels" class="tag" target="_blank" rel="noopener">#Dennis-Geels</a> <a href="https://jayitha.github.io/Notes?query=tag:Timothy-Roscoe" class="tag" target="_blank" rel="noopener">#Timothy-Roscoe</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Kubiatowicz" class="tag" target="_blank" rel="noopener">#John-Kubiatowicz</a> <a href="https://jayitha.github.io/Notes?query=tag:-others" class="tag" target="_blank" rel="noopener">#-others</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/rhea2004handling.html</link><guid isPermaLink="false">Literature Notes/rhea2004handling.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:52 GMT</pubDate></item><item><title><![CDATA[The UNIX time-sharing system]]></title><description><![CDATA[ 
 <br><br>Dennis M Ritchie, Ken Thompson (1978)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Dennis" class="tag" target="_blank" rel="noopener">#Dennis</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Ritchie" class="tag" target="_blank" rel="noopener">#M-Ritchie</a> <a href="https://jayitha.github.io/Notes?query=tag:Ken-Thompson" class="tag" target="_blank" rel="noopener">#Ken-Thompson</a><br>Abstract
unix* is a general-purpose, multi-user, interactive operating system for the larger Digital Equipment Corporation pdp-11 and the Interdata 8/32 computers. It offers a number of features seldom found even in larger operating systems, including (i) A hierarchical file system incorporating demountable volumes, (ii) Compatible file, device, and inter-process I/O, (iii) The ability to initiate asynchronous processes, (iv) System command language selectable on a per-user basis, (v) Over 100 subsystems including a dozen languages, (vi) High degree of portability. This paper discusses the nature and implementation of the file system and of the user command interface.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/ritchie1978unix.html</link><guid isPermaLink="false">Literature Notes/ritchie1978unix.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:04:59 GMT</pubDate></item><item><title><![CDATA[Writing reviews for systems conferences]]></title><description><![CDATA[ 
 <br><br>Timothy Roscoe (2007)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Timothy-Roscoe" class="tag" target="_blank" rel="noopener">#Timothy-Roscoe</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/roscoe2007writing.html</link><guid isPermaLink="false">Literature Notes/roscoe2007writing.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:43:00 GMT</pubDate></item><item><title><![CDATA[The design and implementation of a log-structured file system]]></title><description><![CDATA[ 
 <br><br>Mendel Rosenblum, John K Ousterhout (1992)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mendel-Rosenblum" class="tag" target="_blank" rel="noopener">#Mendel-Rosenblum</a> <a href="https://jayitha.github.io/Notes?query=tag:John" class="tag" target="_blank" rel="noopener">#John</a> <a href="https://jayitha.github.io/Notes?query=tag:K-Ousterhout" class="tag" target="_blank" rel="noopener">#K-Ousterhout</a><br>Abstract
This paper presents a new technique for disk storage management called a log-structured file system. A log-structured file system writes all modifications to disk sequentially in a log-like structure, thereby speeding up both file writing and crash recovery. The log is the only structure on disk; it contains indexing information so that files can be read back from the log efficiently. In order to maintain large free areas on disk for fast writing, we divide the log intosegmentsand use a segment cleaner to compress the live information from heavily fragmented segments. We present a series of simulations that demonstrate the efficiency of a simple cleaning policy based on cost and benefit. We have implemented a prototype log-structured file system called Sprite LFS; it outperforms current Unix file systems by an order of magnitude for small-file writes while matching or exceeding Unix performance for reads and large writes. Even when the overhead for cleaning is included, Sprite LFS can use 70% of the disk bandwidth for writing, whereas Unix file systems typically can use only 5–10%.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rosenblum1992design.html</link><guid isPermaLink="false">Literature Notes/rosenblum1992design.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:15:48 GMT</pubDate></item><item><title><![CDATA[Pastry: Scalable, decentralized object location, and routing for large-scale peer-to-peer systems]]></title><description><![CDATA[ 
 <br><br>Antony Rowstron, Peter Druschel (2001)<br>Tags: <br>Abstract
This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing substrate for wide-area peer-to-peer applications. Pastry performs application-level routing and object location in a potentially very large overlay network of nodes connected via the Internet. It can be used to support a variety of peer-to-peer applications, including global data storage, data sharing, group communication and naming. Each node in the Pastry network has a unique identifier (nodeId). When presented with a message and a key, a Pastry node efficiently routes the message to the node with a nodeId that is numerically closest to the key, among all currently live Pastry nodes. Each Pastry node keeps track of its immediate neighbors in the nodeId space, and notifies applications of new node arrivals, node failures and recoveries. Pastry takes into account network locality; it seeks to minimize the distance messages travel, according to a to scalar proximity metric like the number of IP routing hops Pastry is completely decentralized, scalable, and self-organizing; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on an emulated network of up to 100,000 nodes confirm Pastry's scalability and efficiency, its ability to self-organize and adapt to node failures, and its good network locality properties
]]></description><link>https://jayitha.github.io/Notes/literature-notes/rowstron2001pastry.html</link><guid isPermaLink="false">Literature Notes/rowstron2001pastry.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:03:19 GMT</pubDate></item><item><title><![CDATA[Storage management and caching in PAST]]></title><description><![CDATA[ 
 <br><br>Antony Rowstron, Peter Druschel (2001)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Antony-Rowstron" class="tag" target="_blank" rel="noopener">#Antony-Rowstron</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Druschel" class="tag" target="_blank" rel="noopener">#Peter-Druschel</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/rowstron2001storage.html</link><guid isPermaLink="false">Literature Notes/rowstron2001storage.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 26 Dec 2023 10:27:10 GMT</pubDate></item><item><title><![CDATA[Can learned models replace hash functions?]]></title><description><![CDATA[ 
 <br><br>Ibrahim Sabek, Kapil Vaidya, Dominik Horn, Andreas Kipf, Michael Mitzenmacher, Tim Kraska (2022)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Ibrahim-Sabek" class="tag" target="_blank" rel="noopener">#Ibrahim-Sabek</a> <a href="https://jayitha.github.io/Notes?query=tag:Kapil-Vaidya" class="tag" target="_blank" rel="noopener">#Kapil-Vaidya</a> <a href="https://jayitha.github.io/Notes?query=tag:Dominik-Horn" class="tag" target="_blank" rel="noopener">#Dominik-Horn</a> <a href="https://jayitha.github.io/Notes?query=tag:Andreas-Kipf" class="tag" target="_blank" rel="noopener">#Andreas-Kipf</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Mitzenmacher" class="tag" target="_blank" rel="noopener">#Michael-Mitzenmacher</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Kraska" class="tag" target="_blank" rel="noopener">#Tim-Kraska</a><br>Abstract
Hashing is a fundamental operation in database management, playing a key role in the implementation of numerous core database data structures and algorithms. Traditional hash functions aim to mimic a function that maps a key to a random value, which can result in collisions, where multiple keys are mapped to the same value. There are many well-known schemes like chaining, probing, and cuckoo hashing to handle collisions. In this work, we aim to study if using learned models instead of traditional hash functions can reduce collisions and whether such a reduction translates to improved performance, particularly for indexing and joins. We show that learned models reduce collisions in some cases, which depend on how the data is distributed. To evaluate the effectiveness of learned models as hash function, we test them with bucket chaining, linear probing, and cuckoo hash tables. We find that learned models can (1) yield a 1.4x lower probe latency, and (2) reduce the non-partitioned hash join runtime with 28% over the next best baseline for certain datasets. On the other hand, if the data distribution is not suitable, we either do not see gains or see worse performance. In summary, we find that learned models can indeed outperform hash functions, but only for certain data distributions.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/sabek2022can.html</link><guid isPermaLink="false">Literature Notes/sabek2022can.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 17:52:24 GMT</pubDate></item><item><title><![CDATA[End-to-end arguments in system design]]></title><description><![CDATA[ 
 <br><br>Jerome H Saltzer, David P Reed, David D Clark (1984)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Jerome" class="tag" target="_blank" rel="noopener">#Jerome</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Saltzer" class="tag" target="_blank" rel="noopener">#H-Saltzer</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:P-Reed" class="tag" target="_blank" rel="noopener">#P-Reed</a> <a href="https://jayitha.github.io/Notes?query=tag:D-Clark" class="tag" target="_blank" rel="noopener">#D-Clark</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/saltzer1984end.html</link><guid isPermaLink="false">Literature Notes/saltzer1984end.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:06:09 GMT</pubDate></item><item><title><![CDATA[Hydroflow: A model and runtime for distributed systems programming]]></title><description><![CDATA[ 
 <br><br>Mingwei Samuel, Joseph M Hellerstein, Alvin Cheung (2021)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mingwei-Samuel" class="tag" target="_blank" rel="noopener">#Mingwei-Samuel</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Alvin-Cheung" class="tag" target="_blank" rel="noopener">#Alvin-Cheung</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/samuel2021hydroflow.html</link><guid isPermaLink="false">Literature Notes/samuel2021hydroflow.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:19:42 GMT</pubDate></item><item><title><![CDATA[A fast and slippery slope for file systems]]></title><description><![CDATA[ 
 <br><br>Ricardo Santana, Raju Rangaswami, Vasily Tarasov, Dean Hildebrand (2016)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Ricardo-Santana" class="tag" target="_blank" rel="noopener">#Ricardo-Santana</a> <a href="https://jayitha.github.io/Notes?query=tag:Raju-Rangaswami" class="tag" target="_blank" rel="noopener">#Raju-Rangaswami</a> <a href="https://jayitha.github.io/Notes?query=tag:Vasily-Tarasov" class="tag" target="_blank" rel="noopener">#Vasily-Tarasov</a> <a href="https://jayitha.github.io/Notes?query=tag:Dean-Hildebrand" class="tag" target="_blank" rel="noopener">#Dean-Hildebrand</a><br>Abstract
There is a vast number and variety of file systems currently available, each optimizing for an ever growing number of storage devices and workloads. Users have an unprecedented, and somewhat overwhelming, number of data management options. At the same time, the fastest storage devices are only getting faster, and it is unclear on how well the existing file systems will adapt. Using emulation techniques, we evaluate five popular Linux file systems across a range of storage device latencies typical to low-end hard drives, latest high-performance persistent memory block devices, and in between. Our findings are often surprising. Depending on the workload, we find that some file systems can clearly scale with faster storage devices much better than others. Further, as storage device latency decreases, we find unexpected performance inversions across file systems. Finally, file system scalability in the higher device latency range is not representative of scalability in the lower, submillisecond, latency range. We then focus on Nilfs2 as an especially alarming example of an unexpectedly poor scalability and present detailed instructions for identifying bottlenecks in the I/O stack.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/santana2016fast.html</link><guid isPermaLink="false">Literature Notes/santana2016fast.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:29:03 GMT</pubDate></item><item><title><![CDATA[Lightweight recoverable virtual memory]]></title><description><![CDATA[ 
 <br><br>Mahadev Satyanarayanan, Henry H Mashburn, Puneet Kumar, David C Steere, James J Kistler (1994)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mahadev-Satyanarayanan" class="tag" target="_blank" rel="noopener">#Mahadev-Satyanarayanan</a> <a href="https://jayitha.github.io/Notes?query=tag:Henry" class="tag" target="_blank" rel="noopener">#Henry</a> <a href="https://jayitha.github.io/Notes?query=tag:H-Mashburn" class="tag" target="_blank" rel="noopener">#H-Mashburn</a> <a href="https://jayitha.github.io/Notes?query=tag:Puneet-Kumar" class="tag" target="_blank" rel="noopener">#Puneet-Kumar</a> <a href="https://jayitha.github.io/Notes?query=tag:David" class="tag" target="_blank" rel="noopener">#David</a> <a href="https://jayitha.github.io/Notes?query=tag:C-Steere" class="tag" target="_blank" rel="noopener">#C-Steere</a> <a href="https://jayitha.github.io/Notes?query=tag:James" class="tag" target="_blank" rel="noopener">#James</a> <a href="https://jayitha.github.io/Notes?query=tag:J-Kistler" class="tag" target="_blank" rel="noopener">#J-Kistler</a><br>Abstract
Recoverable virtual memoryrefers to regions of a virtual address space on which transactional guarantees are offered. This article describes RVM, an efficient, portable, and easily used implementation of recoverable virtual memory for Unix environments. A unique characteristic of RVM is that it allows independent control over the transactional properties of atomicity, permanence, and serializability. This leads to considerable flexibility in the use of RVM, potentially enlarging the range of applications that can benefit from transactions. It also simplifies the layering of functionality such as nesting and distribution. The article shows that RVM performs well over its intended range of usage even though it does not benefit from specialized operating system support. It also demonstrates the importance of intra- and inter-transaction optimizations.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/satyanarayanan1994lightweight.html</link><guid isPermaLink="false">Literature Notes/satyanarayanan1994lightweight.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:39:32 GMT</pubDate></item><item><title><![CDATA[The case for vm-based cloudlets in mobile computing]]></title><description><![CDATA[ 
 <br><br>Mahadev Satyanarayanan, Paramvir Bahl, Ramón Caceres, Nigel Davies (2009)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mahadev-Satyanarayanan" class="tag" target="_blank" rel="noopener">#Mahadev-Satyanarayanan</a> <a href="https://jayitha.github.io/Notes?query=tag:Paramvir-Bahl" class="tag" target="_blank" rel="noopener">#Paramvir-Bahl</a> <a href="https://jayitha.github.io/Notes?query=tag:Ramón-Caceres" class="tag" target="_blank" rel="noopener">#Ramón-Caceres</a> <a href="https://jayitha.github.io/Notes?query=tag:Nigel-Davies" class="tag" target="_blank" rel="noopener">#Nigel-Davies</a><br>Abstract
Mobile computing continuously evolve through the sustained effort of many researchers. It seamlessly augments users' cognitive abilities via compute-intensive capabilities such as speech recognition, natural language processing, etc. By thus empowering mobile users, we could transform many areas of human activity. This article discusses the technical obstacles to these transformations and proposes a new architecture for overcoming them. In this architecture, a mobile user exploits virtual machine (VM) technology to rapidly instantiate customized service software on a nearby cloudlet and then uses that service over a wireless LAN; the mobile device typically functions as a thin client with respect to the service. A cloudlet is a trusted, resource-rich computer or cluster of computers that's well-connected to the Internet and available for use by nearby mobile devices. Our strategy of leveraging transiently customized proximate infrastructure as a mobile device moves with its user through the physical world is called cloudlet-based, resource-rich, mobile computing. Crisp interactive response, which is essential for seamless augmentation of human cognition, is easily achieved in this architecture because of the cloudlet's physical proximity and one-hop network latency. Using a cloudlet also simplifies the challenge of meeting the peak bandwidth demand of multiple users interactively generating and receiving media such as high-definition video and high-resolution images. Rapid customization of infrastructure for diverse applications emerges as a critical requirement, and our results from a proof-of-concept prototype suggest that VM technology can indeed help meet this requirement.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/satyanarayanan2009case.html</link><guid isPermaLink="false">Literature Notes/satyanarayanan2009case.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:35 GMT</pubDate></item><item><title><![CDATA[The emergence of edge computing]]></title><description><![CDATA[ 
 <br><br>Mahadev Satyanarayanan (2017)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Mahadev-Satyanarayanan" class="tag" target="_blank" rel="noopener">#Mahadev-Satyanarayanan</a><br>Abstract
Industry investment and research interest in edge computing, in which computing and storage nodes are placed at the Internet's edge in close proximity to mobile devices or sensors, have grown dramatically in recent years. This emerging technology promises to deliver highly responsive cloud services for mobile computing, scalability and privacy-policy enforcement for the Internet of Things, and the ability to mask transient cloud outages. The web extra at <a data-tooltip-position="top" aria-label="http://www.youtube.com/playlist?list=PLmrZVvFtthdP3fwHPy_4d61oDvQY_RBgS" rel="noopener" class="external-link" href="http://www.youtube.com/playlist?list=PLmrZVvFtthdP3fwHPy_4d61oDvQY_RBgS" target="_blank">www.youtube.com/playlist?list=PLmrZVvFtthdP3fwHPy_4d61oDvQY_RBgS</a> includes a five-video playlist demonstrating proof-of-concept implementations for three tasks: assembling 2D Lego models, freehand sketching, and playing Ping-Pong.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/satyanarayanan2017emergence.html</link><guid isPermaLink="false">Literature Notes/satyanarayanan2017emergence.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:19 GMT</pubDate></item><item><title><![CDATA[The uncracked pieces in database cracking]]></title><description><![CDATA[ 
 <br><br>Felix Martin Schuhknecht, Alekh Jindal, Jens Dittrich (2013)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Felix" class="tag" target="_blank" rel="noopener">#Felix</a> <a href="https://jayitha.github.io/Notes?query=tag:Martin-Schuhknecht" class="tag" target="_blank" rel="noopener">#Martin-Schuhknecht</a> <a href="https://jayitha.github.io/Notes?query=tag:Alekh-Jindal" class="tag" target="_blank" rel="noopener">#Alekh-Jindal</a> <a href="https://jayitha.github.io/Notes?query=tag:Jens-Dittrich" class="tag" target="_blank" rel="noopener">#Jens-Dittrich</a><br>Abstract
Database cracking has been an area of active research in recent years. The core idea of database cracking is to create indexes adaptively and incrementally as a side-product of query processing. Several works have proposed different cracking techniques for different aspects including updates, tuple-reconstruction, convergence, concurrency-control, and robustness. However, there is a lack of any comparative study of these different methods by an independent group. In this paper, we conduct an experimental study on database cracking. Our goal is to critically review several aspects, identify the potential, and propose promising directions in database cracking. With this study, we hope to expand the scope of database cracking and possibly leverage cracking in database engines other than MonetDB. We repeat several prior database cracking works including the core cracking algorithms as well as three other works on convergence (hybrid cracking), tuple-reconstruction (sideways cracking), and robustness (stochastic cracking) respectively. We evaluate these works and show possible directions to do even better. We further test cracking under a variety of experimental settings, including high selectivity queries, low selectivity queries, and multiple query access patterns. Finally, we compare cracking against different sorting algorithms as well as against different main-memory optimised indexes, including the recently proposed Adaptive Radix Tree (ART). Our results show that: (i) the previously proposed cracking algorithms are repeatable, (ii) there is still enough room to significantly improve the previously proposed cracking algorithms, (iii) cracking depends heavily on query selectivity, (iv) cracking needs to catch up with modern indexing trends, and (v) different indexing algorithms have different indexing signatures.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/schuhknecht2013uncracked.html</link><guid isPermaLink="false">Literature Notes/schuhknecht2013uncracked.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:49 GMT</pubDate></item><item><title><![CDATA[Segment-based recovery: Write-ahead logging revisited]]></title><description><![CDATA[ 
 <br><br>Russell Sears, Eric Brewer (2009)<br>Tags: <br>Abstract
Although existing write-ahead logging algorithms scale to conventional database workloads, their communication and synchronization overheads limit their usefulness for modern applications and distributed systems. We revisit write-ahead logging with an eye toward finer-grained concurrency and an increased range of workloads, then remove two core assumptions: that pages are the unit of recovery and that times-tamps (LSNs) should be stored on each page. Recovering individual application-level objects (rather than pages) simplifies the handing of systems with object sizes that differ from the page size. We show how to remove the need for LSNs on the page, which in turn enables DMA or zero-copy I/O for large objects, increases concurrency, and reduces communication between the application, buffer manager and log manager. Our experiments show that the looser coupling significantly reduces the impact of latency among the components. This makes the approach particularly applicable to large scale distributed systems, and enables a "cross pollination" of ideas from distributed systems and transactional storage. However, these advantages come at a cost; segments are incompatible with physiological redo, preventing a number of important optimizations. We show how allocation enables (or prevents) mixing of ARIES pages (and physiological redo) with segments. We present an allocation policy that avoids undesirable interactions that complicate other combinations of ARIES and LSN-free pages, and then present a proof that both approaches and our combination are correct. Many optimizations presented here were proposed in the past. However, we believe this is the first unified approach.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/sears2009segment.html</link><guid isPermaLink="false">Literature Notes/sears2009segment.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:39:27 GMT</pubDate></item><item><title><![CDATA[Conflict-free replicated data types]]></title><description><![CDATA[ 
 <br><br>Marc Shapiro, Nuno Preguiça, Carlos Baquero, Marek Zawirski (2011)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Marc-Shapiro" class="tag" target="_blank" rel="noopener">#Marc-Shapiro</a> <a href="https://jayitha.github.io/Notes?query=tag:Nuno-Preguiça" class="tag" target="_blank" rel="noopener">#Nuno-Preguiça</a> <a href="https://jayitha.github.io/Notes?query=tag:Carlos-Baquero" class="tag" target="_blank" rel="noopener">#Carlos-Baquero</a> <a href="https://jayitha.github.io/Notes?query=tag:Marek-Zawirski" class="tag" target="_blank" rel="noopener">#Marek-Zawirski</a><br>Abstract
Replicating data under Eventual Consistency (EC) allows any replica to accept updates without remote synchronisation. This ensures performance and scalability in large-scale distributed systems (e.g., clouds). However, published EC approaches are ad-hoc and error-prone. Under a formal Strong Eventual Consistency (SEC) model, we study sufficient conditions for convergence. A data type that satisfies these conditions is called a Conflict-free Replicated Data Type (CRDT). Replicas of any CRDT are guaranteed to converge in a self-stabilising manner, despite any number of failures. This paper formalises two popular approaches (state- and operation-based) and their relevant sufficient conditions. We study a number of useful CRDTs, such as sets with clean semantics, supporting both add and remove operations, and consider in depth the more complex Graph data type. CRDT types can be composed to develop large-scale distributed applications, and have interesting theoretical properties.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/shapiro2011conflict.html</link><guid isPermaLink="false">Literature Notes/shapiro2011conflict.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:42:38 GMT</pubDate></item><item><title><![CDATA[Database systems concepts]]></title><description><![CDATA[ 
 <br><br>Abraham Silberschatz, Henry Korth, Shashank Sudarshan (2005)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Abraham-Silberschatz" class="tag" target="_blank" rel="noopener">#Abraham-Silberschatz</a> <a href="https://jayitha.github.io/Notes?query=tag:Henry-Korth" class="tag" target="_blank" rel="noopener">#Henry-Korth</a> <a href="https://jayitha.github.io/Notes?query=tag:Shashank-Sudarshan" class="tag" target="_blank" rel="noopener">#Shashank-Sudarshan</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/silberschatz2005database.html</link><guid isPermaLink="false">Literature Notes/silberschatz2005database.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 06:17:09 GMT</pubDate></item><item><title><![CDATA[Blinkfill: Semi-supervised programming by example for syntactic string transformations]]></title><description><![CDATA[ 
 <br><br>Rishabh Singh (2016)<br>Tags: <br>Abstract
The recent Programming By Example (PBE) techniques such as FlashFill have shown great promise for enabling end-users to perform data transformation tasks using input-output examples. Since examples are inherently an under-specification, there are typically a large number of hypotheses conforming to the examples, and the PBE techniques suffer from scalability issues for finding the intended program amongst the large space. We present a semi-supervised learning technique to significantly reduce this ambiguity by using the logical information present in the input data to guide the synthesis algorithm. We develop a data structure InputDataGraph to succinctly represent a large set of logical patterns that are shared across the input data, and use this graph to efficiently learn substring expressions in a new PBE system BlinkFill. We evaluate BlinkFill on 207 real-world benchmarks and show that BlinkFill is significantly faster (on average 41x) and requires fewer input-output examples (1.27 vs 1.53) to learn the desired transformations in comparison to FlashFill.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/singh2016blinkfill.html</link><guid isPermaLink="false">Literature Notes/singh2016blinkfill.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:15:01 GMT</pubDate></item><item><title><![CDATA[Locality-sensitive hashing for finding nearest neighbors [Lecture notes]]]></title><description><![CDATA[ 
 <br><br>Malcolm Slaney, Michael Casey (2008)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a><br>Abstract
This lecture note describes a technique known as locality-sensitive hashing (LSH) that allows one to quickly find similar entries in large databases. This approach belongs to a novel and interesting class of algorithms that are known as randomized algorithms. A randomized algorithm does not guarantee an exact answer but instead provides a high probability guarantee that it will return the correct answer or one close to it. By investing additional computational effort, the probability can be pushed as high as desired.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/slaney2008locality.html</link><guid isPermaLink="false">Literature Notes/slaney2008locality.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Mon, 06 Nov 2023 09:27:15 GMT</pubDate></item><item><title><![CDATA[Chord: A scalable peer-to-peer lookup protocol for internet applications]]></title><description><![CDATA[ 
 <br><br>Ion Stoica, Robert Morris, David Liben-Nowell, David R Karger, M Frans Kaashoek, Frank Dabek, Hari Balakrishnan (2003)<br>Tags: <br>Abstract
A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/stoica2003chord.html</link><guid isPermaLink="false">Literature Notes/stoica2003chord.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:44 GMT</pubDate></item><item><title><![CDATA[The design and implementation of INGRES]]></title><description><![CDATA[ 
 <br><br>Michael Stonebraker, Eugene Wong, Peter Kreps, Gerald Held (1976)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Michael-Stonebraker" class="tag" target="_blank" rel="noopener">#Michael-Stonebraker</a> <a href="https://jayitha.github.io/Notes?query=tag:Eugene-Wong" class="tag" target="_blank" rel="noopener">#Eugene-Wong</a> <a href="https://jayitha.github.io/Notes?query=tag:Peter-Kreps" class="tag" target="_blank" rel="noopener">#Peter-Kreps</a> <a href="https://jayitha.github.io/Notes?query=tag:Gerald-Held" class="tag" target="_blank" rel="noopener">#Gerald-Held</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract<br>Cites<br>
<a data-href="codd1970relational" href="https://jayitha.github.io/Notes/literature-notes/codd1970relational.html" class="internal-link" target="_self" rel="noopener">codd1970relational</a><br>
<a data-href="codd1971data" href="https://jayitha.github.io/Notes/literature-notes/codd1971data.html" class="internal-link" target="_self" rel="noopener">codd1971data</a><br>
<a data-href="chamberlin1974sequel" href="https://jayitha.github.io/Notes/literature-notes/chamberlin1974sequel.html" class="internal-link" target="_self" rel="noopener">chamberlin1974sequel</a><br>
<a data-href="chamberlin1975views" href="https://jayitha.github.io/Notes/literature-notes/chamberlin1975views.html" class="internal-link" target="_self" rel="noopener">chamberlin1975views</a><br>
<a data-href="astrahan1976system" href="https://jayitha.github.io/Notes/literature-notes/astrahan1976system.html" class="internal-link" target="_self" rel="noopener">astrahan1976system</a><br>
<a data-href="gray1976granularity" href="https://jayitha.github.io/Notes/literature-notes/gray1976granularity.html" class="internal-link" target="_self" rel="noopener">gray1976granularity</a><br><br><br>: <br>: <br>: <br>: <br>: <br>: ]]></description><link>https://jayitha.github.io/Notes/literature-notes/stonebraker1976design.html</link><guid isPermaLink="false">Literature Notes/stonebraker1976design.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:24:31 GMT</pubDate></item><item><title><![CDATA[The design of the Postgres storage system]]></title><description><![CDATA[ 
 <br><br>Michael Stonebraker (1987)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Stonebraker" class="tag" target="_blank" rel="noopener">#Michael-Stonebraker</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/stonebraker1987design.html</link><guid isPermaLink="false">Literature Notes/stonebraker1987design.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:54:06 GMT</pubDate></item><item><title><![CDATA[The POSTGRES next generation database management system]]></title><description><![CDATA[ 
 <br><br>Michael Stonebraker, Greg Kemnitz (1991)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Stonebraker" class="tag" target="_blank" rel="noopener">#Michael-Stonebraker</a> <a href="https://jayitha.github.io/Notes?query=tag:Greg-Kemnitz" class="tag" target="_blank" rel="noopener">#Greg-Kemnitz</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/stonebraker1991postgres.html</link><guid isPermaLink="false">Literature Notes/stonebraker1991postgres.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 05:53:56 GMT</pubDate></item><item><title><![CDATA[MapReduce and parallel DBMSs: Friends or foes?]]></title><description><![CDATA[ 
 <br><br>Michael Stonebraker, Daniel Abadi, David J DeWitt, Sam Madden, Erik Paulson, Andrew Pavlo, Alexander Rasin (2010)<br>Tags: <br>Abstract
MapReduce complements DBMSs since databases are not designed for extract-transform-load tasks, a MapReduce specialty.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/stonebraker2010mapreduce.html</link><guid isPermaLink="false">Literature Notes/stonebraker2010mapreduce.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:34:54 GMT</pubDate></item><item><title><![CDATA[C-store: A column-oriented DBMS]]></title><description><![CDATA[ 
 <br><br>Mike Stonebraker, Daniel J Abadi, Adam Batkin, Xuedong Chen, Mitch Cherniack, Miguel Ferreira, Edmond Lau, Amerson Lin, Sam Madden, Elizabeth O'Neil, others (2005)<br>Tags: <br>Abstract
This paper presents the design of a read-optimized relational DBMS that contrasts sharply with most current systems, which are write-optimized. Among the many differences in its design are: storage of data by column rather than by row, careful coding and packing of objects into storage including main memory during query processing, storing an overlapping collection of column-oriented projections, rather than the current fare of tables and indexes, a non-traditional implementation of transactions which includes high availability and snapshot isolation for read-only transactions, and the extensive use of bitmap indexes to complement B-tree structures. We present preliminary performance data on a subset of TPC-H and show that the system we are building, C-Store, is substantially faster than popular commercial products. Hence, the architecture looks very encouraging.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/stonebraker2018c.html</link><guid isPermaLink="false">Literature Notes/stonebraker2018c.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:21 GMT</pubDate></item><item><title><![CDATA[Scalability in the XFS file system.]]></title><description><![CDATA[ 
 <br><br>Adam Sweeney, Doug Doucette, Wei Hu, Curtis Anderson, Mike Nishimoto, Geoff Peck (1996)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Adam-Sweeney" class="tag" target="_blank" rel="noopener">#Adam-Sweeney</a> <a href="https://jayitha.github.io/Notes?query=tag:Doug-Doucette" class="tag" target="_blank" rel="noopener">#Doug-Doucette</a> <a href="https://jayitha.github.io/Notes?query=tag:Wei-Hu" class="tag" target="_blank" rel="noopener">#Wei-Hu</a> <a href="https://jayitha.github.io/Notes?query=tag:Curtis-Anderson" class="tag" target="_blank" rel="noopener">#Curtis-Anderson</a> <a href="https://jayitha.github.io/Notes?query=tag:Mike-Nishimoto" class="tag" target="_blank" rel="noopener">#Mike-Nishimoto</a> <a href="https://jayitha.github.io/Notes?query=tag:Geoff-Peck" class="tag" target="_blank" rel="noopener">#Geoff-Peck</a><br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/sweeney1996scalability.html</link><guid isPermaLink="false">Literature Notes/sweeney1996scalability.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:20:25 GMT</pubDate></item><item><title><![CDATA[Meerkat: Multicore-scalable replicated transactions following the zero-coordination principle]]></title><description><![CDATA[ 
 <br><br>Adriana Szekeres, Michael Whittaker, Jialin Li, Naveen Kr Sharma, Arvind Krishnamurthy, Dan RK Ports, Irene Zhang (2020)<br>Tags: <br>Abstract
Traditionally, the high cost of network communication between servers has hidden the impact of cross-core coordination in replicated systems. However, new technologies, like kernel-bypass networking and faster network links, have exposed hidden bottlenecks in distributed systems. This paper explores how to build multicore-scalable, replicated storage systems. We introduce a new guideline for their design, called the Zero-Coordination Principle. We use this principle to design a new multicore-scalable, in-memory, replicated, key-value store, called Meerkat. Unlike existing systems, Meerkat eliminates all cross-core and cross-replica coordination, both of which pose a scalability bottleneck. Our experiments found that Meerkat is able to scale up to 80 hyper-threads and execute 8.3 million transactions per second. Meerkat represents an improvement of 12X on state-of-the-art, fault-tolerant, in-memory, transactional storage systems built using leader-based replication and a shared transaction log.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/szekeres2020meerkat.html</link><guid isPermaLink="false">Literature Notes/szekeres2020meerkat.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:13:18 GMT</pubDate></item><item><title><![CDATA[Foreshadow: Extracting the keys to the intel {SGX} kingdom with transient {Out-of-Order} execution]]></title><description><![CDATA[ 
 <br><br>Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F Wenisch, Yuval Yarom, Raoul Strackx (2018)<br>Tags: <br>Abstract
Trusted execution environments, and particularly the Software Guard eXtensions (SGX) included in recent Intel x86 processors, gained significant traction in recent years. A long track of research papers, and increasingly also real-world industry applications, take advantage of the strong hardware-enforced confidentiality and integrity guarantees provided by Intel SGX. Ultimately, enclaved execution holds the compelling potential of securely offloading sensitive computations to untrusted remote platforms. We present Foreshadow, a practical software-only microarchitectural attack that decisively dismantles the security objectives of current SGX implementations. Crucially, unlike previous SGX attacks, we do not make any assumptions on the victim enclave's code and do not necessarily require kernel-level access. At its core, Foreshadow abuses a speculative execution bug in modern Intel processors, on top of which we develop a novel exploitation methodology to reliably leak plaintext enclave secrets from the CPU cache. We demonstrate our attacks by extracting full cryptographic keys from Intel's vetted architectural enclaves, and validate their correctness by launching rogue production enclaves and forging arbitrary local and remote attestation responses. The extracted remote attestation keys affect millions of devices.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/van2018foreshadow.html</link><guid isPermaLink="false">Literature Notes/van2018foreshadow.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:37:15 GMT</pubDate></item><item><title><![CDATA[Leapfrog triejoin: A worst-case optimal join algorithm]]></title><description><![CDATA[ 
 <br><br>Todd L Veldhuizen (2012)<br>Tags: <br>Abstract
Recent years have seen exciting developments in join algorithms. In 2008, Atserias, Grohe and Marx (henceforth AGM) proved a tight bound on the maximum result size of a full conjunctive query, given constraints on the input relation sizes. In 2012, Ngo, Porat, R{é} and Rudra (henceforth NPRR) devised a join algorithm with worst-case running time proportional to the AGM bound. Our commercial Datalog system LogicBlox employs a novel join algorithm, \emph{leapfrog triejoin}, which compared conspicuously well to the NPRR algorithm in preliminary benchmarks. This spurred us to analyze the complexity of leapfrog triejoin. In this paper we establish that leapfrog triejoin is also worst-case optimal, up to a log factor, in the sense of NPRR. We improve on the results of NPRR by proving that leapfrog triejoin achieves worst-case optimality for finer-grained classes of database instances, such as those defined by constraints on projection cardinalities. We show that NPRR is \emph{not} worst-case optimal for such classes, giving a counterexample where leapfrog triejoin runs in O(nlogn) time, compared to Θ(n1.375) time for NPRR. On a practical note, leapfrog triejoin can be implemented using conventional data structures such as B-trees, and extends naturally to ∃1 queries. We believe our algorithm offers a useful addition to the existing toolbox of join algorithms, being easy to absorb, simple to implement, and having a concise optimality proof.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/veldhuizen2012leapfrog.html</link><guid isPermaLink="false">Literature Notes/veldhuizen2012leapfrog.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:44:45 GMT</pubDate></item><item><title><![CDATA[Amazon aurora: Design considerations for high throughput cloud-native relational databases]]></title><description><![CDATA[ 
 <br><br>Alexandre Verbitski, Anurag Gupta, Debanjan Saha, Murali Brahmadesam, Kamal Gupta, Raman Mittal, Sailesh Krishnamurthy, Sandor Maurice, Tengiz Kharatishvili, Xiaofeng Bao (2017)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:Alexandre-Verbitski" class="tag" target="_blank" rel="noopener">#Alexandre-Verbitski</a> <a href="https://jayitha.github.io/Notes?query=tag:Anurag-Gupta" class="tag" target="_blank" rel="noopener">#Anurag-Gupta</a> <a href="https://jayitha.github.io/Notes?query=tag:Debanjan-Saha" class="tag" target="_blank" rel="noopener">#Debanjan-Saha</a> <a href="https://jayitha.github.io/Notes?query=tag:Murali-Brahmadesam" class="tag" target="_blank" rel="noopener">#Murali-Brahmadesam</a> <a href="https://jayitha.github.io/Notes?query=tag:Kamal-Gupta" class="tag" target="_blank" rel="noopener">#Kamal-Gupta</a> <a href="https://jayitha.github.io/Notes?query=tag:Raman-Mittal" class="tag" target="_blank" rel="noopener">#Raman-Mittal</a> <a href="https://jayitha.github.io/Notes?query=tag:Sailesh-Krishnamurthy" class="tag" target="_blank" rel="noopener">#Sailesh-Krishnamurthy</a> <a href="https://jayitha.github.io/Notes?query=tag:Sandor-Maurice" class="tag" target="_blank" rel="noopener">#Sandor-Maurice</a> <a href="https://jayitha.github.io/Notes?query=tag:Tengiz-Kharatishvili" class="tag" target="_blank" rel="noopener">#Tengiz-Kharatishvili</a> <a href="https://jayitha.github.io/Notes?query=tag:Xiaofeng-Bao" class="tag" target="_blank" rel="noopener">#Xiaofeng-Bao</a> <a href="https://jayitha.github.io/Notes?query=tag:reading" class="tag" target="_blank" rel="noopener">#reading</a><br>Abstract
Amazon Aurora is a relational database service for OLTP workloads offered as part of Amazon Web Services (AWS). In this paper, we describe the architecture of Aurora and the design considerations leading to that architecture. We believe the central constraint in high throughput data processing has moved from compute and storage to the network. Aurora brings a novel architecture to the relational database to address this constraint, most notably by pushing redo processing to a multi-tenant scale-out storage service, purpose-built for Aurora. We describe how doing so not only reduces network traffic, but also allows for fast crash recovery, failovers to replicas without loss of data, and fault-tolerant, self-healing storage. We then describe how Aurora achieves consensus on durable state across numerous storage nodes using an efficient asynchronous scheme, avoiding expensive and chatty recovery protocols. Finally, having operated Aurora as a production service for over 18 months, we share the lessons we have learnt from our customers on what modern cloud applications expect from databases.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/verbitski2017amazon.html</link><guid isPermaLink="false">Literature Notes/verbitski2017amazon.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 13 Feb 2024 17:04:31 GMT</pubDate></item><item><title><![CDATA[Amazon aurora: On avoiding distributed consensus for i/Os, commits, and membership changes]]></title><description><![CDATA[ 
 <br><br>Alexandre Verbitski, Anurag Gupta, Debanjan Saha, James Corey, Kamal Gupta, Murali Brahmadesam, Raman Mittal, Sailesh Krishnamurthy, Sandor Maurice, Tengiz Kharatishvilli, others (2018)<br>Tags: <br>Abstract
Amazon Aurora is a high-throughput cloud-native relational database offered as part of Amazon Web Services (AWS). One of the more novel differences between Aurora and other relational databases is how it pushes redo processing to a multi-tenant scale-out storage service, purpose-built for Aurora. Doing so reduces networking traffic, avoids checkpoints and crash recovery, enables failovers to replicas without loss of data, and enables fault-tolerant storage that heals without database involvement. Traditional implementations that leverage distributed storage would use distributed consensus algorithms for commits, reads, replication, and membership changes and amplify cost of underlying storage. In this paper, we describe how Aurora avoids distributed consensus under most circumstances by establishing invariants and leveraging local transient state. Doing so improves performance, reduces variability, and lowers costs.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/verbitski2018amazon.html</link><guid isPermaLink="false">Literature Notes/verbitski2018amazon.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 12:14:24 GMT</pubDate></item><item><title><![CDATA[Lottery scheduling: Flexible proportional-share resource management]]></title><description><![CDATA[ 
 <br><br>Carl A Waldspurger, William E Weihl (1994)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/waldspurger1994lottery.html</link><guid isPermaLink="false">Literature Notes/waldspurger1994lottery.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:49:38 GMT</pubDate></item><item><title><![CDATA[Conjunctive queries with comparisons]]></title><description><![CDATA[ 
 <br><br>Qichen Wang, Ke Yi (2022)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Qichen-Wang" class="tag" target="_blank" rel="noopener">#Qichen-Wang</a> <a href="https://jayitha.github.io/Notes?query=tag:Ke-Yi" class="tag" target="_blank" rel="noopener">#Ke-Yi</a><br>Abstract
Conjunctive queries with predicates in the form of comparisons that span multiple relations have regained interest recently, due to their relevance in OLAP queries, spatiotemporal databases, and machine learning over relational data. The standard technique, predicate pushdown, has limited efficacy on such comparisons. A technique by Willard can be used to process short comparisons that are adjacent in the join tree in time linear in the input size plus output size. In this paper, we describe a new algorithm for evaluating conjunctive queries with both short and long comparisons, and identify an acyclic condition under which linear time can be achieved. We have also implemented the new algorithm on top of Spark, and our experimental results demonstrate order-of-magnitude speedups over SparkSQL on a variety of graph pattern and analytical queries.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/wang2022conjunctive.html</link><guid isPermaLink="false">Literature Notes/wang2022conjunctive.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:18:31 GMT</pubDate></item><item><title><![CDATA[Logoot-undo: Distributed collaborative editing system on p2p networks]]></title><description><![CDATA[ 
 <br><br>Stephane Weiss, Pascal Urso, Pascal Molli (2010)<br>Tags: <br>Abstract
Peer-to-peer systems provide scalable content distribution for cheap and resist to censorship attempts. However, P2P networks mainly distribute immutable content and provide poor support for highly dynamic content such as produced by collaborative systems. A new class of algorithms called CRDT (Commutative Replicated Data Type), which ensures consistency of highly dynamic content on P2P networks, is emerging. However, if existing CRDT algorithms support the "edit anywhere, anytime” feature, they do not support the "undo anywhere, anytime” feature. In this paper, we present the Logoot-Undo CRDT algorithm, which integrates the "undo anywhere, anytime” feature. We compare the performance of the proposed algorithm with related algorithms and measure the impact of the undo feature on the global performance of the algorithm. We prove that the cost of the undo feature remains low on a corpus of data extracted from Wikipedia.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/weiss2010logoot.html</link><guid isPermaLink="false">Literature Notes/weiss2010logoot.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:36:32 GMT</pubDate></item><item><title><![CDATA[SEDA: An architecture for well-conditioned, scalable internet services]]></title><description><![CDATA[ 
 <br><br>Matt Welsh, David Culler, Eric Brewer (2001)<br>Tags: <br>Abstract
We propose a new design for highly concurrent Internet services, which we call the staged event-driven architecture (SEDA). SEDA is intended to support massive concurrency demands and simplify the construction of well-conditioned services. In SEDA, applications consist of a network of event-driven stages connected by explicit queues. This architecture allows services to be well-conditioned to load, preventing resources from being overcommitted when demand exceeds service capacity. SEDA makes use of a set of dynamic resource controllers to keep stages within their operating regime despite large fluctuations in load. We describe several control mechanisms for automatic tuning and load conditioning, including thread pool sizing, event batching, and adaptive load shedding. We present the SEDA design and an implementation of an Internet services platform based on this architecture. We evaluate the use of SEDA through two applications: a high-performance HTTP server and a packet router for the Gnutella peer-to-peer file sharing network. These results show that SEDA applications exhibit higher performance than traditional service designs, and are robust to huge variations in load.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/welsh2001seda.html</link><guid isPermaLink="false">Literature Notes/welsh2001seda.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:49:42 GMT</pubDate></item><item><title><![CDATA[The HP AutoRAID hierarchical storage system]]></title><description><![CDATA[ 
 <br><br>John Wilkes, Richard Golding, Carl Staelin, Tim Sullivan (1996)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:John-Wilkes" class="tag" target="_blank" rel="noopener">#John-Wilkes</a> <a href="https://jayitha.github.io/Notes?query=tag:Richard-Golding" class="tag" target="_blank" rel="noopener">#Richard-Golding</a> <a href="https://jayitha.github.io/Notes?query=tag:Carl-Staelin" class="tag" target="_blank" rel="noopener">#Carl-Staelin</a> <a href="https://jayitha.github.io/Notes?query=tag:Tim-Sullivan" class="tag" target="_blank" rel="noopener">#Tim-Sullivan</a><br>Abstract
Configuring redundant disk arrays is a black art. To configure an array properly, a system administrator must understand the details of both the array and the workload it will support. Incorrect understanding of either, or changes in the workload over time, can lead to poor performance. We present a solution to this problem: a two-level storage hierarchy implemented inside a single disk-array controller. In the upper level of this hierarchy, two copies of active data are stored to provide full redundancy and excellent performance. In the lower level, RAID 5 parity protection is used to provide excellent storage cost for inactive data, at somewhat lower performance. The technology we describe in this article, know as HP AutoRAID, automatically and transparently manages migration of data blocks between these two levels as access patterns change. The result is a fully redundant storage system that is extremely easy to use, is suitable for a wide variety of workloads, is largely insensitive to dynamic workload changes, and performs much better than disk arrays with comparable numbers of spindles and much larger amounts of front-end RAM cache. Because the implementation of the HP AutoRAID technology is almost entirely in software, the additional hardware cost for these benefits is very small. We describe the HP AutoRAID technology in detail, provide performance data for an embodiment of it in a storage array, and summarize the results of simulation studies used to choose algorithms implemented in the array.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/wilkes1996hp.html</link><guid isPermaLink="false">Literature Notes/wilkes1996hp.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:16:48 GMT</pubDate></item><item><title><![CDATA[Transient customization of mobile computing infrastructure]]></title><description><![CDATA[ 
 <br><br>Adam Wolbach, Jan Harkes, Srinivas Chellappa, Mahadev Satyanarayanan (2008)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Adam-Wolbach" class="tag" target="_blank" rel="noopener">#Adam-Wolbach</a> <a href="https://jayitha.github.io/Notes?query=tag:Jan-Harkes" class="tag" target="_blank" rel="noopener">#Jan-Harkes</a> <a href="https://jayitha.github.io/Notes?query=tag:Srinivas-Chellappa" class="tag" target="_blank" rel="noopener">#Srinivas-Chellappa</a> <a href="https://jayitha.github.io/Notes?query=tag:Mahadev-Satyanarayanan" class="tag" target="_blank" rel="noopener">#Mahadev-Satyanarayanan</a><br>Abstract
Kimberley is a system that simplifies transient use of fixed hardware infrastructure by a mobile device. It uses virtual machine (VM) technology to resolve the tension between standardizing infrastructure for ease of deployment and maintenance, and customizing that infrastructure to meet the specific needs of a user. Kimberley decomposes the state of a customized VM into a widely-available base VM and a much smaller private VM overlay. The base is downloaded by the infrastructure in advance. Only the small overlay needs to be delivered from the mobile device, or under its control from a public web site. This strategy keeps startup delay low. It may also conserve energy on the mobile device by reducing the volume of wireless transmission. We have built a prototype of Kimberley, and our experiments confirm the feasibility of this approach.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/wolbach2008transient.html</link><guid isPermaLink="false">Literature Notes/wolbach2008transient.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:01:41 GMT</pubDate></item><item><title><![CDATA[Towards a learning optimizer for shared clouds]]></title><description><![CDATA[ 
 <br><br>Chenggang Wu, Alekh Jindal, Saeed Amizadeh, Hiren Patel, Wangchao Le, Shi Qiao, Sriram Rao (2018)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Chenggang-Wu" class="tag" target="_blank" rel="noopener">#Chenggang-Wu</a> <a href="https://jayitha.github.io/Notes?query=tag:Alekh-Jindal" class="tag" target="_blank" rel="noopener">#Alekh-Jindal</a> <a href="https://jayitha.github.io/Notes?query=tag:Saeed-Amizadeh" class="tag" target="_blank" rel="noopener">#Saeed-Amizadeh</a> <a href="https://jayitha.github.io/Notes?query=tag:Hiren-Patel" class="tag" target="_blank" rel="noopener">#Hiren-Patel</a> <a href="https://jayitha.github.io/Notes?query=tag:Wangchao-Le" class="tag" target="_blank" rel="noopener">#Wangchao-Le</a> <a href="https://jayitha.github.io/Notes?query=tag:Shi-Qiao" class="tag" target="_blank" rel="noopener">#Shi-Qiao</a> <a href="https://jayitha.github.io/Notes?query=tag:Sriram-Rao" class="tag" target="_blank" rel="noopener">#Sriram-Rao</a><br>Abstract
Query optimizers are notorious for inaccurate cost estimates, leading to poor performance. The root of the problem lies in inaccurate cardinality estimates, i.e., the size of intermediate (and final) results in a query plan. These estimates also determine the resources consumed in modern shared cloud infrastructures. In this paper, we present CARDLEARNER, a machine learning based approach to learn cardinality models from previous job executions and use them to predict the cardinalities in future jobs. The key intuition in our approach is that shared cloud workloads are often recurring and overlapping in nature, and so we could learn cardinality models for overlapping subgraph templates. We discuss various learning approaches and show how learning a large number of smaller models results in high accuracy and explainability. We further present an exploration technique to avoid learning bias by considering alternate join orders and learning cardinality models over them. We describe the feedback loop to apply the learned models back to future job executions. Finally, we show a detailed evaluation of our models (up to 5 orders of magnitude less error), query plans (60% applicability), performance (up to 100% faster, 3x fewer resources), and exploration (optimal in few 10s of executions).
]]></description><link>https://jayitha.github.io/Notes/literature-notes/wu2018towards.html</link><guid isPermaLink="false">Literature Notes/wu2018towards.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:40:50 GMT</pubDate></item><item><title><![CDATA[Deep unsupervised cardinality estimation]]></title><description><![CDATA[ 
 <br><br>Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi Chen, Pieter Abbeel, Joseph M Hellerstein, Sanjay Krishnan, Ion Stoica (2019)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Zongheng-Yang" class="tag" target="_blank" rel="noopener">#Zongheng-Yang</a> <a href="https://jayitha.github.io/Notes?query=tag:Eric-Liang" class="tag" target="_blank" rel="noopener">#Eric-Liang</a> <a href="https://jayitha.github.io/Notes?query=tag:Amog-Kamsetty" class="tag" target="_blank" rel="noopener">#Amog-Kamsetty</a> <a href="https://jayitha.github.io/Notes?query=tag:Chenggang-Wu" class="tag" target="_blank" rel="noopener">#Chenggang-Wu</a> <a href="https://jayitha.github.io/Notes?query=tag:Yan-Duan" class="tag" target="_blank" rel="noopener">#Yan-Duan</a> <a href="https://jayitha.github.io/Notes?query=tag:Xi-Chen" class="tag" target="_blank" rel="noopener">#Xi-Chen</a> <a href="https://jayitha.github.io/Notes?query=tag:Pieter-Abbeel" class="tag" target="_blank" rel="noopener">#Pieter-Abbeel</a> <a href="https://jayitha.github.io/Notes?query=tag:Joseph" class="tag" target="_blank" rel="noopener">#Joseph</a> <a href="https://jayitha.github.io/Notes?query=tag:M-Hellerstein" class="tag" target="_blank" rel="noopener">#M-Hellerstein</a> <a href="https://jayitha.github.io/Notes?query=tag:Sanjay-Krishnan" class="tag" target="_blank" rel="noopener">#Sanjay-Krishnan</a> <a href="https://jayitha.github.io/Notes?query=tag:Ion-Stoica" class="tag" target="_blank" rel="noopener">#Ion-Stoica</a><br>Abstract
Cardinality estimation has long been grounded in statistical tools for density estimation. To capture the rich multivariate distributions of relational tables, we propose the use of a new type of high-capacity statistical model: deep autoregressive models. However, direct application of these models leads to a limited estimator that is prohibitively expensive to evaluate for range or wildcard predicates. To produce a truly usable estimator, we develop a Monte Carlo integration scheme on top of autoregressive models that can efficiently handle range queries with dozens of dimensions or more. Like classical synopses, our estimator summarizes the data without supervision. Unlike previous solutions, we approximate the joint data distribution without any independence assumptions. Evaluated on real-world datasets and compared against real systems and dominant families of techniques, our estimator achieves single-digit multiplicative error at tail, an up to 90[Math Processing Error] accuracy improvement over the second best method, and is space- and runtime-efficient.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/yang2019deep.html</link><guid isPermaLink="false">Literature Notes/yang2019deep.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 24 Dec 2023 11:40:31 GMT</pubDate></item><item><title><![CDATA[Balsa: Learning a query optimizer without expert demonstrations]]></title><description><![CDATA[ 
 <br><br>Zongheng Yang, Wei-Lin Chiang, Sifei Luan, Gautam Mittal, Michael Luo, Ion Stoica (2022)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Zongheng-Yang" class="tag" target="_blank" rel="noopener">#Zongheng-Yang</a> <a href="https://jayitha.github.io/Notes?query=tag:Wei-Lin-Chiang" class="tag" target="_blank" rel="noopener">#Wei-Lin-Chiang</a> <a href="https://jayitha.github.io/Notes?query=tag:Sifei-Luan" class="tag" target="_blank" rel="noopener">#Sifei-Luan</a> <a href="https://jayitha.github.io/Notes?query=tag:Gautam-Mittal" class="tag" target="_blank" rel="noopener">#Gautam-Mittal</a> <a href="https://jayitha.github.io/Notes?query=tag:Michael-Luo" class="tag" target="_blank" rel="noopener">#Michael-Luo</a> <a href="https://jayitha.github.io/Notes?query=tag:Ion-Stoica" class="tag" target="_blank" rel="noopener">#Ion-Stoica</a><br>Abstract
Query optimizers are a performance-critical component in every database system. Due to their complexity, optimizers take experts months to write and years to refine. In this work, we demonstrate for the first time that learning to optimize queries without learning from an expert optimizer is both possible and efficient. We present Balsa, a query optimizer built by deep reinforcement learning. Balsa first learns basic knowledge from a simple, environment-agnostic simulator, followed by safe learning in real execution. On the Join Order Benchmark, Balsa matches the performance of two expert query optimizers, both open-source and commercial, with two hours of learning, and outperforms them by up to 2.8× in workload runtime after a few more hours. Balsa thus opens the possibility of automatically learning to optimize in future compute environments where expert-designed optimizers do not exist.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/yang2022balsa.html</link><guid isPermaLink="false">Literature Notes/yang2022balsa.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:18:13 GMT</pubDate></item><item><title><![CDATA[Spark: Cluster computing with working sets]]></title><description><![CDATA[ 
 <br><br>Matei Zaharia, Mosharaf Chowdhury, Michael J Franklin, Scott Shenker, Ion Stoica (2010)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/zaharia2010spark.html</link><guid isPermaLink="false">Literature Notes/zaharia2010spark.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:03 GMT</pubDate></item><item><title><![CDATA[Resilient distributed datasets: A {fault-Tolerant} abstraction for {in-Memory} cluster computing]]></title><description><![CDATA[ 
 <br><br>Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauly, Michael J Franklin, Scott Shenker, Ion Stoica (2012)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/zaharia2012resilient.html</link><guid isPermaLink="false">Literature Notes/zaharia2012resilient.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:35:07 GMT</pubDate></item><item><title><![CDATA[Making information flow explicit in HiStar]]></title><description><![CDATA[ 
 <br><br>Nickolai Zeldovich, Silas Boyd-Wickizer, Eddie Kohler, David Mazieres (2011)<br>Tags: <a href="https://jayitha.github.io/Notes?query=tag:to-read" class="tag" target="_blank" rel="noopener">#to-read</a> <a href="https://jayitha.github.io/Notes?query=tag:Nickolai-Zeldovich" class="tag" target="_blank" rel="noopener">#Nickolai-Zeldovich</a> <a href="https://jayitha.github.io/Notes?query=tag:Silas-Boyd-Wickizer" class="tag" target="_blank" rel="noopener">#Silas-Boyd-Wickizer</a> <a href="https://jayitha.github.io/Notes?query=tag:Eddie-Kohler" class="tag" target="_blank" rel="noopener">#Eddie-Kohler</a> <a href="https://jayitha.github.io/Notes?query=tag:David-Mazieres" class="tag" target="_blank" rel="noopener">#David-Mazieres</a><br>Abstract
HiStar is a new operating system designed to minimize the amount of code that must be trusted. HiStar provides strict information flow control, which allows users to specify precise data security policies without unduly limiting the structure of applications. HiStar's security features make it possible to implement a Unix-like environment with acceptable performance almost entirely in an untrusted user-level library. The system has no notion of superuser and no fully trusted code other than the kernel. HiStar's features permit several novel applications, including privacy-preserving, untrusted virus scanners and a dynamic Web server with only a few thousand lines of trusted code.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/zeldovich2011making.html</link><guid isPermaLink="false">Literature Notes/zeldovich2011making.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:36:43 GMT</pubDate></item><item><title><![CDATA[The cloud is not enough: Saving {IoT} from the cloud]]></title><description><![CDATA[ 
 <br><br>Ben Zhang, Nitesh Mor, John Kolb, Douglas S Chan, Ken Lutz, Eric Allman, John Wawrzynek, Edward Lee, John Kubiatowicz (2015)<br>Tags: <br>Abstract
The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, the current approach of directly connecting smart devices to the cloud has a number of disadvantages and is unlikely to keep up with either the growing speed of the IoT or the diverse needs of IoT applications. In this paper we explore these disadvantages and argue that fundamental properties of the IoT prevent the current approach from scaling. What is missing is a wellarchitected system that extends the functionality of the cloud and provides seamless interplay among the heterogeneous components in the IoT space. We argue that raising the level of abstraction to a data-centric design—focused around the distribution, preservation and protection of information—provides a much better match to the IoT.We present early work on such a distributed platform, called the Global Data Plane (GDP), and discuss how it addresses the problems with the cloud-centric architecture.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/zhang2015cloud.html</link><guid isPermaLink="false">Literature Notes/zhang2015cloud.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:35 GMT</pubDate></item><item><title><![CDATA[Tapestry: An infrastructure for fault-tolerant wide-area location and routing]]></title><description><![CDATA[ 
 <br><br>Ben Yanbin Zhao, John Kubiatowicz, Anthony D Joseph, others (2001)<br>Tags: <br>Abstract]]></description><link>https://jayitha.github.io/Notes/literature-notes/zhao2001tapestry.html</link><guid isPermaLink="false">Literature Notes/zhao2001tapestry.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:02:48 GMT</pubDate></item><item><title><![CDATA[Tapestry: A resilient global-scale overlay for service deployment]]></title><description><![CDATA[ 
 <br><br>Ben Y Zhao, Ling Huang, Jeremy Stribling, Sean C Rhea, Anthony D Joseph, John D Kubiatowicz (2004)<br>Tags: <br>Abstract
We present Tapestry, a peer-to-peer overlay routing infrastructure offering efficient, scalable, location-independent routing of messages directly to nearby copies of an object or service using only localized resources. Tapestry supports a generic decentralized object location and routing applications programming interface using a self-repairing, soft-state-based routing layer. The paper presents the Tapestry architecture, algorithms, and implementation. It explores the behavior of a Tapestry deployment on PlanetLab, a global testbed of approximately 100 machines. Experimental results show that Tapestry exhibits stable behavior and performance as an overlay, despite the instability of the underlying network layers. Several widely distributed applications have been implemented on Tapestry, illustrating its utility as a deployment infrastructure.
]]></description><link>https://jayitha.github.io/Notes/literature-notes/zhao2004tapestry.html</link><guid isPermaLink="false">Literature Notes/zhao2004tapestry.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 22 Dec 2023 18:03:14 GMT</pubDate></item><item><title><![CDATA[Ryan Marcus' CIS 6500 – Advanced Topics in Database Systems]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="https://rmarcus.info/syllabi/Penn_CIS6500_F23.pdf" rel="noopener" class="external-link" href="https://rmarcus.info/syllabi/Penn_CIS6500_F23.pdf" target="_blank">Link to Syllabus</a><br><br>Key question: how do column stores take advantage of compression?<br>
<a data-href="abadi2006integrating" href="https://jayitha.github.io/Notes/literature-notes/abadi2006integrating.html" class="internal-link" target="_self" rel="noopener">abadi2006integrating</a><br>Key question: how much, if any, of the advantages of column stores can we get from a row store?<br>
<a data-href="abadi2008column" href="https://jayitha.github.io/Notes/literature-notes/abadi2008column.html" class="internal-link" target="_self" rel="noopener">abadi2008column</a><br><br>Key question: how does one decompose a query execution plan into compile-able steps? What benefit does this bring?<br>
<a data-href="neumann2011efficiently" href="https://jayitha.github.io/Notes/literature-notes/neumann2011efficiently.html" class="internal-link" target="_self" rel="noopener">neumann2011efficiently</a><br>Key question: compare and contrast compiled and vectorized execution engines. What are the pros and cons of each?<br>
<a data-href="kersten2018everything" href="https://jayitha.github.io/Notes/literature-notes/kersten2018everything.html" class="internal-link" target="_self" rel="noopener">kersten2018everything</a><br><br>Key question: how dose the design of index structures change when we consider caching?<br>
<a data-href="rao2000making" href="https://jayitha.github.io/Notes/literature-notes/rao2000making.html" class="internal-link" target="_self" rel="noopener">rao2000making</a><br>Key question: what is a column sketch, and how is it uniquely suited for column-oriented analytics databases?<br>
<a data-href="hentschel2018column" href="https://jayitha.github.io/Notes/literature-notes/hentschel2018column.html" class="internal-link" target="_self" rel="noopener">hentschel2018column</a><br>Key question: can statistical or learned models lead to improved index structures? If so, what is it about learned models that make performance better or worse?<br>
<a data-href="kraska2018case" href="https://jayitha.github.io/Notes/literature-notes/kraska2018case.html" class="internal-link" target="_self" rel="noopener">kraska2018case</a> <a data-href="marcus2020benchmarking" href="https://jayitha.github.io/Notes/literature-notes/marcus2020benchmarking.html" class="internal-link" target="_self" rel="noopener">marcus2020benchmarking</a><br>Key question: how do you design a workload-aware index for queries with predicates on multiple columns? Why can’t you just use multiple single-column indexes?<br>
<a data-href="nathan2020learning" href="https://jayitha.github.io/Notes/literature-notes/nathan2020learning.html" class="internal-link" target="_self" rel="noopener">nathan2020learning</a><br><br>Key question: what are the main problems with naive sort-merge-join? How can the algorithm be improved?<br>
<a data-href="albutiu2012massively" href="https://jayitha.github.io/Notes/literature-notes/albutiu2012massively.html" class="internal-link" target="_self" rel="noopener">albutiu2012massively</a><br>Key question: what are the techniques and algorithms that make hash joins work well? Are there specific conditions or requirements for a hash join to have good performance?<br>
<a data-href="bandle2021partition" href="https://jayitha.github.io/Notes/literature-notes/bandle2021partition.html" class="internal-link" target="_self" rel="noopener">bandle2021partition</a><br>Key question: can statistical or learned techniques improve something as fundamental as a sorting algorithm?<br>
<a data-href="kristo2020case" href="https://jayitha.github.io/Notes/literature-notes/kristo2020case.html" class="internal-link" target="_self" rel="noopener">kristo2020case</a><br>Key question: is there any advantage to using a learned function as a hash function?<br>
<a data-href="sabek2022can" href="https://jayitha.github.io/Notes/literature-notes/sabek2022can.html" class="internal-link" target="_self" rel="noopener">sabek2022can</a><br>Key question: even if we have a really good hash join, if we order the joins incorrectly, the query will still be slow. Is there another way?<br>
<a data-href="freitag2020adopting" href="https://jayitha.github.io/Notes/literature-notes/freitag2020adopting.html" class="internal-link" target="_self" rel="noopener">freitag2020adopting</a><br><br>Key question: what is the “state of the art” in query optimization today? Where do current query optimizers struggle?<br>
<a data-href="leis2015good" href="https://jayitha.github.io/Notes/literature-notes/leis2015good.html" class="internal-link" target="_self" rel="noopener">leis2015good</a><br>Key question: how can learned models help improve cardinality estimation? What are the advantages and disadvantages?<br>
<a data-href="kipf2018learned" href="https://jayitha.github.io/Notes/literature-notes/kipf2018learned.html" class="internal-link" target="_self" rel="noopener">kipf2018learned</a><br>Key question: these query optimizers sure seem complicated! Can we get the computer to just learn a model for us?<br>
<a data-href="yang2022balsa" href="https://jayitha.github.io/Notes/literature-notes/yang2022balsa.html" class="internal-link" target="_self" rel="noopener">yang2022balsa</a> <a data-href="marcus2019neo" href="https://jayitha.github.io/Notes/literature-notes/marcus2019neo.html" class="internal-link" target="_self" rel="noopener">marcus2019neo</a><br>Key question: if techniques like Balsa have a high potential for failure, are there more practical, less error prone ways to improve a query optimizer with learning?<br>
<a data-href="marcus2021bao" href="https://jayitha.github.io/Notes/literature-notes/marcus2021bao.html" class="internal-link" target="_self" rel="noopener">marcus2021bao</a><br>Key question: if an optimizer is going to see the same query many times, what techniques can we use to get better performance than simply running a traditional query optimization algorithm each time?<br>
<a data-href="doshi2023kepler" href="https://jayitha.github.io/Notes/literature-notes/doshi2023kepler.html" class="internal-link" target="_self" rel="noopener">doshi2023kepler</a><br>Key question: most query optimizers pick a query plan and then ship that plan off to the executor. What if we mixed together query planning and query execution? What are the advantages and disadvantages?<br>
<a data-href="avnur2000eddies" href="https://jayitha.github.io/Notes/literature-notes/avnur2000eddies.html" class="internal-link" target="_self" rel="noopener">avnur2000eddies</a><br>Key question: query optimization is only a small part of the puzzle of making a “smart” database. What other challenges and potential for automation exists?<br>
<a data-href="pavlo2017self" href="https://jayitha.github.io/Notes/literature-notes/pavlo2017self.html" class="internal-link" target="_self" rel="noopener">pavlo2017self</a>]]></description><link>https://jayitha.github.io/Notes/streams/ryan-marcus'-cis-6500-–-advanced-topics-in-database-systems.html</link><guid isPermaLink="false">Streams/Ryan Marcus' CIS 6500 – Advanced Topics in Database Systems.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Thu, 21 Dec 2023 18:00:47 GMT</pubDate></item><item><title><![CDATA[UC Berkeley's CS264a - Advanced Topics in Computer Systems]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F23/index.html" rel="noopener" class="external-link" href="https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F23/index.html" target="_blank">Link to course website</a><br>
<br><a data-href="ritchie1978unix" href="https://jayitha.github.io/Notes/literature-notes/ritchie1978unix.html" class="internal-link" target="_self" rel="noopener">ritchie1978unix</a>
<br><a data-href="saltzer1984end" href="https://jayitha.github.io/Notes/literature-notes/saltzer1984end.html" class="internal-link" target="_self" rel="noopener">saltzer1984end</a>
<br><a data-href="chamberlin1981history" href="https://jayitha.github.io/Notes/literature-notes/chamberlin1981history.html" class="internal-link" target="_self" rel="noopener">chamberlin1981history</a>
<br><a data-href="hellerstein2007architecture" href="https://jayitha.github.io/Notes/literature-notes/hellerstein2007architecture.html" class="internal-link" target="_self" rel="noopener">hellerstein2007architecture</a>
<br><a data-href="stonebraker1976design" href="https://jayitha.github.io/Notes/literature-notes/stonebraker1976design.html" class="internal-link" target="_self" rel="noopener">stonebraker1976design</a>
<br><a data-href="mckusick1984fast" href="https://jayitha.github.io/Notes/literature-notes/mckusick1984fast.html" class="internal-link" target="_self" rel="noopener">mckusick1984fast</a>
<br><a data-href="prabhakaran2005analysis" href="https://jayitha.github.io/Notes/literature-notes/prabhakaran2005analysis.html" class="internal-link" target="_self" rel="noopener">prabhakaran2005analysis</a>
<br><a data-href="rosenblum1992design" href="https://jayitha.github.io/Notes/literature-notes/rosenblum1992design.html" class="internal-link" target="_self" rel="noopener">rosenblum1992design</a>
<br><a data-href="wilkes1996hp" href="https://jayitha.github.io/Notes/literature-notes/wilkes1996hp.html" class="internal-link" target="_self" rel="noopener">wilkes1996hp</a>
<br><a data-href="patterson1988case" href="https://jayitha.github.io/Notes/literature-notes/patterson1988case.html" class="internal-link" target="_self" rel="noopener">patterson1988case</a>
<br><a data-href="beaver2010finding" href="https://jayitha.github.io/Notes/literature-notes/beaver2010finding.html" class="internal-link" target="_self" rel="noopener">beaver2010finding</a>
<br><a data-href="sweeney1996scalability" href="https://jayitha.github.io/Notes/literature-notes/sweeney1996scalability.html" class="internal-link" target="_self" rel="noopener">sweeney1996scalability</a>
<br><a data-href="hellwig2009xfs" href="https://jayitha.github.io/Notes/literature-notes/hellwig2009xfs.html" class="internal-link" target="_self" rel="noopener">hellwig2009xfs</a>
<br><a data-href="lee2015f2fs" href="https://jayitha.github.io/Notes/literature-notes/lee2015f2fs.html" class="internal-link" target="_self" rel="noopener">lee2015f2fs</a>
<br><a data-href="santana2016fast" href="https://jayitha.github.io/Notes/literature-notes/santana2016fast.html" class="internal-link" target="_self" rel="noopener">santana2016fast</a>
<br><a data-href="park2008reconfigurable" href="https://jayitha.github.io/Notes/literature-notes/park2008reconfigurable.html" class="internal-link" target="_self" rel="noopener">park2008reconfigurable</a>
<br><a data-href="gervasi2019will" href="https://jayitha.github.io/Notes/literature-notes/gervasi2019will.html" class="internal-link" target="_self" rel="noopener">gervasi2019will</a>
<br>

<br><a data-href="gray1976granularity" href="https://jayitha.github.io/Notes/literature-notes/gray1976granularity.html" class="internal-link" target="_self" rel="noopener">gray1976granularity</a>


<br><a data-href="berenson1995critique" href="https://jayitha.github.io/Notes/literature-notes/berenson1995critique.html" class="internal-link" target="_self" rel="noopener">berenson1995critique</a>
<br><a data-href="adya2000generalized" href="https://jayitha.github.io/Notes/literature-notes/adya2000generalized.html" class="internal-link" target="_self" rel="noopener">adya2000generalized</a>
<br><a data-href="haerder1983principles" href="https://jayitha.github.io/Notes/literature-notes/haerder1983principles.html" class="internal-link" target="_self" rel="noopener">haerder1983principles</a>
<br><a data-href="gray1981transaction" href="https://jayitha.github.io/Notes/literature-notes/gray1981transaction.html" class="internal-link" target="_self" rel="noopener">gray1981transaction</a>
<br><a data-href="mohan1992aries" href="https://jayitha.github.io/Notes/literature-notes/mohan1992aries.html" class="internal-link" target="_self" rel="noopener">mohan1992aries</a>

<br><a data-href="mohan1999repeating" href="https://jayitha.github.io/Notes/literature-notes/mohan1999repeating.html" class="internal-link" target="_self" rel="noopener">mohan1999repeating</a> (Opt)
<br><a data-href="kuo1996model" href="https://jayitha.github.io/Notes/literature-notes/kuo1996model.html" class="internal-link" target="_self" rel="noopener">kuo1996model</a> (Opt)
<br><a data-href="graefe2012survey" href="https://jayitha.github.io/Notes/literature-notes/graefe2012survey.html" class="internal-link" target="_self" rel="noopener">graefe2012survey</a> (Opt)


<br><a data-href="sears2009segment" href="https://jayitha.github.io/Notes/literature-notes/sears2009segment.html" class="internal-link" target="_self" rel="noopener">sears2009segment</a>
<br><a data-href="satyanarayanan1994lightweight" href="https://jayitha.github.io/Notes/literature-notes/satyanarayanan1994lightweight.html" class="internal-link" target="_self" rel="noopener">satyanarayanan1994lightweight</a>
<br><a data-href="letia2009crdts" href="https://jayitha.github.io/Notes/literature-notes/letia2009crdts.html" class="internal-link" target="_self" rel="noopener">letia2009crdts</a>

<br><a data-href="shapiro2011conflict" href="https://jayitha.github.io/Notes/literature-notes/shapiro2011conflict.html" class="internal-link" target="_self" rel="noopener">shapiro2011conflict</a> (Opt)


<br><a data-href="bailis2014coordination" href="https://jayitha.github.io/Notes/literature-notes/bailis2014coordination.html" class="internal-link" target="_self" rel="noopener">bailis2014coordination</a>

<br><a data-href="bailis2016scalable" href="https://jayitha.github.io/Notes/literature-notes/bailis2016scalable.html" class="internal-link" target="_self" rel="noopener">bailis2016scalable</a> (Opt)


<br><a data-href="lamport2019time" href="https://jayitha.github.io/Notes/literature-notes/lamport2019time.html" class="internal-link" target="_self" rel="noopener">lamport2019time</a>
<br><a data-href="adya1995efficient" href="https://jayitha.github.io/Notes/literature-notes/adya1995efficient.html" class="internal-link" target="_self" rel="noopener">adya1995efficient</a>
<br><a data-href="waldspurger1994lottery" href="https://jayitha.github.io/Notes/literature-notes/waldspurger1994lottery.html" class="internal-link" target="_self" rel="noopener">waldspurger1994lottery</a>

<br><a data-href="welsh2001seda" href="https://jayitha.github.io/Notes/literature-notes/welsh2001seda.html" class="internal-link" target="_self" rel="noopener">welsh2001seda</a> (Opt)


<br><a data-href="abeni1998integrating" href="https://jayitha.github.io/Notes/literature-notes/abeni1998integrating.html" class="internal-link" target="_self" rel="noopener">abeni1998integrating</a>

<br><a data-href="goossens2003priority" href="https://jayitha.github.io/Notes/literature-notes/goossens2003priority.html" class="internal-link" target="_self" rel="noopener">goossens2003priority</a> (Opt)
<br><a data-href="baruah2002implementing" href="https://jayitha.github.io/Notes/literature-notes/baruah2002implementing.html" class="internal-link" target="_self" rel="noopener">baruah2002implementing</a> (Opt)


<br><a data-href="pan2010composing" href="https://jayitha.github.io/Notes/literature-notes/pan2010composing.html" class="internal-link" target="_self" rel="noopener">pan2010composing</a>

<br><a data-href="blumofe1995cilk" href="https://jayitha.github.io/Notes/literature-notes/blumofe1995cilk.html" class="internal-link" target="_self" rel="noopener">blumofe1995cilk</a>
<br><a data-href="pan2009lithe" href="https://jayitha.github.io/Notes/literature-notes/pan2009lithe.html" class="internal-link" target="_self" rel="noopener">pan2009lithe</a>


<br><a data-href="ghodsi2011dominant" href="https://jayitha.github.io/Notes/literature-notes/ghodsi2011dominant.html" class="internal-link" target="_self" rel="noopener">ghodsi2011dominant</a>

<br><a data-href="demers1989analysis" href="https://jayitha.github.io/Notes/literature-notes/demers1989analysis.html" class="internal-link" target="_self" rel="noopener">demers1989analysis</a>


<br><a data-href="bugnion1997disco" href="https://jayitha.github.io/Notes/literature-notes/bugnion1997disco.html" class="internal-link" target="_self" rel="noopener">bugnion1997disco</a>
<br><a data-href="barham2003xen" href="https://jayitha.github.io/Notes/literature-notes/barham2003xen.html" class="internal-link" target="_self" rel="noopener">barham2003xen</a>

<br><a data-href="hand2005virtual" href="https://jayitha.github.io/Notes/literature-notes/hand2005virtual.html" class="internal-link" target="_self" rel="noopener">hand2005virtual</a>


<br><a data-href="clark2005live" href="https://jayitha.github.io/Notes/literature-notes/clark2005live.html" class="internal-link" target="_self" rel="noopener">clark2005live</a>
<br><a data-href="satyanarayanan2009case" href="https://jayitha.github.io/Notes/literature-notes/satyanarayanan2009case.html" class="internal-link" target="_self" rel="noopener">satyanarayanan2009case</a>
<br><a data-href="wolbach2008transient" href="https://jayitha.github.io/Notes/literature-notes/wolbach2008transient.html" class="internal-link" target="_self" rel="noopener">wolbach2008transient</a>

<br><a data-href="dunlap2002revirt" href="https://jayitha.github.io/Notes/literature-notes/dunlap2002revirt.html" class="internal-link" target="_self" rel="noopener">dunlap2002revirt</a>
<br><a data-href="lagar2009snowflock" href="https://jayitha.github.io/Notes/literature-notes/lagar2009snowflock.html" class="internal-link" target="_self" rel="noopener">lagar2009snowflock</a>


<br><a data-href="ha2017you" href="https://jayitha.github.io/Notes/literature-notes/ha2017you.html" class="internal-link" target="_self" rel="noopener">ha2017you</a>

<br><a data-href="abe2016urgent" href="https://jayitha.github.io/Notes/literature-notes/abe2016urgent.html" class="internal-link" target="_self" rel="noopener">abe2016urgent</a>
<br><a data-href="satyanarayanan2017emergence" href="https://jayitha.github.io/Notes/literature-notes/satyanarayanan2017emergence.html" class="internal-link" target="_self" rel="noopener">satyanarayanan2017emergence</a>


<br><a data-href="mor2019global" href="https://jayitha.github.io/Notes/literature-notes/mor2019global.html" class="internal-link" target="_self" rel="noopener">mor2019global</a>

<br><a data-href="mor2016toward" href="https://jayitha.github.io/Notes/literature-notes/mor2016toward.html" class="internal-link" target="_self" rel="noopener">mor2016toward</a>
<br><a data-href="zhang2015cloud" href="https://jayitha.github.io/Notes/literature-notes/zhang2015cloud.html" class="internal-link" target="_self" rel="noopener">zhang2015cloud</a>


<br><a data-href="stoica2003chord" href="https://jayitha.github.io/Notes/literature-notes/stoica2003chord.html" class="internal-link" target="_self" rel="noopener">stoica2003chord</a>
<br><a data-href="zhao2004tapestry" href="https://jayitha.github.io/Notes/literature-notes/zhao2004tapestry.html" class="internal-link" target="_self" rel="noopener">zhao2004tapestry</a>

<br><a data-href="rhea2004handling" href="https://jayitha.github.io/Notes/literature-notes/rhea2004handling.html" class="internal-link" target="_self" rel="noopener">rhea2004handling</a>
<br><a data-href="zhao2001tapestry" href="https://jayitha.github.io/Notes/literature-notes/zhao2001tapestry.html" class="internal-link" target="_self" rel="noopener">zhao2001tapestry</a>
<br><a data-href="rowstron2001pastry" href="https://jayitha.github.io/Notes/literature-notes/rowstron2001pastry.html" class="internal-link" target="_self" rel="noopener">rowstron2001pastry</a>


<br><a data-href="decandia2007dynamo" href="https://jayitha.github.io/Notes/literature-notes/decandia2007dynamo.html" class="internal-link" target="_self" rel="noopener">decandia2007dynamo</a>

<br><a data-href="rowstron2001storage" href="https://jayitha.github.io/Notes/literature-notes/rowstron2001storage.html" class="internal-link" target="_self" rel="noopener">rowstron2001storage</a>


<br><a data-href="rhea2003pond" href="https://jayitha.github.io/Notes/literature-notes/rhea2003pond.html" class="internal-link" target="_self" rel="noopener">rhea2003pond</a>

<br><a data-href="kubiatowicz2000oceanstore" href="https://jayitha.github.io/Notes/literature-notes/kubiatowicz2000oceanstore.html" class="internal-link" target="_self" rel="noopener">kubiatowicz2000oceanstore</a>


<br><a data-href="chandra2007paxos" href="https://jayitha.github.io/Notes/literature-notes/chandra2007paxos.html" class="internal-link" target="_self" rel="noopener">chandra2007paxos</a>

<br><a data-href="lamport1998part" href="https://jayitha.github.io/Notes/literature-notes/lamport1998part.html" class="internal-link" target="_self" rel="noopener">lamport1998part</a>
<br><a data-href="lamport2001paxos" href="https://jayitha.github.io/Notes/literature-notes/lamport2001paxos.html" class="internal-link" target="_self" rel="noopener">lamport2001paxos</a>


<br><a data-href="ongaro2014search" href="https://jayitha.github.io/Notes/literature-notes/ongaro2014search.html" class="internal-link" target="_self" rel="noopener">ongaro2014search</a>
<br><a data-href="lamport1982byzantine" href="https://jayitha.github.io/Notes/literature-notes/lamport1982byzantine.html" class="internal-link" target="_self" rel="noopener">lamport1982byzantine</a>
<br><a data-href="castro1999practical" href="https://jayitha.github.io/Notes/literature-notes/castro1999practical.html" class="internal-link" target="_self" rel="noopener">castro1999practical</a>

<br><a data-href="gueta2019sbft" href="https://jayitha.github.io/Notes/literature-notes/gueta2019sbft.html" class="internal-link" target="_self" rel="noopener">gueta2019sbft</a>
<br><a data-href="chun2007attested" href="https://jayitha.github.io/Notes/literature-notes/chun2007attested.html" class="internal-link" target="_self" rel="noopener">chun2007attested</a>
<br><a data-href="castro2000proactive" href="https://jayitha.github.io/Notes/literature-notes/castro2000proactive.html" class="internal-link" target="_self" rel="noopener">castro2000proactive</a>


<br><a data-href="ghemawat2003google" href="https://jayitha.github.io/Notes/literature-notes/ghemawat2003google.html" class="internal-link" target="_self" rel="noopener">ghemawat2003google</a>
<br><a data-href="chang2008bigtable" href="https://jayitha.github.io/Notes/literature-notes/chang2008bigtable.html" class="internal-link" target="_self" rel="noopener">chang2008bigtable</a>

<br><a data-href="burrows2006chubby" href="https://jayitha.github.io/Notes/literature-notes/burrows2006chubby.html" class="internal-link" target="_self" rel="noopener">burrows2006chubby</a>


<br><a data-href="pavlo2009comparison" href="https://jayitha.github.io/Notes/literature-notes/pavlo2009comparison.html" class="internal-link" target="_self" rel="noopener">pavlo2009comparison</a>

<br><a data-href="dean2008mapreduce" href="https://jayitha.github.io/Notes/literature-notes/dean2008mapreduce.html" class="internal-link" target="_self" rel="noopener">dean2008mapreduce</a>
<br><a data-href="stonebraker2010mapreduce" href="https://jayitha.github.io/Notes/literature-notes/stonebraker2010mapreduce.html" class="internal-link" target="_self" rel="noopener">stonebraker2010mapreduce</a>
<br><a data-href="abouzeid2009hadoopdb" href="https://jayitha.github.io/Notes/literature-notes/abouzeid2009hadoopdb.html" class="internal-link" target="_self" rel="noopener">abouzeid2009hadoopdb</a>


<br><a data-href="zaharia2010spark" href="https://jayitha.github.io/Notes/literature-notes/zaharia2010spark.html" class="internal-link" target="_self" rel="noopener">zaharia2010spark</a>

<br><a data-href="zaharia2012resilient" href="https://jayitha.github.io/Notes/literature-notes/zaharia2012resilient.html" class="internal-link" target="_self" rel="noopener">zaharia2012resilient</a>


<br><a data-href="stonebraker2018c" href="https://jayitha.github.io/Notes/literature-notes/stonebraker2018c.html" class="internal-link" target="_self" rel="noopener">stonebraker2018c</a>

<br><a data-href="lamb2012vertica" href="https://jayitha.github.io/Notes/literature-notes/lamb2012vertica.html" class="internal-link" target="_self" rel="noopener">lamb2012vertica</a>
<br><a data-href="abadi2013design" href="https://jayitha.github.io/Notes/literature-notes/abadi2013design.html" class="internal-link" target="_self" rel="noopener">abadi2013design</a>
<br><a data-href="bruno2009teaching" href="https://jayitha.github.io/Notes/literature-notes/bruno2009teaching.html" class="internal-link" target="_self" rel="noopener">bruno2009teaching</a>


<br><a data-href="schuhknecht2013uncracked" href="https://jayitha.github.io/Notes/literature-notes/schuhknecht2013uncracked.html" class="internal-link" target="_self" rel="noopener">schuhknecht2013uncracked</a>

<br><a data-href="idreos2007database" href="https://jayitha.github.io/Notes/literature-notes/idreos2007database.html" class="internal-link" target="_self" rel="noopener">idreos2007database</a>


<br><a data-href="engler1995exokernel" href="https://jayitha.github.io/Notes/literature-notes/engler1995exokernel.html" class="internal-link" target="_self" rel="noopener">engler1995exokernel</a>

<br><a data-href="bershad1994spin" href="https://jayitha.github.io/Notes/literature-notes/bershad1994spin.html" class="internal-link" target="_self" rel="noopener">bershad1994spin</a>


<br><a data-href="klein2009sel4" href="https://jayitha.github.io/Notes/literature-notes/klein2009sel4.html" class="internal-link" target="_self" rel="noopener">klein2009sel4</a>

<br><a data-href="klein2014comprehensive" href="https://jayitha.github.io/Notes/literature-notes/klein2014comprehensive.html" class="internal-link" target="_self" rel="noopener">klein2014comprehensive</a>
<br><a data-href="rashd1991microkernel" href="https://jayitha.github.io/Notes/literature-notes/rashd1991microkernel.html" class="internal-link" target="_self" rel="noopener">rashd1991microkernel</a>
<br><a data-href="liedtke1996toward" href="https://jayitha.github.io/Notes/literature-notes/liedtke1996toward.html" class="internal-link" target="_self" rel="noopener">liedtke1996toward</a>


<br><a data-href="zeldovich2011making" href="https://jayitha.github.io/Notes/literature-notes/zeldovich2011making.html" class="internal-link" target="_self" rel="noopener">zeldovich2011making</a>

<br><a data-href="efstathopoulos2005labels" href="https://jayitha.github.io/Notes/literature-notes/efstathopoulos2005labels.html" class="internal-link" target="_self" rel="noopener">efstathopoulos2005labels</a>


<br><a data-href="chen2015using" href="https://jayitha.github.io/Notes/literature-notes/chen2015using.html" class="internal-link" target="_self" rel="noopener">chen2015using</a>
<br><a data-href="lipp2020meltdown" href="https://jayitha.github.io/Notes/literature-notes/lipp2020meltdown.html" class="internal-link" target="_self" rel="noopener">lipp2020meltdown</a>
<br><a data-href="kocher2020spectre" href="https://jayitha.github.io/Notes/literature-notes/kocher2020spectre.html" class="internal-link" target="_self" rel="noopener">kocher2020spectre</a>

<br><a data-href="van2018foreshadow" href="https://jayitha.github.io/Notes/literature-notes/van2018foreshadow.html" class="internal-link" target="_self" rel="noopener">van2018foreshadow</a>


<br>
<br>
]]></description><link>https://jayitha.github.io/Notes/streams/uc-berkeley's-cs264a-advanced-topics-in-computer-systems.html</link><guid isPermaLink="false">Streams/UC Berkeley's CS264a - Advanced Topics in Computer Systems.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 03 Jan 2024 11:23:09 GMT</pubDate></item><item><title><![CDATA[UC Berkeley's CS286 - Graduate Database Systems]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="https://cs286berkeley.net/sp20#today" rel="noopener" class="external-link" href="https://cs286berkeley.net/sp20#today" target="_blank">Link to website (2020)</a><br>
<a data-tooltip-position="top" aria-label="https://cs286berkeley.net/#grading" rel="noopener" class="external-link" href="https://cs286berkeley.net/#grading" target="_blank">Link to website (2024)</a> - We'll try to keep up.<br>
Pre-requisites include (<a data-href="UC Berkeley's CS294-248 - Topics in Database Theory" href="https://jayitha.github.io/Notes/streams/uc-berkeley's-cs294-248-topics-in-database-theory.html" class="internal-link" target="_self" rel="noopener">UC Berkeley's CS294-248 - Topics in Database Theory</a> or <a data-href="UC Berkeley's CS264a - Advanced Topics in Computer Systems" href="https://jayitha.github.io/Notes/streams/uc-berkeley's-cs264a-advanced-topics-in-computer-systems.html" class="internal-link" target="_self" rel="noopener">UC Berkeley's CS264a - Advanced Topics in Computer Systems</a>)<br>
<br>
Introduction and Course Overview

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1xYb_nHPbjmVAF_ahUvdRx2OOxI_m9fUP0bpdOUepqXk/edit#heading=h.opw2qul7bk9m" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1xYb_nHPbjmVAF_ahUvdRx2OOxI_m9fUP0bpdOUepqXk/edit#heading=h.opw2qul7bk9m" target="_blank">Lecture Notes</a>
<br><a data-href="hellerstein2007architecture" href="https://jayitha.github.io/Notes/literature-notes/hellerstein2007architecture.html" class="internal-link" target="_self" rel="noopener">hellerstein2007architecture</a>

<br><a data-href="chamberlin1981history" href="https://jayitha.github.io/Notes/literature-notes/chamberlin1981history.html" class="internal-link" target="_self" rel="noopener">chamberlin1981history</a>
<br><a data-href="stonebraker1976design" href="https://jayitha.github.io/Notes/literature-notes/stonebraker1976design.html" class="internal-link" target="_self" rel="noopener">stonebraker1976design</a>
<br><a data-tooltip-position="top" aria-label="https://hpi.de/naumann/projects/rdbms-genealogy.html" rel="noopener" class="external-link" href="https://hpi.de/naumann/projects/rdbms-genealogy.html" target="_blank">Database Genealogy Map</a>
<br><a data-href="keshav2007read" href="https://jayitha.github.io/Notes/literature-notes/keshav2007read.html" class="internal-link" target="_self" rel="noopener">keshav2007read</a>
<br><a data-href="roscoe2007writing" href="https://jayitha.github.io/Notes/literature-notes/roscoe2007writing.html" class="internal-link" target="_self" rel="noopener">roscoe2007writing</a>




<br>
 Pioneering Systems Group #1: IBM

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1rOt8eAwTf4iIX-qzIRhatgbOmSJ--mh9Z7F0-ywjo3c/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1rOt8eAwTf4iIX-qzIRhatgbOmSJ--mh9Z7F0-ywjo3c/edit?usp=sharing" target="_blank">Lecture Notes</a>
<br><a data-href="mohan1986transaction" href="https://jayitha.github.io/Notes/literature-notes/mohan1986transaction.html" class="internal-link" target="_self" rel="noopener">mohan1986transaction</a>
<br><a data-href="mackert1986r" href="https://jayitha.github.io/Notes/literature-notes/mackert1986r.html" class="internal-link" target="_self" rel="noopener">mackert1986r</a>

<br><a data-href="lohman1991extensions" href="https://jayitha.github.io/Notes/literature-notes/lohman1991extensions.html" class="internal-link" target="_self" rel="noopener">lohman1991extensions</a>




<br>
Pioneering Systems Group #2: Berkeley

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/14LTjziRp3gCI_g8C8RQzx7dZeUx7PlsOYKX6kWutqiQ/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/14LTjziRp3gCI_g8C8RQzx7dZeUx7PlsOYKX6kWutqiQ/edit?usp=sharing" target="_blank">Lecture Notes</a>
<br><a data-href="stonebraker1991postgres" href="https://jayitha.github.io/Notes/literature-notes/stonebraker1991postgres.html" class="internal-link" target="_self" rel="noopener">stonebraker1991postgres</a>
<br><a data-href="stonebraker1987design" href="https://jayitha.github.io/Notes/literature-notes/stonebraker1987design.html" class="internal-link" target="_self" rel="noopener">stonebraker1987design</a>

<br><a data-href="hellerstein2018looking" href="https://jayitha.github.io/Notes/literature-notes/hellerstein2018looking.html" class="internal-link" target="_self" rel="noopener">hellerstein2018looking</a>

<br><a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Second-system_effect" rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/Second-system_effect" target="_blank">Second System Effect</a> and <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/The_Mythical_Man-Month" rel="noopener" class="external-link" href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month" target="_blank">The Mythical Man-Month</a>






<br>
Pioneering Systems Group #3: Wisconsin

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1L9siK1VQn6e9tUWoA3TF16Y6lnEdEnsGte31NuxkdVM/edit#heading=h.opw2qul7bk9m" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1L9siK1VQn6e9tUWoA3TF16Y6lnEdEnsGte31NuxkdVM/edit#heading=h.opw2qul7bk9m" target="_blank">Lecture Notes</a>
<br><a data-href="dewitt1990gamma" href="https://jayitha.github.io/Notes/literature-notes/dewitt1990gamma.html" class="internal-link" target="_self" rel="noopener">dewitt1990gamma</a>
<br><a data-href="carey1991architecture" href="https://jayitha.github.io/Notes/literature-notes/carey1991architecture.html" class="internal-link" target="_self" rel="noopener">carey1991architecture</a>


<br>
Foundations of Concurrency Control: Bernstein and Goodman

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1mrS7GSb9GYhMo7PyUunfXdS79ZOXIhIoE5OZe9SWr0c/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1mrS7GSb9GYhMo7PyUunfXdS79ZOXIhIoE5OZe9SWr0c/edit?usp=sharing" target="_blank">Lecture Notes</a>
<br><a data-href="bernstein1981concurrency" href="https://jayitha.github.io/Notes/literature-notes/bernstein1981concurrency.html" class="internal-link" target="_self" rel="noopener">bernstein1981concurrency</a>


<br>
Concurrency Control Performance

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1Huu1zMfD0Zh0rkQ0KoVomLd5RQr5hJdqhrFRMN32bWg/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1Huu1zMfD0Zh0rkQ0KoVomLd5RQr5hJdqhrFRMN32bWg/edit?usp=sharing" target="_blank">Lecture Notes</a>
<br><a data-href="agrawal1987concurrency" href="https://jayitha.github.io/Notes/literature-notes/agrawal1987concurrency.html" class="internal-link" target="_self" rel="noopener">agrawal1987concurrency</a>
<br><a data-href="kung1979optimality" href="https://jayitha.github.io/Notes/literature-notes/kung1979optimality.html" class="internal-link" target="_self" rel="noopener">kung1979optimality</a>


<br>
Indexing

<br><a data-href="lehman1981efficient" href="https://jayitha.github.io/Notes/literature-notes/lehman1981efficient.html" class="internal-link" target="_self" rel="noopener">lehman1981efficient</a>
<br><a data-href="o1997improved" href="https://jayitha.github.io/Notes/literature-notes/o1997improved.html" class="internal-link" target="_self" rel="noopener">o1997improved</a>
<br><a data-href="o1996log" href="https://jayitha.github.io/Notes/literature-notes/o1996log.html" class="internal-link" target="_self" rel="noopener">o1996log</a>

<br><a data-href="kornacker1997concurrency" href="https://jayitha.github.io/Notes/literature-notes/kornacker1997concurrency.html" class="internal-link" target="_self" rel="noopener">kornacker1997concurrency</a>




<br>
Introduction to Weak Isolation and Replica Consistency

<br><a data-tooltip-position="top" aria-label="https://drive.google.com/file/d/1hxAO9HCmcICEEgBmo4sPT8-JHMCF870P/view?usp=sharing" rel="noopener" class="external-link" href="https://drive.google.com/file/d/1hxAO9HCmcICEEgBmo4sPT8-JHMCF870P/view?usp=sharing" target="_blank">Slides</a>


<br>
Weak Isolation

<br><a data-href="adya2000generalized" href="https://jayitha.github.io/Notes/literature-notes/adya2000generalized.html" class="internal-link" target="_self" rel="noopener">adya2000generalized</a>
<br><a data-href="crooks2017seeing" href="https://jayitha.github.io/Notes/literature-notes/crooks2017seeing.html" class="internal-link" target="_self" rel="noopener">crooks2017seeing</a>
<br><a data-href="revilak2011precisely" href="https://jayitha.github.io/Notes/literature-notes/revilak2011precisely.html" class="internal-link" target="_self" rel="noopener">revilak2011precisely</a>

<br><a data-href="bailis2016scalable" href="https://jayitha.github.io/Notes/literature-notes/bailis2016scalable.html" class="internal-link" target="_self" rel="noopener">bailis2016scalable</a>
<br><a data-href="bailis2013highly" href="https://jayitha.github.io/Notes/literature-notes/bailis2013highly.html" class="internal-link" target="_self" rel="noopener">bailis2013highly</a>




<br>
Introduction to Application-Level Consistency

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1eYKGgqRfhB-KQRD2mC_E8Hm-YVgMkZO2JFd5mfAxJ3E/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1eYKGgqRfhB-KQRD2mC_E8Hm-YVgMkZO2JFd5mfAxJ3E/edit?usp=sharing" target="_blank">Lecture Notes</a>

<br><a data-href="brewer2012cap" href="https://jayitha.github.io/Notes/literature-notes/brewer2012cap.html" class="internal-link" target="_self" rel="noopener">brewer2012cap</a>
<br><a data-href="hellerstein2020keeping" href="https://jayitha.github.io/Notes/literature-notes/hellerstein2020keeping.html" class="internal-link" target="_self" rel="noopener">hellerstein2020keeping</a>




<br>
Application-Level Consistency

<br><a data-href="helland2009building" href="https://jayitha.github.io/Notes/literature-notes/helland2009building.html" class="internal-link" target="_self" rel="noopener">helland2009building</a>
<br><a data-href="conway2012logic" href="https://jayitha.github.io/Notes/literature-notes/conway2012logic.html" class="internal-link" target="_self" rel="noopener">conway2012logic</a>
<br><a data-href="weiss2010logoot" href="https://jayitha.github.io/Notes/literature-notes/weiss2010logoot.html" class="internal-link" target="_self" rel="noopener">weiss2010logoot</a>

<br><a data-href="decandia2007dynamo" href="https://jayitha.github.io/Notes/literature-notes/decandia2007dynamo.html" class="internal-link" target="_self" rel="noopener">decandia2007dynamo</a>
<br><a data-href="alvaro2011consistency" href="https://jayitha.github.io/Notes/literature-notes/alvaro2011consistency.html" class="internal-link" target="_self" rel="noopener">alvaro2011consistency</a>
<br><a data-href="shapiro2011conflict" href="https://jayitha.github.io/Notes/literature-notes/shapiro2011conflict.html" class="internal-link" target="_self" rel="noopener">shapiro2011conflict</a>




<br>
Introduction to Learning and Database Systems

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1fu-ihMbefbQErcRPcds5Bi2TxF4CxLmamWhvqMN3Mig/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1fu-ihMbefbQErcRPcds5Bi2TxF4CxLmamWhvqMN3Mig/edit?usp=sharing" target="_blank">Lecture Notes</a>
<br><a data-tooltip-position="top" aria-label="https://drive.google.com/file/d/18DMsYodshkmSmJJFS50LfbZK0vIyIqfn/view?usp=sharing" rel="noopener" class="external-link" href="https://drive.google.com/file/d/18DMsYodshkmSmJJFS50LfbZK0vIyIqfn/view?usp=sharing" target="_blank">Slides on CARDLearner</a>
<br><a data-tooltip-position="top" aria-label="https://drive.google.com/file/d/19f3smK7tHueBciHa5I0FAQEXFG_ZHJQc/view?usp=sharing" rel="noopener" class="external-link" href="https://drive.google.com/file/d/19f3smK7tHueBciHa5I0FAQEXFG_ZHJQc/view?usp=sharing" target="_blank">Slides on Naru</a>


<br>
Learning-Based Query Optimization

<br><a data-href="yang2019deep" href="https://jayitha.github.io/Notes/literature-notes/yang2019deep.html" class="internal-link" target="_self" rel="noopener">yang2019deep</a>
<br><a data-href="marcus2019neo" href="https://jayitha.github.io/Notes/literature-notes/marcus2019neo.html" class="internal-link" target="_self" rel="noopener">marcus2019neo</a>
<br><a data-href="wu2018towards" href="https://jayitha.github.io/Notes/literature-notes/wu2018towards.html" class="internal-link" target="_self" rel="noopener">wu2018towards</a>


<br>
Query Processing Revisited

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/1clzcplQ_CwQttAlyDmudbyMzmGZywYE9jK9E-zNADwQ/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/1clzcplQ_CwQttAlyDmudbyMzmGZywYE9jK9E-zNADwQ/edit?usp=sharing" target="_blank">Lecture Notes</a>


<br>
New Approaches to Join Processing

<br><a data-href="veldhuizen2012leapfrog" href="https://jayitha.github.io/Notes/literature-notes/veldhuizen2012leapfrog.html" class="internal-link" target="_self" rel="noopener">veldhuizen2012leapfrog</a>
<br><a data-href="avnur2000eddies" href="https://jayitha.github.io/Notes/literature-notes/avnur2000eddies.html" class="internal-link" target="_self" rel="noopener">avnur2000eddies</a>
<br><a data-href="deshpande2004lifting" href="https://jayitha.github.io/Notes/literature-notes/deshpande2004lifting.html" class="internal-link" target="_self" rel="noopener">deshpande2004lifting</a>


<br>
Introduction to Approximate Query Processing

<br><a data-tooltip-position="top" aria-label="https://docs.google.com/document/d/19IJFdcP_41G9eXDxrTlkyfN9WXzt0l0sUMHd0I0JnHc/edit?usp=sharing" rel="noopener" class="external-link" href="https://docs.google.com/document/d/19IJFdcP_41G9eXDxrTlkyfN9WXzt0l0sUMHd0I0JnHc/edit?usp=sharing" target="_blank">Lecture Notes</a>

<br><a data-href="cormode2017data" href="https://jayitha.github.io/Notes/literature-notes/cormode2017data.html" class="internal-link" target="_self" rel="noopener">cormode2017data</a>
<br><a data-href="hellerstein1999interactive" href="https://jayitha.github.io/Notes/literature-notes/hellerstein1999interactive.html" class="internal-link" target="_self" rel="noopener">hellerstein1999interactive</a>




<br>
Approximate Query Processing

<br><a data-href="li2016wander" href="https://jayitha.github.io/Notes/literature-notes/li2016wander.html" class="internal-link" target="_self" rel="noopener">li2016wander</a>
<br><a data-href="rahman2017ve" href="https://jayitha.github.io/Notes/literature-notes/rahman2017ve.html" class="internal-link" target="_self" rel="noopener">rahman2017ve</a>
<br><a data-href="park2018verdictdb" href="https://jayitha.github.io/Notes/literature-notes/park2018verdictdb.html" class="internal-link" target="_self" rel="noopener">park2018verdictdb</a>

<br><a data-href="hellerstein1997online" href="https://jayitha.github.io/Notes/literature-notes/hellerstein1997online.html" class="internal-link" target="_self" rel="noopener">hellerstein1997online</a>
<br><a data-href="raman2002partial" href="https://jayitha.github.io/Notes/literature-notes/raman2002partial.html" class="internal-link" target="_self" rel="noopener">raman2002partial</a>
<br><a data-href="mozafari2017approximate" href="https://jayitha.github.io/Notes/literature-notes/mozafari2017approximate.html" class="internal-link" target="_self" rel="noopener">mozafari2017approximate</a>




<br>
Main Memory Query Processing

<br><a data-href="neumann2011efficiently" href="https://jayitha.github.io/Notes/literature-notes/neumann2011efficiently.html" class="internal-link" target="_self" rel="noopener">neumann2011efficiently</a>
<br><a data-href="leis2014morsel" href="https://jayitha.github.io/Notes/literature-notes/leis2014morsel.html" class="internal-link" target="_self" rel="noopener">leis2014morsel</a>
<br><a data-href="leis2018leanstore" href="https://jayitha.github.io/Notes/literature-notes/leis2018leanstore.html" class="internal-link" target="_self" rel="noopener">leis2018leanstore</a>


<br>
Main Memory Concurrency Control

<br><a data-href="larson2011high" href="https://jayitha.github.io/Notes/literature-notes/larson2011high.html" class="internal-link" target="_self" rel="noopener">larson2011high</a>
<br><a data-href="neumann2015fast" href="https://jayitha.github.io/Notes/literature-notes/neumann2015fast.html" class="internal-link" target="_self" rel="noopener">neumann2015fast</a>
<br><a data-href="huang2020opportunities" href="https://jayitha.github.io/Notes/literature-notes/huang2020opportunities.html" class="internal-link" target="_self" rel="noopener">huang2020opportunities</a>

<br><a data-href="szekeres2020meerkat" href="https://jayitha.github.io/Notes/literature-notes/szekeres2020meerkat.html" class="internal-link" target="_self" rel="noopener">szekeres2020meerkat</a>




<br>
Programming Support for Database-Backed Applications

<br><a data-href="bernstein2014orleans" href="https://jayitha.github.io/Notes/literature-notes/bernstein2014orleans.html" class="internal-link" target="_self" rel="noopener">bernstein2014orleans</a>
<br><a data-href="cheung2013optimizing" href="https://jayitha.github.io/Notes/literature-notes/cheung2013optimizing.html" class="internal-link" target="_self" rel="noopener">cheung2013optimizing</a>
<br><a data-href="bailis2015feral" href="https://jayitha.github.io/Notes/literature-notes/bailis2015feral.html" class="internal-link" target="_self" rel="noopener">bailis2015feral</a>


<br>
Cloud Databases

<br><a data-href="corbett2013spanner" href="https://jayitha.github.io/Notes/literature-notes/corbett2013spanner.html" class="internal-link" target="_self" rel="noopener">corbett2013spanner</a>
<br><a data-href="verbitski2017amazon" href="https://jayitha.github.io/Notes/literature-notes/verbitski2017amazon.html" class="internal-link" target="_self" rel="noopener">verbitski2017amazon</a>
<br><a data-href="verbitski2018amazon" href="https://jayitha.github.io/Notes/literature-notes/verbitski2018amazon.html" class="internal-link" target="_self" rel="noopener">verbitski2018amazon</a>


<br>
Data Wrangling and Cleaning

<br><a data-href="kandel2011wrangler" href="https://jayitha.github.io/Notes/literature-notes/kandel2011wrangler.html" class="internal-link" target="_self" rel="noopener">kandel2011wrangler</a>
<br><a data-href="mahdavi2019raha" href="https://jayitha.github.io/Notes/literature-notes/mahdavi2019raha.html" class="internal-link" target="_self" rel="noopener">mahdavi2019raha</a>
<br><a data-href="mudgal2018deep" href="https://jayitha.github.io/Notes/literature-notes/mudgal2018deep.html" class="internal-link" target="_self" rel="noopener">mudgal2018deep</a>

<br><a data-href="rekatsinas2017holoclean" href="https://jayitha.github.io/Notes/literature-notes/rekatsinas2017holoclean.html" class="internal-link" target="_self" rel="noopener">rekatsinas2017holoclean</a>
<br><a data-href="singh2016blinkfill" href="https://jayitha.github.io/Notes/literature-notes/singh2016blinkfill.html" class="internal-link" target="_self" rel="noopener">singh2016blinkfill</a>
<br><a data-href="krishnan2016activeclean" href="https://jayitha.github.io/Notes/literature-notes/krishnan2016activeclean.html" class="internal-link" target="_self" rel="noopener">krishnan2016activeclean</a>




]]></description><link>https://jayitha.github.io/Notes/streams/uc-berkeley's-cs286-graduate-database-systems.html</link><guid isPermaLink="false">Streams/UC Berkeley's CS286 - Graduate Database Systems.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 26 Dec 2023 12:07:35 GMT</pubDate></item><item><title><![CDATA[UC Berkeley's CS294-248 - Topics in Database Theory]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io" target="_blank">Link to website</a><br>
Includes content from the Simons <a data-tooltip-position="top" aria-label="https://simons.berkeley.edu/programs/logic-algorithms-database-theory-ai" rel="noopener" class="external-link" href="https://simons.berkeley.edu/programs/logic-algorithms-database-theory-ai" target="_blank">Logic and Algorithms in Database Theory and AI</a> Program<br>
<br><a data-tooltip-position="top" aria-label="https://simons.berkeley.edu/workshops/logic-algorithms-database-theory-ai-boot-camp#simons-tabs" rel="noopener" class="external-link" href="https://simons.berkeley.edu/workshops/logic-algorithms-database-theory-ai-boot-camp#simons-tabs" target="_blank">Logic and Algorithms in Database Theory and AI Boot Camp</a>
<br>Logic and Queries

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit1.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit1.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/VCi45naqnN8?si=Sd981YObi2OM_DLk" rel="noopener" class="external-link" href="https://youtu.be/VCi45naqnN8?si=Sd981YObi2OM_DLk" target="_blank">Video</a>


<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/hw/hw1-whitespace.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/hw/hw1-whitespace.pdf" target="_blank">HW1</a>
<br>Conjunctive Queries

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit2.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit2.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/DFZ3NmKHKPo?si=JW2EgFMGDKGcFzYF" rel="noopener" class="external-link" href="https://youtu.be/DFZ3NmKHKPo?si=JW2EgFMGDKGcFzYF" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/hdjPCHHMFZU?si=7m6MxqS0MnlG9FKb" rel="noopener" class="external-link" href="https://youtu.be/hdjPCHHMFZU?si=7m6MxqS0MnlG9FKb" target="_blank">Video2</a>


<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/hw/hw2-whitespace.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/hw/hw2-whitespace.pdf" target="_blank">HW2</a>
<br>Incremental View Maintenance

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/Olteanu-IVM-Berkeley.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/Olteanu-IVM-Berkeley.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/H2i2Q2CKzPc?si=EnmBd1geAtHhufm3" rel="noopener" class="external-link" href="https://youtu.be/H2i2Q2CKzPc?si=EnmBd1geAtHhufm3" target="_blank">Video</a>


<br>AGM Bound,&nbsp;Worst-Case Optimal Algorithms

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit4.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit4.pdf" target="_blank">Slides</a> <a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/hung-ngo-wcoj.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/hung-ngo-wcoj.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/H2i2Q2CKzPc?si=KTlwECsUacrNOaUI" rel="noopener" class="external-link" href="https://youtu.be/H2i2Q2CKzPc?si=KTlwECsUacrNOaUI" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/BZ0qENq6aFs?si=P9aZxueBXEnKVLFt" rel="noopener" class="external-link" href="https://youtu.be/BZ0qENq6aFs?si=P9aZxueBXEnKVLFt" target="_blank">Video2</a>


<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/hw/hw3-whitespace.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/hw/hw3-whitespace.pdf" target="_blank">HW3</a>
<br><a data-tooltip-position="top" aria-label="https://simons.berkeley.edu/workshops/fine-grained-complexity-logic-query-evaluation#simons-tabs" rel="noopener" class="external-link" href="https://simons.berkeley.edu/workshops/fine-grained-complexity-logic-query-evaluation#simons-tabs" target="_blank">Fine-Grained Complexity, Logic, and Query Evaluation</a>
<br>Information Inequalities&nbsp;and&nbsp;Database Constraints

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit5.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit5.pdf" target="_blank">Slides</a> <a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit5b.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit5b.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/GzOh82g2G64?si=O5OnV0yO4qo08SOE" rel="noopener" class="external-link" href="https://youtu.be/GzOh82g2G64?si=O5OnV0yO4qo08SOE" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/PnfBUqwiAVA?si=PYLCfGYDSAJclUlD" rel="noopener" class="external-link" href="https://youtu.be/PnfBUqwiAVA?si=PYLCfGYDSAJclUlD" target="_blank">Video2</a>


<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/hw/hw4-whitespace.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/hw/hw4-whitespace.pdf" target="_blank">HW4</a>
<br>Database Constraints (cont'd),&nbsp;Repairs, Incomplete Databases

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit6.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit6.pdf" target="_blank">Slides</a> <a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit6b.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit6b.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/gqbaG_BeFLY?si=LNFEaN0bHM1vBdXu" rel="noopener" class="external-link" href="https://youtu.be/gqbaG_BeFLY?si=LNFEaN0bHM1vBdXu" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/BFql5OxiEDs?si=gp2_WhbA8Rod8FFX" rel="noopener" class="external-link" href="https://youtu.be/BFql5OxiEDs?si=gp2_WhbA8Rod8FFX" target="_blank">Video2</a>


<br><a data-tooltip-position="top" aria-label="https://simons.berkeley.edu/workshops/probabilistic-circuits-logic#simons-tabs" rel="noopener" class="external-link" href="https://simons.berkeley.edu/workshops/probabilistic-circuits-logic#simons-tabs" target="_blank">Probabilistic Circuits and Logic</a>
<br>Semirings and K-Relations, WCOJ and Tree Decomposition

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit7.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit7.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/tPmv09CIAaM?si=edv01qdDhYgfwPKh" rel="noopener" class="external-link" href="https://youtu.be/tPmv09CIAaM?si=edv01qdDhYgfwPKh" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/FilHYGSiy2A?si=kx1p_yrOaI7sRbbH" rel="noopener" class="external-link" href="https://youtu.be/FilHYGSiy2A?si=kx1p_yrOaI7sRbbH" target="_blank">Video2</a>
<br>Recommended talk by Reinhard Pichler

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/2023-09-18-ReinhardPichler.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/2023-09-18-ReinhardPichler.pdf" target="_blank">Slides</a> <a data-tooltip-position="top" aria-label="https://youtu.be/9Ze7l8XxS5Y?si=_VvuDgx1AlUdrXRT" rel="noopener" class="external-link" href="https://youtu.be/9Ze7l8XxS5Y?si=_VvuDgx1AlUdrXRT" target="_blank">Video</a>




<br>FAQ&nbsp;(Hung Ngo), Introduction to Datalog

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/faq.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/faq.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/MW2pCvvAa7s?si=XqjH14s_YKAw5u8F" rel="noopener" class="external-link" href="https://youtu.be/MW2pCvvAa7s?si=XqjH14s_YKAw5u8F" target="_blank">Video1</a> <a data-tooltip-position="top" aria-label="https://youtu.be/F337yVUdR6U?si=pSXxl_JqyEiSqTRu" rel="noopener" class="external-link" href="https://youtu.be/F337yVUdR6U?si=pSXxl_JqyEiSqTRu" target="_blank">Video2</a>


<br>Datalog&nbsp;(cont'd)

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit9.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit9.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/4t9nhWY_Uf4?si=GIdf0XhvShkm5eTg" rel="noopener" class="external-link" href="https://youtu.be/4t9nhWY_Uf4?si=GIdf0XhvShkm5eTg" target="_blank">Video</a>


<br><a data-tooltip-position="top" aria-label="https://simons.berkeley.edu/workshops/logic-algebra-query-evaluation#simons-tabs" rel="noopener" class="external-link" href="https://simons.berkeley.edu/workshops/logic-algebra-query-evaluation#simons-tabs" target="_blank">Logic and Algebra for Query Evaluation</a>
<br>Datalog,&nbsp;Final review of the class

<br><a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unit9b.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unit9b.pdf" target="_blank">Slides</a> <a data-tooltip-position="top" aria-label="https://berkeley-cs294-248.github.io/lectures/unitReview.pdf" rel="noopener" class="external-link" href="https://berkeley-cs294-248.github.io/lectures/unitReview.pdf" target="_blank">Slides</a>
<br><a data-tooltip-position="top" aria-label="https://youtu.be/witWaeaSXaQ?si=TDKsa69xGTGApsuP" rel="noopener" class="external-link" href="https://youtu.be/witWaeaSXaQ?si=TDKsa69xGTGApsuP" target="_blank">Video</a>


]]></description><link>https://jayitha.github.io/Notes/streams/uc-berkeley's-cs294-248-topics-in-database-theory.html</link><guid isPermaLink="false">Streams/UC Berkeley's CS294-248 - Topics in Database Theory.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 26 Dec 2023 10:18:24 GMT</pubDate></item><item><title><![CDATA[TIL - Rust]]></title><description><![CDATA[<a class="tag" href="https://jayitha.github.io/Notes/?query=tag:Rust" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#Rust</a> 
 <br><a href="https://jayitha.github.io/Notes?query=tag:Rust" class="tag" target="_blank" rel="noopener">#Rust</a><br><br>If you want to modify a Some value behind an Option variable in place, there are a few ways to do it. Let's assume we want to modify a variable opt_x of type Option&lt;X&gt;<br>opt_x: Option&lt;X&gt;
Copy<br>where type X has an associated method that mutates the value in place i.e. <br>impl X {
	pub fn mutate(&amp;mut self) {...}
}
Copy<br>
<br>Use pattern matching.
<br>if let Some(ref mut x: &amp;mut X) = opt_x {
	x.mutate()
}
Copy<br>
<br>Use <a data-tooltip-position="top" aria-label="https://doc.rust-lang.org/std/option/struct.IterMut.html" rel="noopener" class="external-link" href="https://doc.rust-lang.org/std/option/struct.IterMut.html" target="_blank"><code></code></a>iter_mut and map. The iter_mut iterator yields one value if it's the Some variant and none otherwise.
<br>let _ = opt_x.iter_mut().map(|x: &amp;mut X| x.mutate())
Copy<br>you have to assign the map result to something -- since iterators are lazy, the map doesn't get evaluated until it's assigned to something<br><br>Today on Reddit someone was discussing <a data-tooltip-position="top" aria-label="https://internals.rust-lang.org/t/pre-rfc-implicit-number-type-widening/10432/19" rel="noopener" class="external-link" href="https://internals.rust-lang.org/t/pre-rfc-implicit-number-type-widening/10432/19" target="_blank">integer wielding</a> and how code could be verbose and unreadable without wielding. I loved one comment which said<br>
I'd rather have an annoyance instead of a bug.
<br><a href="https://www.reddit.com/r/rust/comments/1833k19/comment/kamde3v/" target="_blank" rel="noopener">Comment</a><br> by<a href="https://www.reddit.com/user/althahahayes/" target="_blank" rel="noopener">u/althahahayes</a> from discussion<a href="https://www.reddit.com/r/rust/comments/1833k19/what_is_the_idiomatic_way_to_deal_with_mixed/" target="_blank" rel="noopener"></a><br> in<a href="https://www.reddit.com/r/rust/" target="_blank" rel="noopener">rust</a><br><br>I've always wondered how data is written to disk in a typical data management system. Do you use mmap? <br>So, I'm going to take a quick peek at <a data-tooltip-position="top" aria-label="https://github.com/risinglightdb/risinglight" rel="noopener" class="external-link" href="https://github.com/risinglightdb/risinglight" target="_blank">RisingLight</a><br>RisingLight uses protobuf to encode some data on disk<br>For some reason I had to reinstall rust-analyzer even though it ran this morning]]></description><link>https://jayitha.github.io/Notes/til/til-rust.html</link><guid isPermaLink="false">TIL/TIL - Rust.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Wed, 14 Feb 2024 18:28:06 GMT</pubDate></item><item><title><![CDATA[TIL - Words]]></title><description><![CDATA[ 
 <br>Words I come across in papers I'd like to use more when writing. Or maybe I should just use a Thesaurus?<br>
<br>Eschews - deliberately avoid using; abstain from. <a data-href="moseley2006out" href="https://jayitha.github.io/Notes/literature-notes/moseley2006out.html" class="internal-link" target="_self" rel="noopener">moseley2006out</a>
<br>Emphatically - in a forceful way <a data-href="moseley2006out" href="https://jayitha.github.io/Notes/literature-notes/moseley2006out.html" class="internal-link" target="_self" rel="noopener">moseley2006out</a>
<br>Obviates - remove (a need or difficulty) <a data-href="kemper2010hyper" href="https://jayitha.github.io/Notes/literature-notes/kemper2010hyper.html" class="internal-link" target="_self" rel="noopener">kemper2010hyper</a>
]]></description><link>https://jayitha.github.io/Notes/til/til-words.html</link><guid isPermaLink="false">TIL/TIL - Words.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Fri, 02 Feb 2024 16:34:54 GMT</pubDate></item><item><title><![CDATA[Glossary]]></title><description><![CDATA[ 
 <br><br><br>C: <br><a data-tooltip-position="top" aria-label="Glossary/Chebyshev Metric.md" data-href="Glossary/Chebyshev Metric.md" href="https://jayitha.github.io/Notes/glossary/chebyshev-metric.html" class="internal-link" target="_self" rel="noopener">Chebyshev Metric</a><br><a data-tooltip-position="top" aria-label="Glossary/Concurrency.md" data-href="Glossary/Concurrency.md" href="https://jayitha.github.io/Notes/glossary/concurrency.html" class="internal-link" target="_self" rel="noopener">Concurrency</a><br><a data-tooltip-position="top" aria-label="Glossary/Curse of Dimensionality.md" data-href="Glossary/Curse of Dimensionality.md" href="https://jayitha.github.io/Notes/glossary/curse-of-dimensionality.html" class="internal-link" target="_self" rel="noopener">Curse of Dimensionality</a><br><a data-tooltip-position="top" aria-label="Glossary/Converges in Probability.md" data-href="Glossary/Converges in Probability.md" href="https://jayitha.github.io/Notes/glossary/converges-in-probability.html" class="internal-link" target="_self" rel="noopener">Converges in Probability</a><br>E: <br><a data-tooltip-position="top" aria-label="Glossary/Equi-Join.md" data-href="Glossary/Equi-Join.md" href="https://jayitha.github.io/Notes/glossary/equi-join.html" class="internal-link" target="_self" rel="noopener">Equi-Join</a><br>i: <br><a data-tooltip-position="top" aria-label="Glossary/iMinMax.md" data-href="Glossary/iMinMax.md" href="https://jayitha.github.io/Notes/glossary/iminmax.html" class="internal-link" target="_self" rel="noopener">iMinMax</a><br>I: <br><a data-tooltip-position="top" aria-label="Glossary/Independent and Identically Distributed (IID).md" data-href="Glossary/Independent and Identically Distributed (IID).md" href="https://jayitha.github.io/Notes/glossary/independent-and-identically-distributed-(iid).html" class="internal-link" target="_self" rel="noopener">Independent and Identically Distributed (IID)</a><br>L: <br><a data-tooltip-position="top" aria-label="Glossary/Locality Sensitive Hashing.md" data-href="Glossary/Locality Sensitive Hashing.md" href="https://jayitha.github.io/Notes/glossary/locality-sensitive-hashing.html" class="internal-link" target="_self" rel="noopener">Locality Sensitive Hashing</a><br>P: <br><a data-tooltip-position="top" aria-label="Glossary/Persistence.md" data-href="Glossary/Persistence.md" href="https://jayitha.github.io/Notes/glossary/persistence.html" class="internal-link" target="_self" rel="noopener">Persistence</a><br><a data-tooltip-position="top" aria-label="Glossary/Pyramid Technique.md" data-href="Glossary/Pyramid Technique.md" href="https://jayitha.github.io/Notes/glossary/pyramid-technique.html" class="internal-link" target="_self" rel="noopener">Pyramid Technique</a><br>S: <br><a data-tooltip-position="top" aria-label="Glossary/Slutsky's Theorem.md" data-href="Glossary/Slutsky's Theorem.md" href="https://jayitha.github.io/Notes/glossary/slutsky's-theorem.html" class="internal-link" target="_self" rel="noopener">Slutsky's Theorem</a><br>T: <br><a data-tooltip-position="top" aria-label="Glossary/The Relational Model.md" data-href="Glossary/The Relational Model.md" href="https://jayitha.github.io/Notes/glossary/the-relational-model.html" class="internal-link" target="_self" rel="noopener">The Relational Model</a><br>U: <br><a data-tooltip-position="top" aria-label="Glossary/Unstable Nearest Neighbor Query.md" data-href="Glossary/Unstable Nearest Neighbor Query.md" href="https://jayitha.github.io/Notes/glossary/unstable-nearest-neighbor-query.html" class="internal-link" target="_self" rel="noopener">Unstable Nearest Neighbor Query</a><br>V: <br><a data-tooltip-position="top" aria-label="Glossary/VA-File.md" data-href="Glossary/VA-File.md" href="https://jayitha.github.io/Notes/glossary/va-file.html" class="internal-link" target="_self" rel="noopener">VA-File</a><br><a data-tooltip-position="top" aria-label="Glossary/Virtualization.md" data-href="Glossary/Virtualization.md" href="https://jayitha.github.io/Notes/glossary/virtualization.html" class="internal-link" target="_self" rel="noopener">Virtualization</a><br>W: <br><a data-tooltip-position="top" aria-label="Glossary/Weak Law of Large Numbers.md" data-href="Glossary/Weak Law of Large Numbers.md" href="https://jayitha.github.io/Notes/glossary/weak-law-of-large-numbers.html" class="internal-link" target="_self" rel="noopener">Weak Law of Large Numbers</a><br><br><br><a data-href="UC Berkeley's CS286 - Graduate Database Systems" href="https://jayitha.github.io/Notes/streams/uc-berkeley's-cs286-graduate-database-systems.html" class="internal-link" target="_self" rel="noopener">UC Berkeley's CS286 - Graduate Database Systems</a><br>
<a data-href="Ryan Marcus' CIS 6500 – Advanced Topics in Database Systems" href="https://jayitha.github.io/Notes/streams/ryan-marcus'-cis-6500-–-advanced-topics-in-database-systems.html" class="internal-link" target="_self" rel="noopener">Ryan Marcus' CIS 6500 – Advanced Topics in Database Systems</a><br>
<a data-href="UC Berkeley's CS294-248 - Topics in Database Theory" href="https://jayitha.github.io/Notes/streams/uc-berkeley's-cs294-248-topics-in-database-theory.html" class="internal-link" target="_self" rel="noopener">UC Berkeley's CS294-248 - Topics in Database Theory</a><br>
<a data-href="UC Berkeley's CS264a - Advanced Topics in Computer Systems" href="https://jayitha.github.io/Notes/streams/uc-berkeley's-cs264a-advanced-topics-in-computer-systems.html" class="internal-link" target="_self" rel="noopener">UC Berkeley's CS264a - Advanced Topics in Computer Systems</a><br><br><br>2019: <br><a data-tooltip-position="top" aria-label="Literature Notes/petrov2019database.md" data-href="Literature Notes/petrov2019database.md" href="https://jayitha.github.io/Notes/literature-notes/petrov2019database.html" class="internal-link" target="_self" rel="noopener">Database Internals: A deep dive into how distributed data systems work</a><br>2018: <br><a data-tooltip-position="top" aria-label="Literature Notes/arpacidusseau2018operating.md" data-href="Literature Notes/arpacidusseau2018operating.md" href="https://jayitha.github.io/Notes/literature-notes/arpacidusseau2018operating.html" class="internal-link" target="_self" rel="noopener">Operating systems: Three easy pieces</a><br>2017: <br><a data-tooltip-position="top" aria-label="Literature Notes/verbitski2017amazon.md" data-href="Literature Notes/verbitski2017amazon.md" href="https://jayitha.github.io/Notes/literature-notes/verbitski2017amazon.html" class="internal-link" target="_self" rel="noopener">Amazon aurora: Design considerations for high throughput cloud-native relational databases</a><br>2016: <br><a data-tooltip-position="top" aria-label="Literature Notes/kleppmann2014designing.md" data-href="Literature Notes/kleppmann2014designing.md" href="https://jayitha.github.io/Notes/literature-notes/kleppmann2014designing.html" class="internal-link" target="_self" rel="noopener">Designing data-intensive applications: The big ideas behind reliable, scalable, and maintainable systems</a><br>2013: <br><a data-tooltip-position="top" aria-label="Literature Notes/corbett2013spanner.md" data-href="Literature Notes/corbett2013spanner.md" href="https://jayitha.github.io/Notes/literature-notes/corbett2013spanner.html" class="internal-link" target="_self" rel="noopener">Spanner: Google's globally distributed database</a><br>2010: <br><a data-tooltip-position="top" aria-label="Literature Notes/kemper2010hyper.md" data-href="Literature Notes/kemper2010hyper.md" href="https://jayitha.github.io/Notes/literature-notes/kemper2010hyper.html" class="internal-link" target="_self" rel="noopener">Hyper: Hybrid OLTP&amp;OLAP high performance database system</a><br>2006: <br><a data-tooltip-position="top" aria-label="Literature Notes/ierusalimschy2006programming.md" data-href="Literature Notes/ierusalimschy2006programming.md" href="https://jayitha.github.io/Notes/literature-notes/ierusalimschy2006programming.html" class="internal-link" target="_self" rel="noopener">Programming in lua</a><br><a data-tooltip-position="top" aria-label="Literature Notes/moseley2006out.md" data-href="Literature Notes/moseley2006out.md" href="https://jayitha.github.io/Notes/literature-notes/moseley2006out.html" class="internal-link" target="_self" rel="noopener">Out of the tar pit</a><br>2000: <br><a data-tooltip-position="top" aria-label="Literature Notes/ooi2000indexing.md" data-href="Literature Notes/ooi2000indexing.md" href="https://jayitha.github.io/Notes/literature-notes/ooi2000indexing.html" class="internal-link" target="_self" rel="noopener">Indexing the Edges—a simple and yet efficient approach to high-dimensional indexing</a><br>1999: <br><a data-tooltip-position="top" aria-label="Literature Notes/beyer1999nearest.md" data-href="Literature Notes/beyer1999nearest.md" href="https://jayitha.github.io/Notes/literature-notes/beyer1999nearest.html" class="internal-link" target="_self" rel="noopener">When is “Nearest neighbor” meaningful?</a><br>1995: <br><a data-tooltip-position="top" aria-label="Literature Notes/abiteboul1995foundations.md" data-href="Literature Notes/abiteboul1995foundations.md" href="https://jayitha.github.io/Notes/literature-notes/abiteboul1995foundations.html" class="internal-link" target="_self" rel="noopener">Foundations of databases</a><br>1984: <br><a data-tooltip-position="top" aria-label="Literature Notes/gray1984logic.md" data-href="Literature Notes/gray1984logic.md" href="https://jayitha.github.io/Notes/literature-notes/gray1984logic.html" class="internal-link" target="_self" rel="noopener">Logic, algebra and databases</a><br>1976: <br><a data-tooltip-position="top" aria-label="Literature Notes/stonebraker1976design.md" data-href="Literature Notes/stonebraker1976design.md" href="https://jayitha.github.io/Notes/literature-notes/stonebraker1976design.html" class="internal-link" target="_self" rel="noopener">The design and implementation of INGRES</a><br><a data-tooltip-position="top" aria-label="Literature Notes/gray1976granularity.md" data-href="Literature Notes/gray1976granularity.md" href="https://jayitha.github.io/Notes/literature-notes/gray1976granularity.html" class="internal-link" target="_self" rel="noopener">Granularity of locks and degrees of consistency</a><br>1970: <br><a data-tooltip-position="top" aria-label="Literature Notes/codd1970relational.md" data-href="Literature Notes/codd1970relational.md" href="https://jayitha.github.io/Notes/literature-notes/codd1970relational.html" class="internal-link" target="_self" rel="noopener">A relational model of data for large shared data banks</a><br><br><br>2023: <br><a data-tooltip-position="top" aria-label="Literature Notes/bos2023rust.md" data-href="Literature Notes/bos2023rust.md" href="https://jayitha.github.io/Notes/literature-notes/bos2023rust.html" class="internal-link" target="_self" rel="noopener">Rust temporary lifetimes and "Super Let"</a><br>2013: <br><a data-tooltip-position="top" aria-label="Literature Notes/leis2013adaptive.md" data-href="Literature Notes/leis2013adaptive.md" href="https://jayitha.github.io/Notes/literature-notes/leis2013adaptive.html" class="internal-link" target="_self" rel="noopener">The adaptive radix tree: ARTful indexing for main-memory databases</a><br>2007: <br><a data-tooltip-position="top" aria-label="Literature Notes/keshav2007read.md" data-href="Literature Notes/keshav2007read.md" href="https://jayitha.github.io/Notes/literature-notes/keshav2007read.html" class="internal-link" target="_self" rel="noopener">How to read a paper</a><br>]]></description><link>https://jayitha.github.io/Notes/index.html</link><guid isPermaLink="false">index.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Tue, 26 Dec 2023 10:20:24 GMT</pubDate></item><item><title><![CDATA[To Read]]></title><description><![CDATA[ 
 <br><br><br>2023: <br><br>2022: <br><br><br><br><br>2021: <br><br><br>2020: <br><br><br><br><br><br>2019: <br><br><br><br>2018: <br><br><br><br><br><br>2017: <br><br><br><br>2016: <br><br><br><br><br><br>2015: <br><br><br><br><br>2014: <br><br><br><br>2013: <br><br><br><br>2012: <br><br><br><br>2011: <br><br><br><br><br><br>2010: <br><br>2009: <br><br><br><br><br>2008: <br><br><br><br><br>2007: <br><br><br><br>2006: <br><br><br>2005: <br><br><br><br><br><br>2004: <br><br><br>2003: <br><br><br><br>2002: <br><br><br>2001: <br><br><br>2000: <br><br><br><br>1999: <br><br><br>1998: <br><br><br><br>1997: <br><br><br><br>1996: <br><br><br><br><br><br>1995: <br><br><br>1994: <br><br>1992: <br><br>1991: <br><br><br><br>1990: <br><br>1989: <br><br>1988: <br><br>1987: <br><br>1986: <br><br><br>1984: <br><br><br>1983: <br><br>1982: <br><br>1981: <br><br><br><br>1979: <br><br>1978: <br><br>1976: <br><br>1975: <br><br>1974: <br><br>1971: <br>]]></description><link>https://jayitha.github.io/Notes/to-read.html</link><guid isPermaLink="false">To-Read.md</guid><dc:creator><![CDATA[Jayitha Cherapanamjeri]]></dc:creator><pubDate>Sun, 31 Dec 2023 11:17:32 GMT</pubDate></item></channel></rss>